[
  {
    "path": "posts/2022-04-03-closeness-betweeness-socialnetworking/",
    "title": "Investigating Closeness in a MOOC-Ed discussion group",
    "description": "Working on this one",
    "author": [
      {
        "name": "Jeanne McClure",
        "url": {}
      }
    ],
    "date": "2022-04-03",
    "categories": [],
    "contents": "\r\n1 Load Packages\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\nlibrary(skimr)\r\nlibrary(igraph)\r\nlibrary(tidygraph)\r\nlibrary(ggraph)\r\nlibrary(janitor)\r\nlibrary(RColorBrewer)\r\n\r\n\r\n\r\n2 Wrangle Data\r\nImport edges:\r\n\r\n\r\nShow code\r\n\r\ndlt1_ties <- read_csv(\"~/r-projects/mccluredistill/_posts/2022-04-03-closeness-betweeness-socialnetworking/data/dlt1-edges.csv\", \r\n                      col_types = cols(Sender = col_character(), \r\n                                       Receiver = col_character(), \r\n                                       `Category Text` = col_skip(), \r\n                                       `Comment ID` = col_character(), \r\n                                       `Discussion ID` = col_character())) |>\r\n  clean_names()\r\n\r\ndlt1_ties\r\n\r\n\r\n# A tibble: 2,529 x 9\r\n   sender receiver timestamp    discussion_title      discussion_cate~\r\n   <chr>  <chr>    <chr>        <chr>                 <chr>           \r\n 1 360    444      4/4/13 16:32 Most important chang~ Group N         \r\n 2 356    444      4/4/13 18:45 Most important chang~ Group D-L       \r\n 3 356    444      4/4/13 18:47 DLT Resources—Commen~ Group D-L       \r\n 4 344    444      4/4/13 18:55 Most important chang~ Group O-T       \r\n 5 392    444      4/4/13 19:13 Most important chang~ Group U-Z       \r\n 6 219    444      4/4/13 19:16 Most important chang~ Group M         \r\n 7 318    444      4/4/13 19:26 Most important chang~ Group M         \r\n 8 4      444      4/4/13 19:44 Most important chang~ Group N         \r\n 9 355    356      4/4/13 20:12 DLT Resources—Commen~ Group D-L       \r\n10 355    444      4/4/13 20:13 Most important chang~ Group D-L       \r\n# ... with 2,519 more rows, and 4 more variables:\r\n#   parent_category <chr>, discussion_identifier <chr>,\r\n#   comment_id <chr>, discussion_id <chr>\r\n\r\nAdd node attributes:\r\n\r\n\r\nShow code\r\n\r\ndlt1_actors <- read_csv(\"data/dlt1-nodes.csv\", \r\n                        col_types = cols(UID = col_character(), \r\n                                       Facilitator = col_character(), \r\n                                       `expert` = col_character(), \r\n                                       `connect` = col_character())) |>\r\n  clean_names()\r\n\r\ndlt1_actors\r\n\r\n\r\n# A tibble: 445 x 13\r\n   uid   facilitator role1      experience experience2 grades location\r\n   <chr> <chr>       <chr>           <dbl> <chr>       <chr>  <chr>   \r\n 1 1     0           libmedia            1 6 to 10     secon~ VA      \r\n 2 2     0           classteac~          1 6 to 10     secon~ FL      \r\n 3 3     0           districta~          2 11 to 20    gener~ PA      \r\n 4 4     0           classteac~          2 11 to 20    middle NC      \r\n 5 5     0           otheredpr~          3 20+         gener~ AL      \r\n 6 6     0           classteac~          1 4 to 5      gener~ AL      \r\n 7 7     0           instructi~          2 11 to 20    gener~ SD      \r\n 8 8     0           specialed           1 6 to 10     secon~ BE      \r\n 9 9     0           classteac~          1 6 to 10     middle NC      \r\n10 10    0           schooladm~          2 11 to 20    middle NC      \r\n# ... with 435 more rows, and 6 more variables: region <chr>,\r\n#   country <chr>, group <chr>, gender <chr>, expert <chr>,\r\n#   connect <chr>\r\n\r\ncodebook descriptors. The first one has been done as an example.\r\nFacilitator = Identification of course facilitator (1 =\r\ninstructor)\r\nUID = Dummy variable for whether participants listed\r\nnetworking and collaboration with others as one of their course goals on\r\nthe registration form\r\nexpert = Identifier of “expert panelists” invited to\r\ncourse to share experience through recorded Q&A\r\nFacilitator = Identification of course facilitator (1\r\n= instructor)\r\nrole1 = Professional role (eg, teacher, librarian,\r\nadministrator)\r\nexperience2 = Years of experience as an educator\r\ngrades = Works with elementary, middle, and/or high\r\nschool students\r\ngeoup = Initial assignment of discussion group\r\n2b. Create\r\nNetwork Object and convert to graph object\r\n\r\n\r\nShow code\r\n\r\ndlt1_network <- tbl_graph(edges = dlt1_ties,\r\n                          nodes = dlt1_actors,\r\n                          node_key = \"uid\",\r\n                          directed = TRUE)\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\n# create dlt2\r\n\r\ndlt2_ties <- read_csv(\"data/dlt2-edges.csv\", \r\n                      col_types = cols(Sender = col_character(), \r\n                                       Reciever = col_character(), \r\n                                       `Category` = col_skip(), \r\n                                       `CommentID` = col_character(), \r\n                                       `DiscussionID` = col_character())) |>\r\n  clean_names()\r\n\r\ndlt2_actors <- read_csv(\"data/dlt2-nodes.csv\", \r\n                      col_types = cols(uid = col_character(), \r\n                                       facilitator = col_character(), \r\n                                       `expert` = col_character(), \r\n                                       `connect` = col_character())) |>\r\n  clean_names()\r\n\r\ndlt2_network <- tbl_graph(edges = dlt2_ties,\r\n                          nodes = dlt2_actors,\r\n                          node_key = \"uid\",\r\n                          directed = TRUE)\r\n\r\n\r\n\r\nInspect the networks\r\n\r\n\r\nShow code\r\n\r\ndlt1_network\r\n\r\n\r\n# A tbl_graph: 445 nodes and 2529 edges\r\n#\r\n# A directed multigraph with 4 components\r\n#\r\n# Node Data: 445 x 13 (active)\r\n  uid   facilitator role1 experience experience2 grades location\r\n  <chr> <chr>       <chr>      <dbl> <chr>       <chr>  <chr>   \r\n1 1     0           libm~          1 6 to 10     secon~ VA      \r\n2 2     0           clas~          1 6 to 10     secon~ FL      \r\n3 3     0           dist~          2 11 to 20    gener~ PA      \r\n4 4     0           clas~          2 11 to 20    middle NC      \r\n5 5     0           othe~          3 20+         gener~ AL      \r\n6 6     0           clas~          1 4 to 5      gener~ AL      \r\n# ... with 439 more rows, and 6 more variables: region <chr>,\r\n#   country <chr>, group <chr>, gender <chr>, expert <chr>,\r\n#   connect <chr>\r\n#\r\n# Edge Data: 2,529 x 9\r\n   from    to timestamp discussion_title discussion_cate~\r\n  <int> <int> <chr>     <chr>            <chr>           \r\n1   360   444 4/4/13 1~ Most important ~ Group N         \r\n2   356   444 4/4/13 1~ Most important ~ Group D-L       \r\n3   356   444 4/4/13 1~ DLT Resources—C~ Group D-L       \r\n# ... with 2,526 more rows, and 4 more variables:\r\n#   parent_category <chr>, discussion_identifier <chr>,\r\n#   comment_id <chr>, discussion_id <chr>\r\n\r\nShow code\r\n\r\ndlt2_network\r\n\r\n\r\n# A tbl_graph: 492 nodes and 2584 edges\r\n#\r\n# A directed multigraph with 69 components\r\n#\r\n# Node Data: 492 x 13 (active)\r\n  uid   facilitator role  experience2 experience grades location\r\n  <chr> <chr>       <chr>       <dbl>      <dbl> <chr>  <chr>   \r\n1 1     0           curr~           2         17 gener~ IN      \r\n2 2     0           other           1          3 prima~ NC      \r\n3 3     0           inst~           2         20 gener~ US      \r\n4 4     0           inst~           2         12 middle TX      \r\n5 5     0           other           1          0 gener~ CAN     \r\n6 6     0           inst~           1          7 gener~ CAN     \r\n# ... with 486 more rows, and 6 more variables: region <chr>,\r\n#   country <chr>, group <chr>, gender <chr>, expert <chr>,\r\n#   connect <chr>\r\n#\r\n# Edge Data: 2,584 x 8\r\n   from    to timestamp title parent description comment_id\r\n  <int> <int> <chr>     <chr> <chr>  <chr>       <chr>     \r\n1    37   461 9/27/13   Gree~ Group~ Please int~ 3         \r\n2   434   434 9/27/13   Sher~ Group~ Please int~ 4         \r\n3   302   434 9/27/13   Sher~ Group~ Please int~ 5         \r\n# ... with 2,581 more rows, and 1 more variable: discussion_id <chr>\r\n\r\n3. Explore\r\nLet’s first take a quick look at the summaries for “weak” components\r\nin our network: There are 4 components as we discovered above, 1\r\ncomponent has 442 members and three (our isolates) have only 1\r\nmember.\r\n\r\n\r\nShow code\r\n\r\ncomponents(dlt1_network, mode = c(\"weak\"))\r\n\r\n\r\n$membership\r\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n [33] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n [65] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n [97] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[129] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[161] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[193] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[225] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[257] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[289] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[321] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[353] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[385] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n[417] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 4 1 1\r\n\r\n$csize\r\n[1] 442   1   1   1\r\n\r\n$no\r\n[1] 4\r\n\r\nNow let’s inspect the strong components: WOW, you’ll see that we have\r\na total of 209 distinct components!\r\n\r\n\r\nShow code\r\n\r\ncomponents(dlt1_network, mode = c(\"strong\"))\r\n\r\n\r\n$membership\r\n  [1] 194 194 194 194 194 194 194 194 194 194 194 194 194 194 194 194\r\n [17] 194 193 194 194 203 194 209 194 194 194 194 192 194 194 191 194\r\n [33] 194 194 194 194 194 194 194 190 194 194 194 194 194 194 189 194\r\n [49] 194 194 194 194 194 194 188 194 194 194 194 194 194 194 194 194\r\n [65] 194 194 194 194 194 194 194 194 187 194 194 194 194 194 186 194\r\n [81] 194 194 194 208 194 185 194 194 184 194 194 194 183 194 181 180\r\n [97] 178 194 194 194 194 177 194 194 194 194 194 176 194 194 175 194\r\n[113] 194 194 194 194 194 194 194 174 194 194 169 168 167 166 165 194\r\n[129] 194 164 194 194 194 163 162 194 194 194 161 159 194 194 158 194\r\n[145] 173 182 157 156 155 172 171 194 206 194 194 194 194 194 194 154\r\n[161] 194 194 194 153 194 152 194 151 150 194 149 194 194 148 202 194\r\n[177] 194 194 147 146 194 201 194 194 194 145 195 194 198 194 194 194\r\n[193] 194 194 194 144 194 194 194 194 194 143 194 142 194 194 194 194\r\n[209] 194 141 194 194 140 139 138 194 194 194 194 137 194 194 194 136\r\n[225] 135 194 194 134 133 131 130 129 128 204 194 127 126 125 160 124\r\n[241] 123 122 194 121 119 194 194 194 194 194 194 194 194 194 118 194\r\n[257] 194 179 117 115 116 194 120 114 194 194 113 194 112 194 194 194\r\n[273] 199 111 194 194 194 110 194 109 194 108 106 107 194 200 194 105\r\n[289] 104 103 102 194 194 101 194 100  99  98  97 194 194 194 194  96\r\n[305] 194 197 194 207  95 194  94  93  92  91  90  89 194 194 194  88\r\n[321] 194 194 194 205 194  87  86  85 194 170 194  84  83 196 194 194\r\n[337] 194 194 194 194 194 194 194 132 194 194 194  82  81 194 194  80\r\n[353]  79  78 194 194  77 194  76  75 194  74  73  72  71  70  69  68\r\n[369]  67  66  65  64  63  62  61  60  59  58  57  56  55  54  53  52\r\n[385]  51  50  49  48  47  46  45  44  43  42  41  40  39  38  37  36\r\n[401]  35  34  33  32  31  30  29  28  27  26  25  24 194  23  22  21\r\n[417]  20  19  18  17  16 194  15  14  13  12  11  10   9   8   7 194\r\n[433] 194 194   6   5 194 194 194   4   3   2   1 194 194\r\n\r\n$csize\r\n  [1]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n [17]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n [33]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n [49]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n [65]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n [81]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n [97]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n[113]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n[129]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n[145]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n[161]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n[177]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n[193]   1 237   1   1   1   1   1   1   1   1   1   1   1   1   1   1\r\n[209]   1\r\n\r\n$no\r\n[1] 209\r\n\r\nIf we wanted to illustrate this with a sociogram, we could create a\r\nnew edge variable using the same activate() and\r\nmutate() functions and filter() our edges so\r\nour graph only contains reciprocated ties, like so:\r\n\r\n\r\nShow code\r\n\r\ndlt1_network |>\r\n  activate(edges) |>\r\n  mutate( reciprocated = edge_is_mutual()) |> \r\n  filter(reciprocated == TRUE) |>\r\n  autograph()\r\n\r\n\r\n\r\n\r\nOr we could filter out all isolates in our strong component network\r\nentirely using the same activate() and\r\nfilter() functions:\r\n\r\n\r\nShow code\r\n\r\ndlt1_network <- dlt1_network |>\r\n  activate(nodes) |>\r\n  mutate(strong_component = group_components(type = \"strong\"))\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\ndlt1_network |>\r\n  activate(nodes) |>\r\n  filter(strong_component == 1) |>\r\n  autograph()\r\n\r\n\r\n\r\n\r\nCompositional and Variance Measures To quickly\r\ncalculate summary statistics for our nodes, including compositional and\r\nvariance measures for our egocentric measures, we can use the\r\nskim() function from the {skimr} package to take a quick\r\nlook at the variables in our node list:\r\n\r\n\r\nShow code\r\n\r\ndlt1_network |> \r\n  as_tibble() |>\r\n  skim()\r\n\r\n\r\nTable 1: Data summary\r\nName\r\nas_tibble(dlt1_network)\r\nNumber of rows\r\n445\r\nNumber of columns\r\n14\r\n_______________________\r\n\r\nColumn type frequency:\r\n\r\ncharacter\r\n12\r\nnumeric\r\n2\r\n________________________\r\n\r\nGroup variables\r\nNone\r\nVariable type: character\r\nskim_variable\r\nn_missing\r\ncomplete_rate\r\nmin\r\nmax\r\nempty\r\nn_unique\r\nwhitespace\r\nuid\r\n0\r\n1\r\n1\r\n3\r\n0\r\n445\r\n0\r\nfacilitator\r\n0\r\n1\r\n1\r\n1\r\n0\r\n2\r\n0\r\nrole1\r\n0\r\n1\r\n4\r\n18\r\n0\r\n13\r\n0\r\nexperience2\r\n0\r\n1\r\n3\r\n8\r\n0\r\n6\r\n0\r\ngrades\r\n0\r\n1\r\n4\r\n10\r\n0\r\n8\r\n0\r\nlocation\r\n0\r\n1\r\n2\r\n4\r\n0\r\n62\r\n0\r\nregion\r\n0\r\n1\r\n4\r\n13\r\n0\r\n6\r\n0\r\ncountry\r\n0\r\n1\r\n2\r\n4\r\n0\r\n21\r\n0\r\ngroup\r\n0\r\n1\r\n1\r\n4\r\n0\r\n7\r\n0\r\ngender\r\n0\r\n1\r\n4\r\n6\r\n0\r\n3\r\n0\r\nexpert\r\n0\r\n1\r\n1\r\n4\r\n0\r\n3\r\n0\r\nconnect\r\n0\r\n1\r\n1\r\n4\r\n0\r\n3\r\n0\r\nVariable type: numeric\r\nskim_variable\r\nn_missing\r\ncomplete_rate\r\nmean\r\nsd\r\np0\r\np25\r\np50\r\np75\r\np100\r\nhist\r\nexperience\r\n0\r\n1\r\n2.13\r\n0.80\r\n1\r\n1\r\n2\r\n3\r\n3\r\n▆▁▇▁▇\r\nstrong_component\r\n0\r\n1\r\n49.84\r\n66.43\r\n1\r\n1\r\n1\r\n98\r\n209\r\n▇▁▁▁▁\r\n\r\nCreate in a tibble and convert our node to a table and\r\narrange() in descending order by size to make\r\nit easier to see the range in values of our network:\r\n\r\n\r\nShow code\r\n\r\ndlt1_network <- dlt1_network |>\r\n  activate(nodes) |>\r\n  mutate(size = local_size())\r\n\r\ndlt1_network |> \r\n  as_tibble() |>\r\n  arrange(desc(size)) |> \r\n  select(uid, facilitator, size)\r\n\r\n\r\n# A tibble: 445 x 3\r\n   uid   facilitator  size\r\n   <chr> <chr>       <dbl>\r\n 1 444   1             295\r\n 2 445   1             160\r\n 3 44    0              61\r\n 4 11    0              51\r\n 5 7     0              42\r\n 6 30    0              42\r\n 7 19    0              39\r\n 8 60    0              39\r\n 9 36    0              37\r\n10 432   0              36\r\n# ... with 435 more rows\r\n\r\nlet’s select only MOOC-Ed participants who are located in the United\r\nStates and calculate compositional and variance measures for\r\nsize by educator’s role:\r\n\r\n\r\nShow code\r\n\r\ndlt1_network |> \r\n  as_tibble() |>\r\n  filter(country == \"US\") |>\r\n  group_by(role1) |>\r\n  select(size) |>\r\n  skim()\r\n\r\n\r\n(#tab:size_role)Data summary\r\nName\r\nselect(…)\r\nNumber of rows\r\n412\r\nNumber of columns\r\n2\r\n_______________________\r\n\r\nColumn type frequency:\r\n\r\nnumeric\r\n1\r\n________________________\r\n\r\nGroup variables\r\nrole1\r\nVariable type: numeric\r\nskim_variable\r\nrole1\r\nn_missing\r\ncomplete_rate\r\nmean\r\nsd\r\np0\r\np25\r\np50\r\np75\r\np100\r\nhist\r\nsize\r\nclassteaching\r\n0\r\n1\r\n8.97\r\n8.22\r\n2\r\n3.00\r\n6.0\r\n12.00\r\n39\r\n▇▂▁▁▁\r\nsize\r\ncurriculum\r\n0\r\n1\r\n7.70\r\n7.22\r\n2\r\n2.50\r\n5.0\r\n8.50\r\n24\r\n▇▁▁▁▂\r\nsize\r\ndistrictadmin\r\n0\r\n1\r\n5.50\r\n4.74\r\n1\r\n2.00\r\n3.5\r\n7.00\r\n22\r\n▇▂▁▁▁\r\nsize\r\ninstructionaltech\r\n0\r\n1\r\n7.46\r\n9.38\r\n1\r\n2.00\r\n4.0\r\n7.75\r\n61\r\n▇▁▁▁▁\r\nsize\r\nlibmedia\r\n0\r\n1\r\n9.91\r\n9.91\r\n1\r\n2.00\r\n6.0\r\n15.00\r\n33\r\n▇▂▁▁▁\r\nsize\r\nOperations\r\n0\r\n1\r\n3.00\r\nNA\r\n3\r\n3.00\r\n3.0\r\n3.00\r\n3\r\n▁▁▇▁▁\r\nsize\r\nother\r\n0\r\n1\r\n8.25\r\n8.10\r\n2\r\n2.00\r\n6.0\r\n12.25\r\n19\r\n▇▁▃▁▃\r\nsize\r\notheredprof\r\n0\r\n1\r\n18.95\r\n53.48\r\n2\r\n3.00\r\n4.0\r\n9.00\r\n295\r\n▇▁▁▁▁\r\nsize\r\nprofdev\r\n0\r\n1\r\n5.71\r\n4.44\r\n2\r\n2.00\r\n4.0\r\n7.50\r\n21\r\n▇▂▂▁▁\r\nsize\r\nschooladmin\r\n0\r\n1\r\n9.40\r\n9.10\r\n2\r\n3.25\r\n5.5\r\n13.50\r\n42\r\n▇▂▁▁▁\r\nsize\r\nspecialed\r\n0\r\n1\r\n12.00\r\n6.63\r\n2\r\n11.00\r\n11.0\r\n17.00\r\n19\r\n▃▁▇▁▇\r\nsize\r\ntechinfrastructure\r\n0\r\n1\r\n5.44\r\n3.22\r\n2\r\n3.00\r\n4.5\r\n7.00\r\n14\r\n▇▂▃▁▁\r\n\r\nFind degree Run the following create two new variables\r\nfor our nodes: in_dgree and out_degree. We’ll\r\nset the mode = argument in centrality_degree()\r\nfunction to \"in\" and \"out\" respectively.\r\n\r\n\r\nShow code\r\n\r\ndlt1_network <- dlt1_network |>\r\n  activate(nodes) |>\r\n  mutate(in_degree = centrality_degree(mode = \"in\"),\r\n         out_degree = centrality_degree(mode = \"out\"))\r\n  \r\ndlt1_network |> \r\n  as_tibble()\r\n\r\n\r\n# A tibble: 445 x 17\r\n   uid   facilitator role1      experience experience2 grades location\r\n   <chr> <chr>       <chr>           <dbl> <chr>       <chr>  <chr>   \r\n 1 1     0           libmedia            1 6 to 10     secon~ VA      \r\n 2 2     0           classteac~          1 6 to 10     secon~ FL      \r\n 3 3     0           districta~          2 11 to 20    gener~ PA      \r\n 4 4     0           classteac~          2 11 to 20    middle NC      \r\n 5 5     0           otheredpr~          3 20+         gener~ AL      \r\n 6 6     0           classteac~          1 4 to 5      gener~ AL      \r\n 7 7     0           instructi~          2 11 to 20    gener~ SD      \r\n 8 8     0           specialed           1 6 to 10     secon~ BE      \r\n 9 9     0           classteac~          1 6 to 10     middle NC      \r\n10 10    0           schooladm~          2 11 to 20    middle NC      \r\n# ... with 435 more rows, and 10 more variables: region <chr>,\r\n#   country <chr>, group <chr>, gender <chr>, expert <chr>,\r\n#   connect <chr>, strong_component <int>, size <dbl>,\r\n#   in_degree <dbl>, out_degree <dbl>\r\n\r\nUse the code chunk below to add a closeness and\r\nbetweenness variable to the nodes in our network\r\n\r\n\r\nShow code\r\n\r\ndlt1_undirected <-  to_undirected(dlt1_network)\r\n\r\nset.seed(123)\r\ndlt1_stats <- dlt1_undirected %>% \r\n  activate(nodes)%>%\r\n  mutate(community = as.factor(group_louvain())) %>%\r\n  mutate(degree_c = centrality_degree()) %>%\r\n  mutate(betweenness_c = centrality_betweenness(directed = FALSE ,normalized = TRUE)) %>%\r\n  mutate(closeness_c = centrality_closeness(normalized = TRUE))\r\n\r\n  \r\n\r\ndltl_stats_ego <- as.data.frame(dlt1_stats)  \r\ndltl_stats_ego\r\n\r\n\r\n    uid facilitator              role1 experience experience2\r\n1     1           0           libmedia          1     6 to 10\r\n2     2           0      classteaching          1     6 to 10\r\n3     3           0      districtadmin          2    11 to 20\r\n4     4           0      classteaching          2    11 to 20\r\n5     5           0        otheredprof          3         20+\r\n6     6           0      classteaching          1      4 to 5\r\n7     7           0  instructionaltech          2    11 to 20\r\n8     8           0          specialed          1     6 to 10\r\n9     9           0      classteaching          1     6 to 10\r\n10   10           0        schooladmin          2    11 to 20\r\n11   11           0              other          3         20+\r\n12   12           0      classteaching          3         20+\r\n13   13           0      classteaching          2    11 to 20\r\n14   14           0              other          1      0 to 3\r\n15   15           0        schooladmin          3         20+\r\n16   16           0        otheredprof          1      0 to 3\r\n17   17           0           libmedia          1      0 to 3\r\n18   18           0          specialed          1      4 to 5\r\n19   19           0        otheredprof          3         20+\r\n20   20           0      districtadmin          1      0 to 3\r\n21   21           0        otheredprof          1      0 to 3\r\n22   22           0        schooladmin          1     6 to 10\r\n23   23           0           libmedia          3         20+\r\n24   24           0  instructionaltech          2    11 to 20\r\n25   25           0  instructionaltech          2    11 to 20\r\n26   26           0        otheredprof          3         20+\r\n27   27           0        otheredprof          1      0 to 3\r\n28   28           0            profdev          3         20+\r\n29   29           0        schooladmin          2    11 to 20\r\n30   30           0        schooladmin          3         20+\r\n31   31           0      classteaching          1      4 to 5\r\n32   32           0            profdev          1     6 to 10\r\n33   33           0  instructionaltech          3         20+\r\n34   34           0         curriculum          3         20+\r\n35   35           0         curriculum          2    11 to 20\r\n36   36           0      classteaching          2    11 to 20\r\n37   37           0         curriculum          2    11 to 20\r\n38   38           0      classteaching          1     6 to 10\r\n39   39           0      classteaching          2    11 to 20\r\n40   40           0      districtadmin          3         20+\r\n41   41           0  instructionaltech          1     6 to 10\r\n42   42           0         curriculum          3         20+\r\n43   43           0            profdev          3         20+\r\n44   44           0  instructionaltech          2    11 to 20\r\n45   45           0      districtadmin          2    11 to 20\r\n46   46           0      classteaching          2    11 to 20\r\n47   47           0            profdev          3         20+\r\n48   48           0        schooladmin          3         20+\r\n49   49           0           libmedia          3         20+\r\n50   50           0        schooladmin          3         20+\r\n51   51           0        schooladmin          3         20+\r\n52   52           0        schooladmin          3         20+\r\n53   53           0  instructionaltech          3         20+\r\n54   54           0        otheredprof          2    11 to 20\r\n55   55           0  instructionaltech          1      4 to 5\r\n56   56           0      districtadmin          3         20+\r\n57   57           0         curriculum          3         20+\r\n58   58           0  instructionaltech          2    11 to 20\r\n59   59           0           libmedia          1      0 to 3\r\n60   60           0      classteaching          2    11 to 20\r\n61   61           0        schooladmin          3         20+\r\n62   62           0      classteaching          1      0 to 3\r\n63   63           0          specialed          1     6 to 10\r\n64   64           0  instructionaltech          2    11 to 20\r\n65   65           0           libmedia          2    11 to 20\r\n66   66           0  instructionaltech          2    11 to 20\r\n67   67           0           libmedia          3         20+\r\n68   68           0           libmedia          3         20+\r\n69   69           0            profdev          3         20+\r\n70   70           0        schooladmin          1     6 to 10\r\n71   71           0      districtadmin          3         20+\r\n72   72           0  instructionaltech          2    11 to 20\r\n73   73           0      districtadmin          3         20+\r\n74   74           0        schooladmin          3         20+\r\n75   75           0      classteaching          3         20+\r\n76   76           0         curriculum          3         20+\r\n77   77           0            profdev          2    11 to 20\r\n78   78           0        schooladmin          3         20+\r\n79   79           0            profdev          1      4 to 5\r\n80   80           0      classteaching          2    11 to 20\r\n81   81           0      classteaching          3         20+\r\n82   82           0      classteaching          1     6 to 10\r\n83   83           0      classteaching          3         20+\r\n84   84           0         curriculum          1     6 to 10\r\n85   85           0      classteaching          1     6 to 10\r\n86   86           0        schooladmin          3         20+\r\n87   87           0           libmedia          2    11 to 20\r\n88   88           0      classteaching          1      0 to 3\r\n89   89           0            profdev          3         20+\r\n90   90           0        otheredprof          3         20+\r\n91   91           0  instructionaltech          2    11 to 20\r\n92   92           0         curriculum          3         20+\r\n93   93           0      classteaching          1     6 to 10\r\n94   94           0      classteaching          1     6 to 10\r\n95   95           0  instructionaltech          1     6 to 10\r\n96   96           0  instructionaltech          2    11 to 20\r\n97   97           0           libmedia          1     6 to 10\r\n98   98           0      classteaching          2    11 to 20\r\n99   99           0  instructionaltech          3         20+\r\n100 100           0  instructionaltech          2    11 to 20\r\n101 101           0  instructionaltech          1      4 to 5\r\n102 102           0      classteaching          3         20+\r\n103 103           0      classteaching          2    11 to 20\r\n104 104           0      classteaching          3         20+\r\n105 105           0 techinfrastructure          2    11 to 20\r\n106 106           0      districtadmin          3         20+\r\n107 107           0  instructionaltech          2    11 to 20\r\n108 108           0      classteaching          1      4 to 5\r\n109 109           0  instructionaltech          3         20+\r\n110 110           0  instructionaltech          1      4 to 5\r\n111 111           0      districtadmin          2    11 to 20\r\n112 112           0      districtadmin          2    11 to 20\r\n113 113           0        schooladmin          2    11 to 20\r\n114 114           0            profdev          2    11 to 20\r\n115 115           0        schooladmin          2    11 to 20\r\n116 116           0      classteaching          3         20+\r\n117 117           0         curriculum          1     6 to 10\r\n118 118           0      classteaching          1     6 to 10\r\n119 119           0           libmedia          2    11 to 20\r\n120 120           0  instructionaltech          3         20+\r\n121 121           0  instructionaltech          2    11 to 20\r\n122 122           0        otheredprof          3         20+\r\n123 123           0         curriculum          2    11 to 20\r\n124 124           0  instructionaltech          2    11 to 20\r\n125 125           0  instructionaltech          3         20+\r\n126 126           0 techinfrastructure          2    11 to 20\r\n127 127           0 techinfrastructure          2    11 to 20\r\n128 128           0         curriculum          1     6 to 10\r\n129 129           0  instructionaltech          2    11 to 20\r\n130 130           0        otheredprof          3         20+\r\n131 131           0            profdev          2    11 to 20\r\n132 132           0  instructionaltech          1     6 to 10\r\n133 133           0 techinfrastructure          3         20+\r\n134 134           0      classteaching          1     6 to 10\r\n135 135           0        otheredprof          1      0 to 3\r\n136 136           0      districtadmin          3         20+\r\n137 137           0      districtadmin          3         20+\r\n138 138           0            profdev          2    11 to 20\r\n139 139           0  instructionaltech          2    11 to 20\r\n140 140           0        otheredprof          3         20+\r\n141 141           0  instructionaltech          3         20+\r\n142 142           0            profdev          2    11 to 20\r\n143 143           0  instructionaltech          2    11 to 20\r\n144 144           0      districtadmin          2    11 to 20\r\n145 145           0      classteaching          1     6 to 10\r\n146 146           0        otheredprof          1     6 to 10\r\n147 147           0      classteaching          2    11 to 20\r\n148 148           0      districtadmin          2         20+\r\n149 149           0  instructionaltech          1     6 to 10\r\n150 150           0            profdev          1     6 to 10\r\n151 151           0 techinfrastructure          2    11 to 20\r\n152 152           0        otheredprof          2    11 to 20\r\n153 153           0        schooladmin          1     6 to 10\r\n154 154           0  instructionaltech          3         20+\r\n155 155           0  instructionaltech          3         20+\r\n156 156           0        otheredprof          3         20+\r\n157 157           0      classteaching          1      4 to 5\r\n158 158           0           libmedia          3         20+\r\n159 159           0  instructionaltech          2    11 to 20\r\n160 160           0         curriculum          3         20+\r\n161 161           0  instructionaltech          3         20+\r\n162 162           0        schooladmin          3         20+\r\n163 163           0              other          1      0 to 3\r\n164 164           0        schooladmin          2    11 to 20\r\n165 165           0            profdev          3         20+\r\n166 166           0 techinfrastructure          1      0 to 3\r\n167 167           0  instructionaltech          3         20+\r\n168 168           0  instructionaltech          3         20+\r\n169 169           0  instructionaltech          3         20+\r\n170 170           0 techinfrastructure          1     6 to 10\r\n171 171           0      classteaching          2    11 to 20\r\n172 172           0        otheredprof          2    11 to 20\r\n173 173           0        schooladmin          2    11 to 20\r\n174 174           0        schooladmin          2    11 to 20\r\n175 175           0         curriculum          3         20+\r\n176 176           0 techinfrastructure          2    11 to 20\r\n177 177           0      districtadmin          2    11 to 20\r\n178 178           0      districtadmin          2    11 to 20\r\n179 179           0  instructionaltech          2    11 to 20\r\n180 180           0        otheredprof          3         20+\r\n181 181           0 techinfrastructure          1     6 to 10\r\n182 182           0        otheredprof          1     6 to 10\r\n183 183           0      districtadmin          2    11 to 20\r\n184 184           0      classteaching          1     6 to 10\r\n185 185           0      classteaching          2    11 to 20\r\n186 186           0 techinfrastructure          1      4 to 5\r\n187 187           0 techinfrastructure          2    11 to 20\r\n188 188           0      classteaching          3         20+\r\n189 189           0        schooladmin          3         20+\r\n190 190           0           libmedia          1      4 to 5\r\n191 191           0      classteaching          3         20+\r\n192 192           0      classteaching          3         20+\r\n193 193           0  instructionaltech          2    11 to 20\r\n194 194           0  instructionaltech          3         20+\r\n195 195           0      districtadmin          3         20+\r\n196 196           0        otheredprof          1      0 to 3\r\n197 197           0      districtadmin          3         20+\r\n198 198           0           libmedia          2    11 to 20\r\n199 199           0        schooladmin          3         20+\r\n200 200           0        schooladmin          2    11 to 20\r\n201 201           0      classteaching          1     6 to 10\r\n202 202           0  instructionaltech          2    11 to 20\r\n203 203           0            profdev          3         20+\r\n204 204           0  instructionaltech          2    11 to 20\r\n205 205           0        otheredprof          1      0 to 3\r\n206 206           0         curriculum          2    11 to 20\r\n207 207           0  instructionaltech          1      0 to 3\r\n208 208           0        otheredprof          2    11 to 20\r\n209 209           0        schooladmin          3         20+\r\n210 210           0         Operations          2     6 to 10\r\n211 211           0        otheredprof          2    11 to 20\r\n212 212           0        schooladmin          3         20+\r\n213 213           0  instructionaltech          2    11 to 20\r\n214 214           0            profdev          1     6 to 10\r\n215 215           0      classteaching          1     6 to 10\r\n216 216           0        schooladmin          3         20+\r\n217 217           0        otheredprof          3         20+\r\n218 218           0        otheredprof          1     6 to 10\r\n219 219           0         curriculum          3         20+\r\n220 220           0            profdev          3         20+\r\n221 221           0          specialed          1     6 to 10\r\n222 222           0        otheredprof          3         20+\r\n223 223           0         curriculum          2    11 to 20\r\n224 224           0  instructionaltech          3         20+\r\n225 225           0        otheredprof          3         20+\r\n226 226           0 techinfrastructure          3         20+\r\n227 227           0      classteaching          2    11 to 20\r\n228 228           0        otheredprof          1      0 to 3\r\n229 229           0  instructionaltech          2    11 to 20\r\n230 230           0      districtadmin          3         20+\r\n231 231           0      districtadmin          3         20+\r\n232 232           0           libmedia          3         20+\r\n233 233           0        otheredprof          2    11 to 20\r\n234 234           0  instructionaltech          3         20+\r\n235 235           0            profdev          2    11 to 20\r\n236 236           0      classteaching          1     6 to 10\r\n237 237           0  instructionaltech          2    11 to 20\r\n238 238           0  instructionaltech          1      4 to 5\r\n239 239           0  instructionaltech          1     6 to 10\r\n240 240           0        schooladmin          1     6 to 10\r\n241 241           0      classteaching          1      4 to 5\r\n242 242           0        otheredprof          1      4 to 5\r\n243 243           0  instructionaltech          1     6 to 10\r\n244 244           0            profdev          3         20+\r\n245 245           0            profdev          1      0 to 3\r\n246 246           0  instructionaltech          3         20+\r\n247 247           0      classteaching          2    11 to 20\r\n248 248           0 techinfrastructure          1      0 to 3\r\n249 249           0  instructionaltech          2    11 to 20\r\n250 250           0  instructionaltech          2    11 to 20\r\n251 251           0  instructionaltech          2    11 to 20\r\n252 252           0        schooladmin          2    11 to 20\r\n253 253           0  instructionaltech          3         20+\r\n254 254           0      classteaching          3         20+\r\n255 255           0  instructionaltech          2    11 to 20\r\n256 256           0  instructionaltech          3         20+\r\n257 257           0        otheredprof          3         20+\r\n258 258           0        schooladmin          3         20+\r\n259 259           0      classteaching          3         20+\r\n260 260           0      classteaching          3         20+\r\n261 261           0  instructionaltech          2    11 to 20\r\n262 262           0      classteaching          3         20+\r\n263 263           0              other          2    11 to 20\r\n264 264           0            profdev          2    11 to 20\r\n265 265           0      districtadmin          3         20+\r\n266 266           0      classteaching          1     6 to 10\r\n267 267           0      districtadmin          3         20+\r\n268 268           0  instructionaltech          1     6 to 10\r\n269 269           0  instructionaltech          3         20+\r\n270 270           0      classteaching          1     6 to 10\r\n271 271           0        schooladmin          2    11 to 20\r\n272 272           0      classteaching          3         20+\r\n273 273           0  instructionaltech          3         20+\r\n274 274           0  instructionaltech          3         20+\r\n275 275           0 techinfrastructure          1      0 to 3\r\n276 276           0 techinfrastructure          3         20+\r\n277 277           0  instructionaltech          3         20+\r\n278 278           0        otheredprof          2    11 to 20\r\n279 279           0          specialed          3         20+\r\n280 280           0      districtadmin          3         20+\r\n281 281           0        schooladmin          3         20+\r\n282 282           0      classteaching          1      4 to 5\r\n283 283           0           libmedia          2    11 to 20\r\n284 284           0  instructionaltech          1     6 to 10\r\n285 285           0      classteaching          1      0 to 3\r\n286 286           0      districtadmin          3         20+\r\n287 287           0      districtadmin          1     6 to 10\r\n288 288           0      classteaching          1      4 to 5\r\n289 289           0        schooladmin          2    11 to 20\r\n290 290           0  instructionaltech          3         20+\r\n291 291           0  instructionaltech          1     6 to 10\r\n292 292           0      classteaching          1      0 to 3\r\n293 293           0  instructionaltech          3         20+\r\n294 294           0              other          3         20+\r\n295 295           0      classteaching          1     6 to 10\r\n296 296           0  instructionaltech          3         20+\r\n297 297           0        schooladmin          3         20+\r\n298 298           0  instructionaltech          3         20+\r\n299 299           0      districtadmin          3         20+\r\n300 300           0        schooladmin          2    11 to 20\r\n301 301           0           libmedia          2    11 to 20\r\n302 302           0      classteaching          3         20+\r\n303 303           0      classteaching          3         20+\r\n304 304           0  instructionaltech          1     6 to 10\r\n305 305           0  instructionaltech          3         20+\r\n306 306           0  instructionaltech          1     6 to 10\r\n307 307           0         curriculum          2    11 to 20\r\n308 308           0      classteaching          1      4 to 5\r\n309 309           0      classteaching          1      4 to 5\r\n310 310           0  instructionaltech          2    11 to 20\r\n311 311           0      districtadmin          2    11 to 20\r\n312 312           0      districtadmin          2    11 to 20\r\n313 313           0      classteaching          2    11 to 20\r\n314 314           0  instructionaltech          2    11 to 20\r\n315 315           0           libmedia          3         20+\r\n316 316           0      classteaching          3         20+\r\n317 317           0        otheredprof          3         20+\r\n318 318           0      classteaching          2    11 to 20\r\n319 319           0      districtadmin          2    11 to 20\r\n320 320           0      districtadmin          3         20+\r\n321 321           0        schooladmin          2    11 to 20\r\n322 322           0        schooladmin          1     6 to 10\r\n323 323           0      classteaching          1     6 to 10\r\n324 324           0        schooladmin          3         20+\r\n325 325           0      districtadmin          2    11 to 20\r\n326 326           0        otheredprof          3         20+\r\n327 327           0      classteaching          1     6 to 10\r\n328 328           0  instructionaltech          3         20+\r\n329 329           0 techinfrastructure          2    11 to 20\r\n330 330           0        otheredprof          3         20+\r\n331 331           0         curriculum          2    11 to 20\r\n332 332           0  instructionaltech          1     6 to 10\r\n333 333           0            profdev          1     6 to 10\r\n334 334           0        schooladmin          3         20+\r\n335 335           0  instructionaltech          3         20+\r\n336 336           0  instructionaltech          2    11 to 20\r\n337 337           0            profdev          3         20+\r\n338 338           0        otheredprof          3         20+\r\n339 339           0      classteaching          3         20+\r\n340 340           0      districtadmin          3         20+\r\n341 341           0      classteaching          3         20+\r\n342 342           0        schooladmin          3         20+\r\n343 343           0      classteaching          1      4 to 5\r\n344 344           0  instructionaltech          3         20+\r\n345 345           0  instructionaltech          3         20+\r\n346 346           0  instructionaltech          1     6 to 10\r\n347 347           0  instructionaltech          2    11 to 20\r\n348 348           0        schooladmin          3         20+\r\n349 349           0  instructionaltech          1      0 to 3\r\n350 350           0        schooladmin          2    11 to 20\r\n351 351           0  instructionaltech          2    11 to 20\r\n352 352           0      districtadmin          1     6 to 10\r\n353 353           0           libmedia          1     6 to 10\r\n354 354           0      classteaching          2    11 to 20\r\n355 355           0        schooladmin          2    11 to 20\r\n356 356           0  instructionaltech          2    11 to 20\r\n357 357           0      classteaching          3         20+\r\n358 358           0        schooladmin          3         20+\r\n359 359           0  instructionaltech          3         20+\r\n360 360           0  instructionaltech          1      0 to 3\r\n361 361           0            profdev          3         20+\r\n362 362           0  instructionaltech          2    11 to 20\r\n363 363           0         curriculum          3         20+\r\n364 364           0        otheredprof          3         20+\r\n365 365           0           libmedia          2    11 to 20\r\n366 366           0            profdev          2    11 to 20\r\n367 367           0            profdev          1      0 to 3\r\n368 368           0  instructionaltech          2    11 to 20\r\n369 369           0        otheredprof          3         20+\r\n370 370           0        otheredprof          3         20+\r\n371 371           0  instructionaltech          2    11 to 20\r\n372 372           0  instructionaltech          3         20+\r\n373 373           0  instructionaltech          1     6 to 10\r\n374 374           0      classteaching          2    11 to 20\r\n375 375           0  instructionaltech          3         20+\r\n376 376           0      classteaching          2    11 to 20\r\n377 377           0  instructionaltech          2    11 to 20\r\n378 378           0      districtadmin          1     6 to 10\r\n379 379           0        otheredprof          2    11 to 20\r\n380 380           0      districtadmin          3         20+\r\n381 381           0        schooladmin          2    11 to 20\r\n382 382           0         curriculum          2    11 to 20\r\n383 383           0      districtadmin          3         20+\r\n384 384           0  instructionaltech          2    11 to 20\r\n385 385           0      districtadmin          3         20+\r\n386 386           0  instructionaltech          2    11 to 20\r\n387 387           0  instructionaltech          3         20+\r\n388 388           0  instructionaltech          2    11 to 20\r\n389 389           0         curriculum          3         20+\r\n390 390           0           libmedia          1     6 to 10\r\n391 391           0         curriculum          3         20+\r\n392 392           0 techinfrastructure          3         20+\r\n393 393           0  instructionaltech          2    11 to 20\r\n394 394           0  instructionaltech          1     6 to 10\r\n395 395           0      districtadmin          2    11 to 20\r\n396 396           0         curriculum          2    11 to 20\r\n397 397           0        otheredprof          1      4 to 5\r\n398 398           0         curriculum          1     6 to 10\r\n399 399           0         curriculum          2    11 to 20\r\n400 400           0      classteaching          3         20+\r\n401 401           0 techinfrastructure          2    11 to 20\r\n402 402           0        schooladmin          2    11 to 20\r\n403 403           0  instructionaltech          3         20+\r\n404 404           0        otheredprof          1     6 to 10\r\n405 405           0      districtadmin          1      4 to 5\r\n406 406           0  instructionaltech          2    11 to 20\r\n407 407           0  instructionaltech          3         20+\r\n408 408           0 techinfrastructure          3         20+\r\n409 409           0  instructionaltech          1     6 to 10\r\n410 410           0         curriculum          1      4 to 5\r\n411 411           0  instructionaltech          3         20+\r\n412 412           0          specialed          1     6 to 10\r\n413 413           0  instructionaltech          3         20+\r\n414 414           0  instructionaltech          2    11 to 20\r\n415 415           0            profdev          3         20+\r\n416 416           0           libmedia          2    11 to 20\r\n417 417           0      classteaching          2    11 to 20\r\n418 418           0  instructionaltech          2    11 to 20\r\n419 419           0      classteaching          3         20+\r\n420 420           0      districtadmin          2    11 to 20\r\n421 421           0  instructionaltech          2    11 to 20\r\n422 422           0            profdev          2    11 to 20\r\n423 423           0         curriculum          3         20+\r\n424 424           0           libmedia          2    11 to 20\r\n425 425           0      districtadmin          3         20+\r\n426 426           0      districtadmin          1     6 to 10\r\n427 427           0           libmedia          3         20+\r\n428 428           0        otheredprof          3         20+\r\n429 429           0  instructionaltech          1      0 to 3\r\n430 430           0  instructionaltech          2    11 to 20\r\n431 431           0      classteaching          2    11 to 20\r\n432 432           0  instructionaltech          1     6 to 10\r\n433 433           0         curriculum          3         20+\r\n434 434           0  instructionaltech          1         20+\r\n435 435           0  instructionaltech          1         20+\r\n436 436           0            profdev          2    11 to 20\r\n437 437           0  instructionaltech          1         20+\r\n438 438           0  instructionaltech          1    11 to 20\r\n439 439           0               NULL          1        NULL\r\n440 440           0            profdev          2    11 to 20\r\n441 441           0           libmedia          3         20+\r\n442 442           0      districtadmin          3         20+\r\n443 443           0  instructionaltech          2    11 to 20\r\n444 444           1        otheredprof          3         20+\r\n445 445           1        otheredprof          3         20+\r\n        grades location        region country group gender expert\r\n1    secondary       VA         South      US    UZ female      0\r\n2    secondary       FL         South      US    DL female      0\r\n3   generalist       PA     Northeast      US    OT female      0\r\n4       middle       NC         South      US     N female      0\r\n5   generalist       AL         South      US    AC female      0\r\n6   generalist       AL         South      US    AC female      0\r\n7   generalist       SD       Midwest      US    OT female      0\r\n8    secondary       BE International      BE    AC female      0\r\n9       middle       NC         South      US     N female      0\r\n10      middle       NC         South      US     N   male      0\r\n11  generalist       KG International      KG    DL female      0\r\n12   secondary       AL         South      US    AC female      0\r\n13      middle       CA          West      US    AC female      0\r\n14      middle       NC         South      US     N female      0\r\n15   secondary       WV         South      US    UZ female      0\r\n16      middle       ES International      ES    DL   male      0\r\n17     primary       NC         South      US     N female      0\r\n18      middle       FL         South      US    DL female      0\r\n19     college       AU International      AU    AC   male      0\r\n20  generalist       MI       Midwest      US     M   male      0\r\n21  generalist       NC         South      US     N female      0\r\n22   secondary       FL         South      US    DL   male      0\r\n23      middle       NC         South      US     N female      0\r\n24  generalist       IN       Midwest      US    DL female      0\r\n25  generalist       IL       Midwest      US    DL female      0\r\n26     primary       TX         South      US    OT female      0\r\n27  generalist       IA       Midwest      US    DL female      0\r\n28      middle       ME     Northeast      US     M female      1\r\n29  generalist       AL         South      US    AC female      0\r\n30   secondary       NC         South      US     N female      0\r\n31  generalist       CA          West      US    AC   male      0\r\n32     primary       CA          West      US    AC female      0\r\n33  generalist       CA          West      US    AC   male      0\r\n34     primary       AL         South      US    AC female      0\r\n35     college       SD       Midwest      US    OT   male      0\r\n36   secondary       UT          West      US    UZ female      0\r\n37   secondary       CA          West      US    AC   male      0\r\n38   secondary       ME     Northeast      US     M   male      0\r\n39   secondary       NC         South      US     N female      0\r\n40  generalist       AZ          West      US    AC female      0\r\n41  generalist       PA     Northeast      US    OT   male      1\r\n42  generalist       PA     Northeast      US    OT   male      1\r\n43   secondary       MA     Northeast      US     M female      1\r\n44      middle       NC         South      US     N   male      0\r\n45  generalist       NM          West      US     N female      0\r\n46     primary       NH     Northeast      US     N female      0\r\n47  generalist       MA     Northeast      US     M female      1\r\n48      middle       KS       Midwest      US    DL   male      1\r\n49  generalist       ME     Northeast      US     M female      0\r\n50     primary       VA         South      US    UZ female      0\r\n51     primary       VA         South      US    UZ   male      0\r\n52     primary       NH     Northeast      US     N   male      0\r\n53     primary       MA     Northeast      US     M female      0\r\n54     primary       VT     Northeast      US    UZ female      0\r\n55  generalist       NC         South      US     N female      0\r\n56  generalist       PA     Northeast      US    OT female      1\r\n57  generalist       KS       Midwest      US    DL female      0\r\n58  generalist       NG International      NG     N female      0\r\n59     primary       PA     Northeast      US    OT female      0\r\n60      middle       NC         South      US     N female      0\r\n61     primary       NC         South      US     N female      0\r\n62  generalist       NJ     Northeast      US     N female      0\r\n63   secondary       WV         South      US    UZ female      0\r\n64  generalist       NH     Northeast      US     N female      0\r\n65   secondary       NH     Northeast      US     N female      0\r\n66   secondary       NC         South      US     N female      0\r\n67     primary       NC         South      US     N female      0\r\n68  generalist      ISL International      IL    DL female      0\r\n69  generalist       NJ     Northeast      US     N female      0\r\n70      middle       NC         South      US     N female      0\r\n71  generalist       WA          West      US    UZ female      0\r\n72     primary       VA         South      US    UZ female      0\r\n73     primary       SC         South      US    OT female      0\r\n74  generalist       VT     Northeast      US    UZ female      0\r\n75   secondary       VT     Northeast      US    UZ female      0\r\n76  generalist       KS       Midwest      US    DL female      0\r\n77  generalist       VA         South      US    UZ female      0\r\n78   secondary       TH International      TH    OT female      0\r\n79  generalist       MN       Midwest      US     M female      0\r\n80      middle       VA         South      US    UZ female      0\r\n81     primary       WA          West      US    UZ female      0\r\n82      middle       VA         South      US    UZ female      0\r\n83     primary       ME     Northeast      US     M female      0\r\n84  generalist       PA     Northeast      US    OT female      0\r\n85  generalist       NC         South      US     N female      0\r\n86      middle       NH     Northeast      US     N   male      0\r\n87  generalist       NH     Northeast      US     N female      0\r\n88   secondary       MO       Midwest      US     M   male      0\r\n89  generalist       MI       Midwest      US     M female      0\r\n90  generalist       MI       Midwest      US     M female      0\r\n91   secondary       MN       Midwest      US     M   male      0\r\n92     primary       KS       Midwest      US    DL   male      0\r\n93   secondary       AL         South      US    AC   male      0\r\n94      middle       CA          West      US    AC   male      0\r\n95   secondary       CT     Northeast      US    AC female      0\r\n96   secondary       NC         South      US     N female      0\r\n97     primary       AL         South      US    AC female      0\r\n98     primary       NC         South      US     N female      0\r\n99  generalist       CA          West      US    AC   male      0\r\n100 generalist       NC         South      US     N   male      0\r\n101    primary       NC         South      US     N female      0\r\n102 generalist       RI     Northeast      US    OT female      0\r\n103     middle       RI     Northeast      US    OT   male      0\r\n104     middle       ME     Northeast      US     M female      0\r\n105    primary       NC         South      US     N   male      0\r\n106 generalist       NC         South      US     N   male      0\r\n107 generalist       NC         South      US     N female      0\r\n108  secondary       RI     Northeast      US    OT female      0\r\n109    primary       TX         South      US    OT female      0\r\n110     middle       NC         South      US     N   male      0\r\n111 generalist       SC         South      US    OT female      0\r\n112 generalist       WI       Midwest      US    UZ   male      0\r\n113  secondary       CA          West      US    AC female      0\r\n114  secondary       ZA International      ZA    UZ   male      0\r\n115     middle       PA     Northeast      US    OT female      0\r\n116    college       SD       Midwest      US    OT female      0\r\n117 generalist       SC         South      US    OT female      0\r\n118    college       ZA International      ZA    UZ   male      0\r\n119     middle       TX         South      US    OT female      0\r\n120 generalist       OH       Midwest      US    OT female      0\r\n121 generalist       VA         South      US    UZ   male      0\r\n122 generalist       AL         South      US    AC female      0\r\n123 generalist       TX         South      US    OT female      0\r\n124 generalist       SC         South      US    OT   male      0\r\n125 generalist       PA     Northeast      US    OT female      0\r\n126 generalist       PA     Northeast      US    OT   male      0\r\n127 generalist       AL         South      US    AC   male      0\r\n128    college       RU International      RU    OT female      0\r\n129    primary       OH       Midwest      US    OT female      0\r\n130 generalist       RI     Northeast      US    OT female      0\r\n131 generalist       NC         South      US     N female      0\r\n132 generalist       MI       Midwest      US     M female      0\r\n133  secondary       NC         South      US     N   male      0\r\n134  secondary       NC         South      US     N   male      0\r\n135 generalist       TX         South      US    OT female      0\r\n136 generalist       RI     Northeast      US    OT   male      0\r\n137 generalist       OR          West      US    OT   male      0\r\n138 generalist       VT     Northeast      US    UZ female      0\r\n139 generalist       VA         South      US    UZ female      0\r\n140 generalist       GB International      GB    DL female      0\r\n141  secondary       WA          West      US    UZ female      0\r\n142 generalist       AL         South      US    AC female      0\r\n143 generalist       NJ     Northeast      US     N female      0\r\n144 generalist       VA         South      US    UZ   male      0\r\n145     middle       OH       Midwest      US    OT female      0\r\n146  secondary       CA          West      US    AC female      0\r\n147  secondary       ME     Northeast      US     M female      0\r\n148 generalist       TX         South      US    OT female      1\r\n149 generalist       OH       Midwest      US    OT   male      0\r\n150 generalist       TX         South      US    OT   male      0\r\n151 generalist       RI     Northeast      US    OT   male      0\r\n152 generalist       VT     Northeast      US    UZ   male      0\r\n153  secondary       WY          West      US    UZ   male      0\r\n154  secondary       MN       Midwest      US     M female      0\r\n155 generalist       VA         South      US    UZ female      0\r\n156    primary       ME     Northeast      US     M female      0\r\n157     middle       AL         South      US    AC   male      0\r\n158     middle       WI       Midwest      US    UZ female      0\r\n159  secondary       VT     Northeast      US    UZ   male      0\r\n160 generalist       WI       Midwest      US    UZ female      0\r\n161    primary       NC         South      US     N female      0\r\n162 generalist       NC         South      US     N female      0\r\n163 generalist       NH     Northeast      US     N   male      0\r\n164  secondary       TX         South      US    OT   male      0\r\n165 generalist       RI     Northeast      US    OT female      0\r\n166 generalist       RI     Northeast      US    OT female      0\r\n167 generalist       DC         South      US    DL   male      0\r\n168 generalist       IA       Midwest      US    DL female      0\r\n169 generalist       LA     Northeast      US    DL female      0\r\n170 generalist       IL       Midwest      US    DL   male      0\r\n171 generalist       IN       Midwest      US    DL   male      0\r\n172    college       JM International      JM    DL female      0\r\n173  secondary       AK          West      US    AC   male      0\r\n174  secondary      CAN International      CA    AC   male      0\r\n175 generalist       VT     Northeast      US    UZ female      0\r\n176 generalist       VT     Northeast      US    UZ   male      0\r\n177 generalist       NJ     Northeast      US     N female      1\r\n178  secondary       MN       Midwest      US     M   male      0\r\n179 generalist       AL         South      US    AC   male      0\r\n180    college       AU International      AU    AC   male      0\r\n181 generalist       OR          West      US    OT female      0\r\n182 generalist       VA         South      US    UZ female      0\r\n183 generalist       AL         South      US    AC   male      0\r\n184  secondary       NH     Northeast      US     N   male      0\r\n185  secondary       VA         South      US    UZ female      0\r\n186  secondary       IL       Midwest      US    DL female      0\r\n187 generalist       CA          West      US    AC   male      0\r\n188  secondary       PA     Northeast      US    OT   male      0\r\n189     middle      CAN International      CA    AC female      0\r\n190     middle      CAN International      CA    AC female      0\r\n191     middle       BR International      BR    AC female      0\r\n192     middle       ME     Northeast      US     M female      0\r\n193 generalist       NY     Northeast      US     N female      0\r\n194 generalist       NC         South      US     N female      0\r\n195 generalist       NC         South      US     N female      0\r\n196  secondary       DC         South      US    DL female      0\r\n197 generalist       AZ          West      US    AC female      1\r\n198    primary       VA         South      US    UZ female      0\r\n199     middle       NJ     Northeast      US     N female      0\r\n200     middle       OH       Midwest      US    OT female      0\r\n201     middle       ME     Northeast      US     M female      0\r\n202    primary       VA         South      US    UZ female      0\r\n203 generalist       IA       Midwest      US    DL female      0\r\n204 generalist       WY          West      US    UZ female      0\r\n205 generalist       AL         South      US    AC female      0\r\n206 generalist       MT          West      US     M   male      0\r\n207  secondary       NC         South      US     N   male      0\r\n208 generalist       NJ     Northeast      US     N   male      0\r\n209  secondary       WI       Midwest      US    UZ   male      0\r\n210 generalist       RI     Northeast      US    OT   male      1\r\n211 generalist       DC         South      US    DL   male      1\r\n212  secondary       NH     Northeast      US     N   male      0\r\n213 generalist       NY     Northeast      US     N female      0\r\n214     middle       ME     Northeast      US     M female      0\r\n215  secondary       ME     Northeast      US     M female      0\r\n216     middle       NC         South      US     N female      0\r\n217 generalist       CA          West      US    AC   male      0\r\n218 generalist       DC         South      US    DL   male      0\r\n219  secondary       AL         South      US    AC female      0\r\n220 generalist       OR          West      US    OT female      0\r\n221  secondary       NY     Northeast      US     N female      0\r\n222  secondary       CT     Northeast      US    AC   male      0\r\n223 generalist       AZ          West      US    AC   male      0\r\n224 generalist       OK       Midwest      US    OT female      0\r\n225 generalist       AL         South      US    AC female      0\r\n226 generalist       ME     Northeast      US     M   male      0\r\n227     middle       ME     Northeast      US     M female      0\r\n228 generalist       AL         South      US    AC   male      1\r\n229    primary      CAN International      CA    AC   male      0\r\n230 generalist       SC         South      US    OT female      0\r\n231 generalist       VA         South      US    UZ female      0\r\n232  secondary       WV         South      US    UZ female      0\r\n233 generalist       FL         South      US    DL female      0\r\n234 generalist       IA       Midwest      US    DL female      0\r\n235 generalist       FL         South      US    DL female      0\r\n236    primary       IN       Midwest      US    DL female      0\r\n237     middle       ID          West      US    DL   male      0\r\n238 generalist       KS       Midwest      US    DL   male      0\r\n239 generalist       ID          West      US    DL   male      0\r\n240  secondary       LA         South      US    DL female      0\r\n241 generalist      DEN International      DE    DL female      0\r\n242    college       JM International      JM    DL female      0\r\n243  secondary       IL       Midwest      US    DL   male      0\r\n244 generalist       DC         South      US    DL female      0\r\n245 generalist       FL         South      US    DL female      0\r\n246    primary       WI       Midwest      US    UZ female      0\r\n247  secondary       MI       Midwest      US     M   male      0\r\n248 generalist       IL       Midwest      US    DL   male      0\r\n249 generalist       MO       Midwest      US     M female      0\r\n250 generalist       NC         South      US     N female      0\r\n251     middle       CO          West      US    AC   male      0\r\n252  secondary       NC         South      US     N   male      0\r\n253 generalist       MA     Northeast      US     M female      0\r\n254    primary       MN       Midwest      US     M female      0\r\n255 generalist       ME     Northeast      US     M female      0\r\n256 generalist       ME     Northeast      US     M female      0\r\n257 generalist       CA          West      US    AC   male      0\r\n258     middle       AL         South      US    AC   male      0\r\n259    primary       NC         South      US     N female      0\r\n260    primary       NH     Northeast      US     N   male      0\r\n261  secondary       NC         South      US     N female      0\r\n262    primary       RI     Northeast      US    OT female      0\r\n263  secondary       FL         South      US    DL female      0\r\n264    primary       CO          West      US    AC female      0\r\n265 generalist       WI       Midwest      US    UZ   male      0\r\n266  secondary       WI       Midwest      US    UZ female      0\r\n267 generalist       AL         South      US    AC   male      0\r\n268 generalist       TX         South      US    OT female      0\r\n269     middle       AL         South      US    AC female      0\r\n270  secondary       PA     Northeast      US    OT female      0\r\n271    primary       NC         South      US     N female      0\r\n272  secondary       CA          West      US    AC   male      0\r\n273 generalist       VA         South      US    UZ female      0\r\n274    primary       TX         South      US    OT female      0\r\n275 generalist       NH     Northeast      US     N   male      0\r\n276 generalist       VA         South      US    UZ   male      0\r\n277 generalist       CA          West      US    AC female      1\r\n278  secondary       CA          West      US    AC female      0\r\n279     middle       NH     Northeast      US     N female      0\r\n280 generalist       MN       Midwest      US     M   male      0\r\n281  secondary       ME     Northeast      US     M   male      0\r\n282    primary       MO       Midwest      US     M female      0\r\n283     middle       NC         South      US     N female      0\r\n284 generalist       NC         South      US     N   male      0\r\n285  secondary       WV         South      US    UZ   male      0\r\n286 generalist       VT     Northeast      US    UZ female      0\r\n287 generalist       MA     Northeast      US     M female      0\r\n288  secondary      CAN International      CA    AC   male      0\r\n289  secondary       OH       Midwest      US    OT female      0\r\n290 generalist       KS       Midwest      US    DL female      0\r\n291  secondary       NC         South      US     N female      0\r\n292    primary       NJ     Northeast      US     N female      0\r\n293  secondary       AL         South      US    AC female      1\r\n294  secondary       FL         South      US    DL   male      0\r\n295  secondary      COL International      CO    AC   male      0\r\n296    college      CAN International      CA    AC   male      0\r\n297    primary       NC         South      US     N   male      0\r\n298    primary       NC         South      US     N female      0\r\n299 generalist       PA     Northeast      US    OT   male      0\r\n300  secondary       WI       Midwest      US    UZ   male      0\r\n301 generalist       WI       Midwest      US    UZ female      0\r\n302  secondary       NC         South      US     N female      0\r\n303  secondary       NC         South      US     N female      0\r\n304    college       NJ     Northeast      US     N female      0\r\n305 generalist       WI       Midwest      US    UZ female      0\r\n306 generalist       NC         South      US     N   male      0\r\n307 generalist       WI       Midwest      US    UZ female      0\r\n308  secondary       NY     Northeast      US     N female      0\r\n309  secondary       GB International      GB    DL female      0\r\n310    college       GB International      GB    DL   male      0\r\n311 generalist       CT     Northeast      US    AC   male      0\r\n312 generalist       CT     Northeast      US    AC female      0\r\n313  secondary       CA          West      US    AC female      0\r\n314    primary       AZ          West      US    AC female      0\r\n315  secondary       CA          West      US    AC female      0\r\n316  secondary      CAN International      CA    AC female      0\r\n317 generalist       CA          West      US    AC   male      0\r\n318  secondary       MO       Midwest      US     M female      0\r\n319 generalist       WI       Midwest      US    UZ   male      0\r\n320 generalist       VA         South      US    UZ female      0\r\n321    primary       NC         South      US     N   male      0\r\n322 generalist       VA         South      US    UZ   male      0\r\n323  secondary       CT     Northeast      US    AC female      0\r\n324  secondary       VA         South      US    UZ female      0\r\n325 generalist       NC         South      US     N   male      1\r\n326  secondary       NC         South      US     N female      0\r\n327    primary       PA     Northeast      US    OT   male      0\r\n328 generalist       MO       Midwest      US     M   male      0\r\n329 generalist       MO       Midwest      US     M   male      0\r\n330    college       OR          West      US    OT female      0\r\n331 generalist       CA          West      US    AC   male      0\r\n332 generalist       TN         South      US    OT female      0\r\n333    primary       AL         South      US    AC female      0\r\n334  secondary       NC         South      US     N female      0\r\n335  secondary       VA         South      US    UZ female      0\r\n336    primary       NC         South      US     N female      0\r\n337  secondary       NY     Northeast      US     N   male      0\r\n338 generalist       AL         South      US    AC female      0\r\n339  secondary       VA         South      US    UZ female      0\r\n340 generalist       SC         South      US    OT female      0\r\n341  secondary       NY     Northeast      US     N female      0\r\n342 generalist      CAN International      CA    AC   male      0\r\n343    primary       TX         South      US    OT female      0\r\n344 generalist       OH       Midwest      US    OT female      0\r\n345    primary       VA         South      US    UZ female      0\r\n346  secondary       AL         South      US    AC   male      0\r\n347     middle       NC         South      US     N   male      0\r\n348  secondary       NC         South      US     N female      0\r\n349    primary       NY     Northeast      US     N female      0\r\n350     middle       ME     Northeast      US     M   male      0\r\n351 generalist       WA          West      US    UZ   male      0\r\n352 generalist       OH       Midwest      US    OT female      0\r\n353     middle       NH     Northeast      US     N female      0\r\n354  secondary       NC         South      US     N female      0\r\n355  secondary       KS       Midwest      US    DL female      0\r\n356 generalist       IL       Midwest      US    DL female      0\r\n357  secondary       NC         South      US     N female      0\r\n358    primary       NY     Northeast      US     N female      0\r\n359 generalist       MA     Northeast      US     M female      0\r\n360 generalist       NC         South      US     N female      0\r\n361 generalist       NC         South      US     N female      0\r\n362  secondary       KS       Midwest      US    DL female      0\r\n363  secondary       IL       Midwest      US    DL   male      0\r\n364 generalist       IN International      IN    DL   male      0\r\n365    college       NC         South      US     N female      0\r\n366 generalist       NZ International      NZ     N female      0\r\n367    college       NY     Northeast      US     N female      0\r\n368  secondary       NH     Northeast      US     N female      0\r\n369    college       PA     Northeast      US    OT female      0\r\n370 generalist       NC         South      US     N female      0\r\n371 generalist       NM          West      US     N female      0\r\n372 generalist       NC         South      US     N female      0\r\n373    primary       NY     Northeast      US     N female      0\r\n374  secondary       NC         South      US     N female      0\r\n375       NULL       AL         South      US    AC female      0\r\n376  secondary       NH     Northeast      US     N female      0\r\n377 generalist       NC         South      US     N   male      0\r\n378 generalist       NC         South      US     N   male      0\r\n379  secondary       NC         South      US     N female      0\r\n380  secondary       NJ     Northeast      US     N female      0\r\n381 generalist       NJ     Northeast      US     N female      0\r\n382  secondary       NC         South      US     N female      0\r\n383 generalist       NC         South      US     N female      0\r\n384 generalist       GA         South      US    DL female      0\r\n385 generalist       TX         South      US    OT female      0\r\n386 generalist       TH International      TH    OT female      0\r\n387 generalist       OH       Midwest      US    OT female      0\r\n388 generalist       TX         South      US    OT   male      0\r\n389 generalist       PA     Northeast      US    OT female      0\r\n390    primary       RI     Northeast      US    OT female      0\r\n391    primary       TX         South      US    OT female      0\r\n392 generalist       AL         South      US    AC   male      0\r\n393     middle       WY          West      US    UZ female      0\r\n394 generalist       WI       Midwest      US    UZ   male      0\r\n395 generalist       WY          West      US    UZ female      0\r\n396 generalist       WI       Midwest      US    UZ   male      0\r\n397 generalist       WI       Midwest      US    UZ female      0\r\n398     middle       MD         South      US     M female      0\r\n399 generalist       MA     Northeast      US     M female      0\r\n400    college       MX International      MX     M   male      0\r\n401  secondary       MA International      MA     M female      0\r\n402 generalist       MN       Midwest      US     M   male      0\r\n403 generalist       MI       Midwest      US     M female      0\r\n404    primary       MO       Midwest      US     M female      0\r\n405 generalist       MA     Northeast      US     M   male      0\r\n406 generalist       MI       Midwest      US     M female      0\r\n407  secondary       ME     Northeast      US     M female      0\r\n408 generalist       MO       Midwest      US     M   male      0\r\n409 generalist       NC         South      US     N female      0\r\n410 generalist       NM          West      US     N female      0\r\n411 generalist       OR          West      US    OT female      0\r\n412 generalist       VA         South      US    UZ female      0\r\n413 generalist       SC         South      US    OT female      0\r\n414 generalist       AZ          West      US    AC female      0\r\n415 generalist       AR         South      US    AC   male      0\r\n416  secondary       CA          West      US    AC female      0\r\n417 generalist       NJ     Northeast      US     N female      0\r\n418 generalist       NH     Northeast      US     N female      0\r\n419  secondary       NC         South      US     N female      0\r\n420 generalist       MA     Northeast      US     M female      0\r\n421 generalist       MN       Midwest      US     M female      0\r\n422 generalist       NC         South      US     N female      0\r\n423 generalist       VT     Northeast      US    UZ   male      0\r\n424    primary       CO          West      US    AC female      0\r\n425 generalist       PA     Northeast      US    OT   male      0\r\n426 generalist       OH       Midwest      US    OT female      0\r\n427 generalist       WI       Midwest      US    UZ female      0\r\n428    primary       MA     Northeast      US     M female      0\r\n429 generalist       NM          West      US     N   male      0\r\n430 generalist       NM          West      US     N female      0\r\n431     middle       NH     Northeast      US     N female      0\r\n432  secondary       NC         South      US     N female      0\r\n433 curriculum       AL         South      US    AC female      0\r\n434 generalist       MO       Midwest      US     M female      1\r\n435       high       MA     Northeast      US     M   male      1\r\n436 generalist       NC         South      US     N   male      0\r\n437 generalist       MO       Midwest      US     M female      1\r\n438 generalist       OR          West      US    OT   male      1\r\n439       NULL     NULL          NULL    NULL  NULL   NULL   NULL\r\n440  secondary       NC         South      US     N female      0\r\n441     middle       TX         South      US    OT female      0\r\n442 generalist       SC         South      US    OT female      0\r\n443 generalist       NY     Northeast      US     N female      0\r\n444 generalist       NC         South      US     N   male      0\r\n445 generalist       NC         South      US     N female      0\r\n    connect strong_component size in_degree out_degree community\r\n1         1                1   33        20         33         4\r\n2         0                1    8         2          5         5\r\n3         1                1    7         2          4         5\r\n4         0                1   13         2         14         7\r\n5         0                1   21        16         17         2\r\n6         1                1   23         9         24         3\r\n7         0                1   42        32         26         2\r\n8         0                1   17        13         18         2\r\n9         0                1    9         2         12         1\r\n10        0                1   14         8         12         7\r\n11        1                1   51        47         74         3\r\n12        0                1   16         6         18         2\r\n13        0                1   27        20         15         3\r\n14        0                1   19         5         20         3\r\n15        0                1   26        13         18         7\r\n16        0                1    4         2          1         7\r\n17        0                1   20         2         22         3\r\n18        0              194   17         0         19         3\r\n19        1                1   39        44         35         5\r\n20        0                1    3         1          2         5\r\n21        0              203    3         2          0         3\r\n22        0                1   14         8         15         1\r\n23        0              209    7         6          0         3\r\n24        1                1   34        21         36         3\r\n25        0                1    7         6          6         3\r\n26        0                1   26        22         12         3\r\n27        0                1   25        13         18         1\r\n28        0              193    2         0          1         7\r\n29        0                1   26        12         23         7\r\n30        1                1   42        32         58         7\r\n31        1              192    2         0          1         7\r\n32        0                1   13        11          4         7\r\n33        0                1   17        17          6         8\r\n34        0                1   24        17         22         3\r\n35        0                1   16        15         19         7\r\n36        1                1   37        26         21         7\r\n37        0                1   10         7          4         7\r\n38        1                1    9         7          2         8\r\n39        1                1   13         5         13         4\r\n40        0              191    2         0          1         4\r\n41        1                1   24        29          6         4\r\n42        0                1   14        10          9         7\r\n43        1                1    7         1          7         4\r\n44        1                1   61        47         70         4\r\n45        0                1    4         1          2         3\r\n46        0                1   12         2          9         4\r\n47        0              190    6         0          5         4\r\n48        0                1    5         2          4         7\r\n49        0                1   29        19         23         4\r\n50        0                1   21        16         14         2\r\n51        0                1   10         6         13         2\r\n52        0                1   14         4         13         3\r\n53        0                1   30        19         16         3\r\n54        0                1   31        14         28         2\r\n55        0              189    4         0          4         2\r\n56        1                1   18         4         20         2\r\n57        0                1    7         7          4         3\r\n58        0                1   25        23         16         3\r\n59        0                1   18         7         14         6\r\n60        0                1   39        25         40         3\r\n61        0                1   34        29         24         2\r\n62        0                1   24        16         17         3\r\n63        0                1   19        11         25         3\r\n64        0                1   34        26         19         3\r\n65        0                1    3         1          2         3\r\n66        0                1    9         4          4         1\r\n67        0                1   26        21          9         5\r\n68        1                1   30        21         40         3\r\n69        0                1   10         4          6         4\r\n70        0                1    5         3          1         3\r\n71        0                1    8         1         12         2\r\n72        0                1    6         3          3         8\r\n73        0              188    3         0          2         8\r\n74        0                1   14         6         10         3\r\n75        0                1   10         3          7         7\r\n76        0                1    6         1          4         3\r\n77        1                1    9         3          8         2\r\n78        1                1    6         3          3         8\r\n79        0              187    5         0          4         8\r\n80        1                1    8         1          6         3\r\n81        0                1   10         3          6         2\r\n82        0                1    8         1          6         1\r\n83        0                1   12         1         13         4\r\n84        0              208    6         5          0         4\r\n85        0                1    8         1          6         4\r\n86        0              186    2         0          1         4\r\n87        0                1   10         3          9         4\r\n88        0                1   19        16         14         8\r\n89        0              185    2         0          1         8\r\n90        0                1    4         1          3         8\r\n91        0                1   13         7         11         8\r\n92        0                1   21        17         16         3\r\n93        0              184    4         1          2         8\r\n94        0                1    7         6          1         1\r\n95        0              182    7         4          3         1\r\n96        0              181    9         0         12         1\r\n97        0              179    6         0          5         1\r\n98        0                1   20        16         12         3\r\n99        1                1    7         3          3         8\r\n100       0                1   24        22          7         4\r\n101       0                1   12         9          3         4\r\n102       0              178    5         0          6         2\r\n103       0                1   11         5          9         6\r\n104       0                1   20         6         15         8\r\n105       0                1    6         2          3         8\r\n106       0                1    6         2          4         4\r\n107       0                1   16         4         15         4\r\n108       1              177    5         0          4         4\r\n109       0                1   17         4         18         4\r\n110       0                1    5         2          2         5\r\n111       0              176    2         0          1         5\r\n112       0                1    6         3          2         4\r\n113       0                1   10         4          6         5\r\n114       1                1   11         6          5         2\r\n115       0                1   19        20          6         6\r\n116       0                1   28        32          3         6\r\n117       0                1    7         5          1         3\r\n118       0                1    5         1          5         6\r\n119       0                1    8         5          2         6\r\n120       0              175    4         1          2         6\r\n121       0                1   10         1         10         7\r\n122       1                1    4         2          1         6\r\n123       0              170    6         0          5         6\r\n124       0              169    3         0          2         6\r\n125       0              168    2         0          1         6\r\n126       1              167    3         0          3         1\r\n127       0              166    3         0          2         6\r\n128       0                1   15        10         14         6\r\n129       0                1   10         6          8         6\r\n130       1              165    2         0          1         6\r\n131       0                1    5         1          4         1\r\n132       1                1    7         4          2         1\r\n133       1                1    7         2          7         1\r\n134       0              164    3         0          2         1\r\n135       0              163    3         0          2         6\r\n136       0                1   15        12         13         6\r\n137       0                1   22        22          8         6\r\n138       0                1    7         3          6         2\r\n139       0              162    5         0          4         7\r\n140       0              160    4         0          3         1\r\n141       0                1    5         2          3         1\r\n142       0                1   11         5          9         1\r\n143       1              159    5         0          6         6\r\n144       0                1   13         9         12         3\r\n145       0              174    3         1          1         6\r\n146       0              183    4         1          2         1\r\n147       0              158   14         1         12         8\r\n148       1              157    8         0          8         2\r\n149       1              156    2         0          1         1\r\n150       0              173    4         2          2         1\r\n151       1              172    3         1          1         6\r\n152       0                1    6         3          2         1\r\n153       0              206    4         3          0         1\r\n154       0                1    9         4          6         1\r\n155       0                1   15         9          9         8\r\n156       0                1    4         1          2         8\r\n157       0                1    9         3          8         2\r\n158       0                1   10         8          7         1\r\n159       0                1    6         1          4         7\r\n160       0              155    4         0          3         1\r\n161       0                1   13         6         12         5\r\n162       0                1    6         4          3         6\r\n163       0                1   10         2         10         7\r\n164       0              154    2         0          1         6\r\n165       0                1    9         3          5         6\r\n166       0              153    6         0          6         2\r\n167       1                1   13        11          3         1\r\n168       0              152    3         0          2         1\r\n169       0              151    4         0          5         1\r\n170       0                1    7         2          7         1\r\n171       0              150    5         1          6         1\r\n172       0                1    6         2          6         1\r\n173       0                1    9         3          6         5\r\n174       0              149    3         1          1         5\r\n175       1              202    6         5          0         2\r\n176       0                1   11         6          8         3\r\n177       1                1   12         9          6         3\r\n178       0                1    6         3          5         8\r\n179       0              148    6         0          6         1\r\n180       0              147    2         0          1         1\r\n181       0                1    3         2          1         1\r\n182       0              201   11        10          0         2\r\n183       0                1   12         3          9         2\r\n184       0                1   11         3          9         3\r\n185       0                1   13         1         13         2\r\n186       0              146    3         0          2         1\r\n187       0              195    4         3          0         1\r\n188       0                1    4         1          3         1\r\n189       0              198    4         3          0         5\r\n190       0                1    5         1          4         2\r\n191       0                1    4         1          3         7\r\n192       0                1   16        16          2         7\r\n193       0                1   13        11         11         3\r\n194       1                1    7         5          1         4\r\n195       1                1   12         8          4         4\r\n196       0              145    6         0          5         4\r\n197       1                1    8         1          6         2\r\n198       0                1   23        20         16         2\r\n199       0                1   12         6          8         8\r\n200       1                1    4         2          3         1\r\n201       0                1   16        11         11         4\r\n202       0              144   13         0         13         3\r\n203       0                1   11        10          2         4\r\n204       0              143    3         0          2         4\r\n205       0                1   14         5         12         8\r\n206       1                1    4         1          2         1\r\n207       1                1   15         9          7         5\r\n208       0                1    8         5          2         3\r\n209       0                1    4         2          1         4\r\n210       0              142    3         0          2         3\r\n211       1                1    9         6          4         3\r\n212       0                1    8         5          7         3\r\n213       0              141    2         0          1         3\r\n214       0              140    3         0          2         4\r\n215       1              139    5         0          5         2\r\n216       0                1    7         5          2         5\r\n217       1                1    9         7          6         5\r\n218       0                1    6         3          2         7\r\n219       0                1   24        17         13         8\r\n220       0              138    2         0          1         5\r\n221       0                1   11         8          2         4\r\n222       0                1    2         1          1         5\r\n223       0                1   21        24         15         5\r\n224       0              137    3         0          2         5\r\n225       1              136    2         0          1         5\r\n226       0                1   14         7          8         2\r\n227       0                1    2         1          1         5\r\n228       0              135    3         0          2         5\r\n229       0              134    2         0          1         7\r\n230       0              132    4         0          3         6\r\n231       1              131    7         0          7         6\r\n232       0              130    4         0          3         7\r\n233       0              129    2         0          1         1\r\n234       0              204   28        37          0         1\r\n235       0                1    4         1          3         1\r\n236       0              128    3         0          3         1\r\n237       0              127    2         0          1         1\r\n238       0              126    2         0          2         1\r\n239       0              161    4         1          2         1\r\n240       0              125    3         0          2         1\r\n241       0              124    3         0          3         1\r\n242       0              123    4         0          4         1\r\n243       0                1    8         5          3         1\r\n244       0              122    2         0          1         1\r\n245       1              120    4         0          3         1\r\n246       0                1    5         1          5         1\r\n247       0                1    8         2          6         7\r\n248       0                1    8         6          3         4\r\n249       0                1    9         5          7         8\r\n250       0                1    5         1          3         5\r\n251       0                1    5         4          1         7\r\n252       0                1    4         2          1         1\r\n253       0                1    3         2          1         1\r\n254       0                1    3         1          1         8\r\n255       0              119    3         0          2         8\r\n256       0                1    6         3          2         8\r\n257       0                1    5         3          1         8\r\n258       0              180    5         1          4         1\r\n259       0              118    4         0          3         3\r\n260       0              116    2         0          1         1\r\n261       1              117    3         1          1         1\r\n262       0                1    4         2          2         2\r\n263       0              121    2         1          0         1\r\n264       0              115    3         0          2         7\r\n265       0                1    5         3          1         2\r\n266       0                1    6         1          4         2\r\n267       0              114    3         0          2         2\r\n268       0                1    9         7          2         3\r\n269       0              113    4         0          3         6\r\n270       0                1    2         1          1         6\r\n271       0                1    4         2          2         1\r\n272       0                1    2         1          1         5\r\n273       1              199    5         4          0         3\r\n274       0              112    2         0          1         4\r\n275       0                1    5         1          4         2\r\n276       0                1    4         1          4         1\r\n277       0                1    5         1          5         2\r\n278       1              111    6         0          5         5\r\n279       0                1   11         8          4         5\r\n280       0              110    3         0          3         1\r\n281       0                1    8         5          3         8\r\n282       0              109    2         0          1         1\r\n283       0              107    2         0          1         1\r\n284       0              108    3         1          1         1\r\n285       1                1    6         2          4         4\r\n286       0              200    3         2          0         3\r\n287       0                1    5         3          1         6\r\n288       1              106    3         0          2         6\r\n289       0              105    4         0          3         5\r\n290       0              104    2         0          1         6\r\n291       0              103    2         0          1         6\r\n292       0                1    3         1          1         3\r\n293       1                1    4         2          1         5\r\n294       1              102    2         0          1         1\r\n295       0                1    6         4          1         1\r\n296       0              101    2         0          1         1\r\n297       1              100    3         0          2         1\r\n298       0               99    4         0          3         5\r\n299       0               98    3         0          2         4\r\n300       0                1   16        12          3         8\r\n301       0                1   12        11          3         2\r\n302       0                1    4         1          4         1\r\n303       0                1    8         5          2         4\r\n304       0               97    3         0          2         4\r\n305       0                1    3         1          1         7\r\n306       0              197    5         4          0         2\r\n307       0                1    5         3          3         2\r\n308       0              207    9         8          0         3\r\n309       0               96    2         0          1         2\r\n310       0                1   24        29          1         5\r\n311       0               95    2         0          1         5\r\n312       0               94    2         0          1         5\r\n313       0               93    2         0          1         5\r\n314       0               92    3         0          2         5\r\n315       0               91    3         0          2         5\r\n316       0               90    2         0          1         5\r\n317       0                1    5         1          5         5\r\n318       0                1    4         2          2         1\r\n319       0                1    5         2          2         7\r\n320       0               89    4         0          3         3\r\n321       0                1    3         1          1         7\r\n322       0                1    6         4          1         7\r\n323       0                1    3         1          2         2\r\n324       0              205    5         4          0         2\r\n325       0                1    3         1          1         8\r\n326       1               88    4         0          3         8\r\n327       0               87    2         0          1         8\r\n328       0               86    2         0          1         7\r\n329       0                1    7         3          6         1\r\n330       0              171    4         1          2         6\r\n331       0                1    4         2          4         1\r\n332       1               85    2         0          1         6\r\n333       0               84    3         0          2         8\r\n334       0              196    3         2          0         3\r\n335       0                1    6         4          2         2\r\n336       0                1   13         9          3         2\r\n337       1                1    5         3          1         6\r\n338       0                1    3         1          3         1\r\n339       0                1    3         1          1         2\r\n340       0                1    4         1          2         1\r\n341       1                1   10         9          2         5\r\n342       0                1    5         3          1         1\r\n343       0                1    3         1          1         1\r\n344       0              133    3         1          1         6\r\n345       0                1    4         2          1         7\r\n346       0                1    3         1          2         1\r\n347       1                1    6         2          3         2\r\n348       0               83    2         0          1         2\r\n349       0               82    2         0          1         2\r\n350       0                1    7         5          1         8\r\n351       0                1    5         5          1         3\r\n352       0               81    2         0          1         5\r\n353       0               80    3         0          2         4\r\n354       0               79    4         0          3         4\r\n355       0                1    3         1          3         1\r\n356       0                1    5         3          2         1\r\n357       0               78    3         0          2         2\r\n358       0                1    3         1          1         3\r\n359       0               77    2         0          1         4\r\n360       0               76    5         0          4         2\r\n361       1                1   21         1         20         8\r\n362       0               75    2         0          1         1\r\n363       0               74    2         0          1         1\r\n364       0               73    2         0          1         1\r\n365       0               72    2         0          1         1\r\n366       0               71    2         0          2         1\r\n367       0               70    2         0          1         1\r\n368       0               69    2         0          1         1\r\n369       0               68    2         0          1         1\r\n370       0               67    2         0          1         4\r\n371       0               66    2         0          1         1\r\n372       0               65    2         0          1         1\r\n373       0               64    2         0          1         1\r\n374       0               63    2         0          1         1\r\n375       0               62    2         0          1         1\r\n376       0               61    3         0          3         1\r\n377       0               60    3         0          2         2\r\n378       0               59    3         0          2         2\r\n379       0               58    3         0          2         2\r\n380       0               57    2         0          1         1\r\n381       0               56    2         0          1         1\r\n382       0               55    3         0          2         2\r\n383       0               54    2         0          1         1\r\n384       1               53    2         0          1         1\r\n385       0               52    2         0          1         1\r\n386       0               51    2         0          1         1\r\n387       1               50    2         0          1         1\r\n388       0               49    3         0          2         2\r\n389       0               48    2         0          1         1\r\n390       0               47    2         0          1         1\r\n391       0               46    2         0          1         1\r\n392       0               45    2         0          1         1\r\n393       0               44    2         0          1         1\r\n394       0               43    2         0          1         1\r\n395       0               42    2         0          1         1\r\n396       0               41    2         0          1         1\r\n397       0               40    3         0          3         1\r\n398       0               39    2         0          1         1\r\n399       0               38    3         0          2         2\r\n400       1               37    2         0          1         1\r\n401       0               36    2         0          1         1\r\n402       0               35    2         0          1         1\r\n403       0               34    3         0          2         2\r\n404       0               33    2         0          1         1\r\n405       0               32    2         0          1         1\r\n406       0               31    3         0          3         1\r\n407       0               30    2         0          1         1\r\n408       0               29    2         0          1         1\r\n409       0               28    3         0          2         2\r\n410       1               27    3         0          3         2\r\n411       1               26    2         0          1         1\r\n412       0               25    2         0          1         1\r\n413       1                1    2         1          1         1\r\n414       0               24    2         0          1         1\r\n415       0               23    2         0          2         1\r\n416       0               22    2         0          1         2\r\n417       0               21    2         0          1         2\r\n418       0               20    2         0          1         2\r\n419       0               19    2         0          1         2\r\n420       0               18    2         0          1         2\r\n421       0               17    2         0          1         2\r\n422       1                1    4         3          1         3\r\n423       0               16    2         0          1         2\r\n424       0               15    2         0          1         1\r\n425       1               14    2         0          1         1\r\n426       0               13    2         0          1         1\r\n427       0               12    2         0          1         1\r\n428       0               11    2         0          1         1\r\n429       1               10    2         0          1         1\r\n430       0                9    2         0          1         1\r\n431       0                8    2         0          1         1\r\n432       0                1   36         5         38         3\r\n433       0                1    2         1          1         2\r\n434       0                1    4         1          2         3\r\n435       0                7    2         0          1         2\r\n436       0                6    2         0          1         2\r\n437       0                1    2         1          1         7\r\n438       0                1    3         1          1         7\r\n439    NULL                1    2         1          1         1\r\n440       0                5    2         0          1         1\r\n441       0                4    1         0          0         9\r\n442       0                3    1         0          0        10\r\n443       0                2    1         0          0        11\r\n444       0                1  295       475        106         1\r\n445       0                1  160       276         56         2\r\n    degree_c betweenness_c closeness_c\r\n1         53  9.997258e-03 0.197508897\r\n2          7  9.338289e-05 0.172628305\r\n3          6  1.332240e-04 0.171627368\r\n4         16  2.173936e-04 0.191709845\r\n5         33  4.915016e-03 0.194907814\r\n6         33  4.110439e-03 0.196113074\r\n7         58  1.514472e-02 0.198835647\r\n8         31  1.092029e-03 0.194907814\r\n9         14  6.887348e-05 0.193295603\r\n10        20  4.643416e-03 0.194736842\r\n11       121  1.357036e-02 0.200814111\r\n12        24  4.039876e-04 0.181669394\r\n13        35  3.087664e-03 0.194140796\r\n14        25  2.642207e-04 0.194993412\r\n15        31  1.926153e-03 0.196460177\r\n16         3  1.508410e-05 0.167610419\r\n17        24  6.282821e-04 0.195250660\r\n18        19  5.392684e-04 0.193971166\r\n19        79  3.362383e-02 0.198835647\r\n20         3  6.686092e-06 0.166791886\r\n21         2  1.977146e-06 0.166666667\r\n22        23  1.796529e-03 0.194140796\r\n23         6  8.503385e-06 0.170441459\r\n24        57  6.177946e-03 0.198746643\r\n25        12  2.348410e-04 0.189339019\r\n26        34  1.848973e-03 0.195422535\r\n27        31  6.929039e-03 0.193548387\r\n28         1  0.000000e+00 0.163235294\r\n29        35  9.491100e-03 0.196721311\r\n30        90  1.645036e-02 0.199192463\r\n31         1  0.000000e+00 0.164627364\r\n32        15  5.051407e-04 0.189662537\r\n33        23  6.929501e-04 0.191875540\r\n34        39  1.092729e-03 0.196113074\r\n35        34  5.316433e-03 0.193464052\r\n36        47  7.218586e-03 0.198657718\r\n37        11  1.623720e-04 0.173099415\r\n38         9  1.016427e-04 0.190721649\r\n39        18  4.665541e-04 0.194140796\r\n40         1  0.000000e+00 0.151535836\r\n41        35  5.602716e-03 0.178313253\r\n42        19  4.711667e-04 0.174734357\r\n43         8  3.957020e-05 0.170900693\r\n44       117  2.750977e-02 0.201360544\r\n45         3  3.627871e-05 0.189339019\r\n46        11  4.804831e-04 0.179757085\r\n47         5  1.592974e-05 0.177316294\r\n48         6  9.722768e-05 0.189097104\r\n49        42  7.914720e-03 0.196460177\r\n50        30  9.747479e-04 0.195079086\r\n51        19  1.788484e-04 0.193295603\r\n52        17  5.245653e-04 0.181002854\r\n53        35  1.838537e-03 0.184538653\r\n54        42  8.083196e-03 0.196634190\r\n55         4  1.094847e-04 0.175632911\r\n56        24  6.434155e-04 0.182415776\r\n57        11  8.681808e-05 0.189258312\r\n58        39  9.939424e-04 0.196547145\r\n59        21  5.947597e-03 0.195250660\r\n60        65  1.478094e-02 0.198037467\r\n61        53  1.966297e-02 0.196808511\r\n62        33  4.608381e-04 0.195767196\r\n63        36  1.528650e-03 0.194395797\r\n64        45  4.634750e-03 0.195680917\r\n65         3  0.000000e+00 0.188535032\r\n66         8  1.031376e-04 0.193043478\r\n67        30  6.168175e-03 0.196460177\r\n68        61  4.240547e-03 0.196113074\r\n69        10  4.555436e-03 0.192792010\r\n70         4  4.041984e-05 0.188775510\r\n71        13  1.165292e-03 0.192124621\r\n72         6  1.957734e-03 0.189177674\r\n73         2  2.371625e-06 0.164261931\r\n74        16  7.699256e-04 0.179393939\r\n75        10  4.696823e-04 0.192959583\r\n76         5  8.353946e-06 0.188615123\r\n77        11  1.603071e-04 0.192457737\r\n78         6  1.030969e-03 0.189177674\r\n79         4  1.316145e-05 0.164871890\r\n80         7  6.675907e-05 0.173844949\r\n81         9  2.023521e-04 0.189824711\r\n82         7  1.565938e-04 0.192374350\r\n83        14  2.723061e-03 0.194310722\r\n84         5  4.482609e-03 0.166666667\r\n85         7  9.703950e-04 0.192792010\r\n86         1  0.000000e+00 0.143041237\r\n87        12  2.490986e-03 0.193971166\r\n88        30  7.380835e-03 0.194480946\r\n89         1  0.000000e+00 0.163055454\r\n90         4  2.870534e-06 0.188375053\r\n91        18  9.879306e-04 0.193211488\r\n92        33  3.693240e-03 0.195853551\r\n93         3  2.428104e-05 0.164505372\r\n94         7  1.838970e-03 0.191792657\r\n95         7  4.493683e-03 0.188375053\r\n96        12  4.745181e-04 0.192875760\r\n97         5  4.446413e-05 0.176190476\r\n98        28  4.422862e-04 0.192792010\r\n99         6  1.074300e-04 0.192792010\r\n100       29  2.226758e-03 0.195939982\r\n101       12  1.491776e-03 0.193211488\r\n102        6  0.000000e+00 0.192291035\r\n103       14  5.205746e-03 0.192792010\r\n104       21  9.561525e-04 0.182640889\r\n105        5  9.977457e-05 0.189662537\r\n106        6  1.553601e-05 0.172293364\r\n107       19  5.186231e-04 0.190967742\r\n108        4  3.381618e-06 0.168949772\r\n109       22  7.966098e-03 0.192124621\r\n110        4  4.479720e-03 0.188775510\r\n111        1  0.000000e+00 0.159025788\r\n112        5  8.488116e-05 0.188855806\r\n113       10  1.765519e-04 0.189743590\r\n114       11  9.969978e-05 0.180855397\r\n115       26  2.333754e-02 0.193127447\r\n116       35  1.524048e-02 0.197070573\r\n117        6  2.994202e-05 0.171627368\r\n118        6  5.342236e-05 0.166917293\r\n119        7  5.582580e-04 0.169659916\r\n120        3  4.474000e-03 0.188615123\r\n121       11  1.416391e-04 0.193464052\r\n122        3  2.903839e-05 0.166729253\r\n123        5  7.004260e-04 0.168118137\r\n124        2  0.000000e+00 0.188455008\r\n125        1  0.000000e+00 0.164871890\r\n126        3  0.000000e+00 0.188455008\r\n127        2  0.000000e+00 0.188455008\r\n128       24  1.690773e-03 0.192291035\r\n129       14  1.254664e-03 0.190149893\r\n130        1  0.000000e+00 0.164871890\r\n131        5  1.821601e-05 0.188936170\r\n132        6  3.640050e-05 0.171230235\r\n133        9  6.186174e-04 0.189905902\r\n134        2  1.138480e-04 0.187896741\r\n135        2  2.412686e-05 0.160927872\r\n136       25  1.148455e-03 0.193717277\r\n137       30  3.241522e-03 0.195767196\r\n138        9  1.111568e-04 0.192291035\r\n139        4  1.847047e-05 0.188455008\r\n140        3  2.542045e-06 0.161807580\r\n141        5  1.773828e-03 0.188535032\r\n142       14  2.481858e-04 0.193379791\r\n143        6  1.068402e-06 0.189016603\r\n144       21  2.019987e-04 0.190803610\r\n145        2  1.866003e-05 0.164566345\r\n146        3  4.023374e-05 0.191461837\r\n147       13  1.800397e-03 0.193211488\r\n148        8  3.947696e-05 0.177955912\r\n149        1  0.000000e+00 0.158571429\r\n150        4  8.477025e-03 0.188135593\r\n151        2  2.440364e-05 0.160000000\r\n152        5  5.905531e-04 0.189016603\r\n153        3  7.111750e-06 0.163415532\r\n154       10  2.301671e-03 0.192541197\r\n155       18  2.595965e-03 0.193971166\r\n156        3  2.979074e-06 0.169465649\r\n157       11  1.112162e-03 0.192708333\r\n158       15  1.195712e-03 0.190312902\r\n159        5  2.855870e-05 0.176610979\r\n160        3  7.270113e-04 0.188135593\r\n161       18  2.865065e-04 0.192041522\r\n162        7  3.611767e-05 0.191875540\r\n163       12  7.773809e-05 0.193127447\r\n164        1  0.000000e+00 0.161866569\r\n165        8  2.495069e-04 0.190803610\r\n166        6  1.530205e-04 0.191958495\r\n167       14  3.070046e-03 0.190394511\r\n168        2  0.000000e+00 0.161807580\r\n169        5  0.000000e+00 0.188455008\r\n170        9  2.442540e-04 0.189177674\r\n171        7  4.474000e-03 0.188615123\r\n172        8  1.063241e-04 0.189500640\r\n173        9  1.893158e-03 0.189743590\r\n174        2  3.389394e-06 0.162756598\r\n175        5  1.207379e-05 0.166917293\r\n176       14  4.787245e-03 0.192875760\r\n177       15  5.059019e-04 0.182116489\r\n178        8  8.215182e-04 0.189016603\r\n179        6  2.089695e-04 0.191875540\r\n180        1  0.000000e+00 0.158741509\r\n181        3  0.000000e+00 0.187896741\r\n182       10  8.758506e-05 0.172964550\r\n183       12  6.552675e-04 0.180781759\r\n184       12  1.835474e-03 0.193211488\r\n185       14  8.593368e-04 0.193295603\r\n186        2  0.000000e+00 0.187817259\r\n187        3  9.243802e-07 0.187896741\r\n188        4  0.000000e+00 0.188535032\r\n189        3  5.180931e-06 0.187976291\r\n190        5  6.130620e-05 0.191709845\r\n191        4  3.038756e-05 0.169078446\r\n192       18  8.311724e-03 0.192041522\r\n193       22  4.425342e-04 0.193379791\r\n194        6  1.290771e-04 0.189419795\r\n195       12  1.090249e-04 0.194651469\r\n196        5  1.783289e-05 0.189419795\r\n197        7  6.288008e-04 0.178743961\r\n198       36  7.005840e-04 0.195336560\r\n199       14  2.846943e-04 0.193295603\r\n200        5  1.945641e-04 0.189097104\r\n201       22  6.532441e-04 0.193886463\r\n202       13  8.398502e-05 0.194310722\r\n203       12  2.806158e-04 0.190721649\r\n204        2  0.000000e+00 0.187976291\r\n205       17  9.459393e-04 0.190312902\r\n206        3  0.000000e+00 0.188135593\r\n207       16  3.426864e-04 0.183017312\r\n208        7  9.279767e-05 0.170180146\r\n209        3  4.400729e-05 0.175841584\r\n210        2  0.000000e+00 0.175355450\r\n211       10  3.336131e-04 0.192708333\r\n212       12  9.547411e-05 0.192457737\r\n213        1  0.000000e+00 0.165548098\r\n214        2  0.000000e+00 0.188215345\r\n215        5  1.321273e-05 0.177316294\r\n216        7  7.396383e-05 0.170049789\r\n217       13  2.370083e-03 0.190394511\r\n218        5  2.627770e-04 0.189419795\r\n219       30  3.178656e-03 0.192624729\r\n220        1  0.000000e+00 0.166105499\r\n221       10  6.195117e-04 0.191461837\r\n222        2  0.000000e+00 0.166105499\r\n223       39  8.530463e-03 0.196026490\r\n224        2  0.000000e+00 0.167673716\r\n225        1  0.000000e+00 0.166105499\r\n226       15  3.017241e-04 0.194310722\r\n227        2  0.000000e+00 0.166105499\r\n228        2  0.000000e+00 0.177387135\r\n229        1  0.000000e+00 0.161337209\r\n230        3  2.736394e-05 0.161689731\r\n231        7  8.912657e-05 0.170966500\r\n232        3  1.664355e-05 0.191709845\r\n233        1  0.000000e+00 0.161689731\r\n234       37  2.242049e-02 0.192541197\r\n235        4  4.327795e-05 0.191875540\r\n236        3  0.000000e+00 0.188295165\r\n237        1  0.000000e+00 0.161689731\r\n238        2  0.000000e+00 0.161689731\r\n239        3  8.818300e-04 0.188375053\r\n240        2  0.000000e+00 0.188295165\r\n241        3  0.000000e+00 0.188295165\r\n242        4  0.000000e+00 0.188375053\r\n243        8  8.748607e-03 0.189662537\r\n244        1  0.000000e+00 0.161689731\r\n245        3  4.474000e-03 0.188455008\r\n246        6  9.804484e-06 0.188936170\r\n247        8  4.513245e-03 0.192541197\r\n248        9  4.524555e-03 0.190639760\r\n249       12  3.758989e-03 0.192541197\r\n250        4  1.124611e-04 0.191709845\r\n251        5  2.123824e-04 0.188535032\r\n252        3  4.994438e-07 0.188295165\r\n253        3  0.000000e+00 0.188295165\r\n254        2  1.520385e-06 0.161984677\r\n255        2  0.000000e+00 0.187896741\r\n256        5  4.152514e-05 0.188695283\r\n257        4  7.012946e-05 0.188936170\r\n258        5  2.263293e-04 0.191709845\r\n259        3  7.710743e-05 0.188695283\r\n260        1  0.000000e+00 0.158401712\r\n261        2  4.474000e-03 0.187896741\r\n262        4  7.810434e-05 0.176120587\r\n263        1  0.000000e+00 0.158798283\r\n264        2  1.475825e-05 0.175632911\r\n265        4  4.980090e-04 0.188535032\r\n266        5  5.145883e-05 0.164627364\r\n267        2  0.000000e+00 0.188775510\r\n268        9  1.532313e-04 0.173844949\r\n269        3  2.866235e-06 0.167673716\r\n270        2  0.000000e+00 0.162102957\r\n271        4  2.285280e-04 0.188135593\r\n272        2  0.000000e+00 0.164140481\r\n273        4  1.041269e-05 0.168373151\r\n274        1  0.000000e+00 0.167863894\r\n275        5  1.959549e-06 0.177528988\r\n276        5  0.000000e+00 0.192124621\r\n277        6  3.919098e-06 0.177528988\r\n278        5  2.665584e-03 0.192457737\r\n279       12  1.773613e-03 0.191296855\r\n280        3  0.000000e+00 0.188295165\r\n281        8  8.324394e-05 0.192124621\r\n282        1  0.000000e+00 0.159654800\r\n283        1  0.000000e+00 0.158401712\r\n284        2  4.474000e-03 0.187896741\r\n285        6  1.193956e-05 0.168693009\r\n286        2  2.944515e-06 0.162102957\r\n287        4  3.862214e-05 0.169271826\r\n288        2  1.171883e-05 0.162399415\r\n289        3  1.296219e-04 0.164261931\r\n290        1  0.000000e+00 0.162102957\r\n291        1  0.000000e+00 0.162102957\r\n292        2  0.000000e+00 0.187976291\r\n293        3  7.205470e-06 0.176190476\r\n294        1  0.000000e+00 0.158911954\r\n295        5  4.479254e-03 0.188135593\r\n296        1  0.000000e+00 0.158571429\r\n297        2  0.000000e+00 0.187896741\r\n298        3  0.000000e+00 0.191792657\r\n299        2  0.000000e+00 0.187976291\r\n300       15  4.780285e-03 0.194140796\r\n301       14  2.176201e-03 0.192959583\r\n302        5  2.205982e-06 0.188615123\r\n303        7  6.020324e-05 0.192457737\r\n304        2  0.000000e+00 0.187817259\r\n305        2  0.000000e+00 0.188295165\r\n306        4  1.164955e-04 0.165857303\r\n307        6  7.882054e-04 0.175980975\r\n308        8  6.997015e-05 0.189824711\r\n309        1  0.000000e+00 0.164566345\r\n310       30  2.296343e-02 0.192541197\r\n311        1  0.000000e+00 0.161689731\r\n312        1  0.000000e+00 0.161689731\r\n313        1  0.000000e+00 0.161689731\r\n314        2  0.000000e+00 0.188615123\r\n315        2  0.000000e+00 0.162102957\r\n316        1  0.000000e+00 0.161689731\r\n317        6  8.873663e-05 0.192291035\r\n318        4  0.000000e+00 0.191958495\r\n319        4  5.642092e-05 0.175771971\r\n320        3  0.000000e+00 0.191627104\r\n321        2  3.223866e-06 0.161866569\r\n322        5  8.752388e-04 0.189500640\r\n323        3  0.000000e+00 0.176050753\r\n324        4  1.069884e-05 0.188375053\r\n325        2  0.000000e+00 0.188135593\r\n326        3  0.000000e+00 0.191461837\r\n327        1  0.000000e+00 0.162816282\r\n328        1  0.000000e+00 0.161689731\r\n329        9  5.630786e-05 0.192041522\r\n330        3  7.858756e-04 0.188215345\r\n331        6  1.271023e-06 0.188055909\r\n332        1  0.000000e+00 0.158911954\r\n333        2  1.819547e-05 0.187976291\r\n334        2  0.000000e+00 0.169400992\r\n335        6  3.508836e-05 0.189258312\r\n336       12  2.630565e-04 0.194225722\r\n337        4  1.347255e-03 0.188375053\r\n338        4  0.000000e+00 0.188295165\r\n339        2  0.000000e+00 0.188455008\r\n340        3  2.514451e-04 0.187976291\r\n341       11  2.492494e-04 0.179684338\r\n342        4  7.466899e-04 0.188135593\r\n343        2  0.000000e+00 0.187896741\r\n344        2  1.122599e-03 0.187896741\r\n345        3  0.000000e+00 0.188375053\r\n346        3  9.418734e-04 0.187976291\r\n347        5  7.612775e-04 0.192875760\r\n348        1  0.000000e+00 0.164688427\r\n349        1  0.000000e+00 0.164688427\r\n350        6  5.820118e-05 0.189662537\r\n351        6  4.412943e-05 0.176962933\r\n352        1  0.000000e+00 0.164444444\r\n353        2  1.992894e-06 0.166043381\r\n354        3  0.000000e+00 0.191544435\r\n355        4  0.000000e+00 0.187817259\r\n356        5  4.248942e-06 0.188455008\r\n357        2  5.191504e-05 0.187976291\r\n358        2  0.000000e+00 0.188695283\r\n359        1  0.000000e+00 0.160346696\r\n360        4  6.108170e-05 0.188615123\r\n361       21  1.206649e-03 0.175841584\r\n362        1  0.000000e+00 0.187737844\r\n363        1  0.000000e+00 0.187737844\r\n364        1  0.000000e+00 0.187737844\r\n365        1  0.000000e+00 0.187737844\r\n366        2  0.000000e+00 0.187737844\r\n367        1  0.000000e+00 0.187737844\r\n368        1  0.000000e+00 0.187737844\r\n369        1  0.000000e+00 0.187737844\r\n370        1  0.000000e+00 0.161866569\r\n371        1  0.000000e+00 0.187737844\r\n372        1  0.000000e+00 0.187737844\r\n373        1  0.000000e+00 0.187737844\r\n374        1  0.000000e+00 0.187737844\r\n375        1  0.000000e+00 0.187737844\r\n376        3  0.000000e+00 0.191296855\r\n377        2  0.000000e+00 0.191296855\r\n378        2  0.000000e+00 0.191296855\r\n379        2  0.000000e+00 0.191296855\r\n380        1  0.000000e+00 0.187737844\r\n381        1  0.000000e+00 0.187737844\r\n382        2  0.000000e+00 0.191296855\r\n383        1  0.000000e+00 0.187737844\r\n384        1  0.000000e+00 0.187737844\r\n385        1  0.000000e+00 0.187737844\r\n386        1  0.000000e+00 0.187737844\r\n387        1  0.000000e+00 0.187737844\r\n388        2  0.000000e+00 0.191296855\r\n389        1  0.000000e+00 0.187737844\r\n390        1  0.000000e+00 0.187737844\r\n391        1  0.000000e+00 0.187737844\r\n392        1  0.000000e+00 0.187737844\r\n393        1  0.000000e+00 0.187737844\r\n394        1  0.000000e+00 0.187737844\r\n395        1  0.000000e+00 0.187737844\r\n396        1  0.000000e+00 0.187737844\r\n397        3  0.000000e+00 0.191296855\r\n398        1  0.000000e+00 0.187737844\r\n399        2  0.000000e+00 0.191296855\r\n400        1  0.000000e+00 0.187737844\r\n401        1  0.000000e+00 0.187737844\r\n402        1  0.000000e+00 0.187737844\r\n403        2  0.000000e+00 0.191296855\r\n404        1  0.000000e+00 0.187737844\r\n405        1  0.000000e+00 0.187737844\r\n406        3  0.000000e+00 0.191296855\r\n407        1  0.000000e+00 0.187737844\r\n408        1  0.000000e+00 0.187737844\r\n409        2  0.000000e+00 0.191296855\r\n410        3  0.000000e+00 0.191296855\r\n411        1  0.000000e+00 0.187737844\r\n412        1  0.000000e+00 0.187737844\r\n413        2  0.000000e+00 0.187737844\r\n414        1  0.000000e+00 0.187737844\r\n415        2  0.000000e+00 0.187737844\r\n416        1  0.000000e+00 0.175217048\r\n417        1  0.000000e+00 0.175217048\r\n418        1  0.000000e+00 0.175217048\r\n419        1  0.000000e+00 0.175217048\r\n420        1  0.000000e+00 0.175217048\r\n421        1  0.000000e+00 0.175217048\r\n422        4  6.389261e-06 0.166416792\r\n423        1  0.000000e+00 0.175217048\r\n424        1  0.000000e+00 0.187737844\r\n425        1  0.000000e+00 0.187737844\r\n426        1  0.000000e+00 0.187737844\r\n427        1  0.000000e+00 0.187737844\r\n428        1  0.000000e+00 0.187737844\r\n429        1  0.000000e+00 0.187737844\r\n430        1  0.000000e+00 0.187737844\r\n431        1  0.000000e+00 0.187737844\r\n432       43  4.114279e-03 0.183698800\r\n433        2  0.000000e+00 0.175217048\r\n434        3  1.626206e-06 0.176610979\r\n435        1  0.000000e+00 0.175217048\r\n436        1  0.000000e+00 0.175217048\r\n437        2  0.000000e+00 0.162340037\r\n438        2  9.470854e-06 0.175702414\r\n439        2  0.000000e+00 0.162399415\r\n440        1  0.000000e+00 0.187737844\r\n441        0  0.000000e+00 0.002247191\r\n442        0  0.000000e+00 0.002247191\r\n443        0  0.000000e+00 0.002247191\r\n444      581  7.142161e-01 0.230649351\r\n445      332  1.850191e-01 0.212034384\r\n\r\nShow code\r\n\r\nkeyego <- data.frame(\r\n  dltl_stats_ego %>%\r\n  arrange(-degree_c)%>%\r\n  select(uid),\r\n dltl_stats_ego %>%\r\n  arrange(-betweenness_c)%>%\r\n  select(uid),\r\n  dltl_stats_ego %>%\r\n  arrange(-closeness_c)%>%\r\n  select(uid))%>%\r\n  setNames(c(\"degree\",\"betweenness\",\"closeness\"))\r\nkeyego[]\r\n\r\n\r\n    degree betweenness closeness\r\n1      444         444       444\r\n2      445         445       445\r\n3       11          19        44\r\n4       44          44        11\r\n5       30         115        30\r\n6       19         310         7\r\n7       60         234        19\r\n8       68          61        24\r\n9        7          30        36\r\n10      24         116        60\r\n11       1           7         1\r\n12      61          60       116\r\n13      36          11        61\r\n14      64           1        29\r\n15     432          29        54\r\n16      49         243        58\r\n17      54         223        15\r\n18      34         150        49\r\n19      58         192        67\r\n20     223          54         6\r\n21     234         109        34\r\n22      63          49        68\r\n23     198          88       223\r\n24      13          36       100\r\n25      29          27        92\r\n26      41          24        62\r\n27      53          67       137\r\n28     116          59        64\r\n29      26          41        26\r\n30      35          35       198\r\n31       5         103        17\r\n32       6           5        59\r\n33      62         176        50\r\n34      92         300        14\r\n35       8          10         5\r\n36      15          64         8\r\n37      27          69        10\r\n38      50         248       195\r\n39      67         247        88\r\n40      88          95        63\r\n41     137          84        83\r\n42     219         110       202\r\n43     310         295       226\r\n44     100         245       336\r\n45      98         120        13\r\n46     115         261        22\r\n47      14         284        39\r\n48     136         171       300\r\n49      12          68        18\r\n50      17         432        87\r\n51      56           6       155\r\n52     128         249       201\r\n53      22          92       136\r\n54      33         137        27\r\n55     109         219        35\r\n56     193          13       121\r\n57     201         167       142\r\n58      59          83       193\r\n59     104         278         9\r\n60     144         155        51\r\n61     361          87       185\r\n62      10         217       199\r\n63      18         154        91\r\n64      42         100       101\r\n65      51         301       147\r\n66     107          72       184\r\n67      39          15       115\r\n68      91         173       163\r\n69     155          26        66\r\n70     161          94        75\r\n71     192          53       301\r\n72      52         184        96\r\n73     205         147       176\r\n74       4          22       347\r\n75      74         141        69\r\n76     207         279        85\r\n77      32         128        98\r\n78     158          63        99\r\n79     177         101       103\r\n80     226         337       157\r\n81     300         129       211\r\n82       9         361       219\r\n83      83         158       154\r\n84     103          71       234\r\n85     129         136       247\r\n86     142         344       249\r\n87     167         157       310\r\n88     176          34        77\r\n89     185           8       212\r\n90     199          78       278\r\n91     301          58       303\r\n92      71          91        82\r\n93     147          50       102\r\n94     202          85       128\r\n95     217         104       138\r\n96      25         205       317\r\n97      87         346        71\r\n98      96         239       109\r\n99     101         322       276\r\n100    163         185       281\r\n101    183         178       161\r\n102    184         307       192\r\n103    195         330       329\r\n104    203          74       166\r\n105    212         347       318\r\n106    249         342        33\r\n107    279         160       162\r\n108    336         198       179\r\n109     37         123       235\r\n110     46          33        94\r\n111     57         183       298\r\n112     77         201         4\r\n113    114          56       190\r\n114    121         197       232\r\n115    157          17       250\r\n116    341         221       258\r\n117     69         133       320\r\n118     75         152       354\r\n119    113         119       146\r\n120    154          18       221\r\n121    182          52       326\r\n122    211         107       279\r\n123    221         177       376\r\n124     38          32       377\r\n125     81         265       378\r\n126    133          46       379\r\n127    138          96       382\r\n128    170          42       388\r\n129    173          75       397\r\n130    248          39       399\r\n131    268          62       403\r\n132    329         193       406\r\n133     43          98       409\r\n134     66          12       410\r\n135    148         207       107\r\n136    165         211       144\r\n137    172         226       165\r\n138    178         161        38\r\n139    243         199       203\r\n140    247         203       248\r\n141    281          14       167\r\n142    308         336       217\r\n143      2         218       158\r\n144     80         340       205\r\n145     82         165       129\r\n146     85         341       133\r\n147     94         142        81\r\n148     95         170       308\r\n149    119          25       113\r\n150    162         271       173\r\n151    171         258        32\r\n152    197           4       105\r\n153    208         251       243\r\n154    216         179       350\r\n155    231          81       172\r\n156    303         144       322\r\n157      3         200       194\r\n158     23          51       196\r\n159     48         113       218\r\n160     72          37        25\r\n161     78          77        45\r\n162     99          82        57\r\n163    102         268       335\r\n164    106         166        72\r\n165    117         121        78\r\n166    118           3       170\r\n167    132         289        48\r\n168    143         194       200\r\n169    166         306       143\r\n170    179         134       152\r\n171    194         250       178\r\n172    246         138       131\r\n173    277          55       246\r\n174    285         195       257\r\n175    307          99       112\r\n176    317         172        70\r\n177    331          66       110\r\n178    335          38       267\r\n179    350         105       256\r\n180    351         114       259\r\n181     47          48       358\r\n182     76         212        76\r\n183     84           2       120\r\n184     97         208       171\r\n185    105         231       302\r\n186    112         317       314\r\n187    123         182       360\r\n188    131          57        65\r\n189    141         112       141\r\n190    152         202       188\r\n191    159         281       251\r\n192    169         262       265\r\n193    175         163       124\r\n194    190         259       126\r\n195    196         216       127\r\n196    200         257       139\r\n197    215         308       169\r\n198    218           9       245\r\n199    251          80       339\r\n200    256         190       356\r\n201    258         360        90\r\n202    266         303        95\r\n203    275         350       239\r\n204    276         319       242\r\n205    278         329       324\r\n206    295         118       337\r\n207    302         357       345\r\n208    322         266       236\r\n209    347          97       240\r\n210    356         351       241\r\n211     55         209       252\r\n212     70         235       253\r\n213     79         256       280\r\n214     90          70       305\r\n215    108         146       338\r\n216    110          43       214\r\n217    139         148       330\r\n218    150         287       150\r\n219    188         132       160\r\n220    191          45       206\r\n221    235         162       271\r\n222    242         335       295\r\n223    250         191       325\r\n224    257         117       342\r\n225    262         122       331\r\n226    265         159       189\r\n227    271         230       204\r\n228    273         151       292\r\n229    287          93       299\r\n230    306         135       333\r\n231    318         145       340\r\n232    319         139       346\r\n233    324         131       357\r\n234    337         333       134\r\n235    338         196       181\r\n236    342         232       187\r\n237    355          47       255\r\n238    360         106       261\r\n239    422          16       284\r\n240     16         264       297\r\n241     20         215       343\r\n242     45          79       344\r\n243     65         175       186\r\n244     93         285       304\r\n245    120         288       355\r\n246    122         324       362\r\n247    126         273       363\r\n248    140         246       364\r\n249    146         438       365\r\n250    153          23       366\r\n251    156          76       367\r\n252    160         293       368\r\n253    181         153       369\r\n254    187          20       371\r\n255    189         422       372\r\n256    206         189       373\r\n257    209         356       374\r\n258    230         277       375\r\n259    232         174       380\r\n260    236         108       381\r\n261    239         321       383\r\n262    241         156       384\r\n263    245         286       385\r\n264    252          90       386\r\n265    253         269       387\r\n266    259         140       389\r\n267    269          73       390\r\n268    280         302       391\r\n269    289         353       392\r\n270    293          21       393\r\n271    298         275       394\r\n272    320         434       395\r\n273    323         254       396\r\n274    326         331       398\r\n275    330         143       400\r\n276    340         187       401\r\n277    345         252       402\r\n278    346          28       404\r\n279    354          31       405\r\n280    376          40       407\r\n281    397          65       408\r\n282    406          86       411\r\n283    410          89       412\r\n284    434         102       413\r\n285     21         111       414\r\n286     73         124       415\r\n287    124         125       424\r\n288    127         126       425\r\n289    134         127       426\r\n290    135         130       427\r\n291    145         149       428\r\n292    151         164       429\r\n293    168         168       430\r\n294    174         169       431\r\n295    186         180       440\r\n296    204         181        53\r\n297    210         186       432\r\n298    214         188       207\r\n299    222         204       104\r\n300    224         206        56\r\n301    227         210       177\r\n302    228         213        12\r\n303    238         214        52\r\n304    240         220       114\r\n305    254         222       183\r\n306    255         224        46\r\n307    261         225       341\r\n308    264         227        74\r\n309    267         228       197\r\n310    270         229        41\r\n311    272         233       148\r\n312    284         236       275\r\n313    286         237       277\r\n314    288         238       228\r\n315    292         240        47\r\n316    297         241       215\r\n317    299         242       351\r\n318    304         244       159\r\n319    305         253       434\r\n320    314         255        97\r\n321    315         260       293\r\n322    321         263       262\r\n323    325         267       323\r\n324    333         270       307\r\n325    334         272       209\r\n326    339         274       361\r\n327    343         276       319\r\n328    344         280       438\r\n329    353         282        55\r\n330    357         283       264\r\n331    358         290       210\r\n332    366         291       416\r\n333    377         292       417\r\n334    378         294       418\r\n335    379         296       419\r\n336    382         297       420\r\n337    388         298       421\r\n338    399         299       423\r\n339    403         304       433\r\n340    409         305       435\r\n341    413         309       436\r\n342    415         311        42\r\n343    433         312        80\r\n344    437         313       268\r\n345    438         314        37\r\n346    439         315       182\r\n347     28         316         2\r\n348     31         318       106\r\n349     40         320         3\r\n350     86         323       117\r\n351     89         325       132\r\n352    111         326       231\r\n353    125         327        43\r\n354    130         328        23\r\n355    149         332       208\r\n356    164         334       216\r\n357    180         338       119\r\n358    213         339       156\r\n359    220         343       334\r\n360    225         345       287\r\n361    229         348       191\r\n362    233         349       108\r\n363    237         352       285\r\n364    244         354       273\r\n365    260         355       123\r\n366    263         358       274\r\n367    274         359       224\r\n368    282         362       269\r\n369    283         363        16\r\n370    290         364       118\r\n371    291         365       175\r\n372    294         366        20\r\n373    296         367       122\r\n374    309         368        21\r\n375    311         369        84\r\n376    312         370       422\r\n377    313         371       220\r\n378    316         372       222\r\n379    327         373       225\r\n380    328         374       227\r\n381    332         375       353\r\n382    348         376       306\r\n383    349         377       213\r\n384    352         378        79\r\n385    359         379       125\r\n386    362         380       130\r\n387    363         381       348\r\n388    364         382       349\r\n389    365         383        31\r\n390    367         384       266\r\n391    368         385       145\r\n392    369         386       309\r\n393    370         387        93\r\n394    371         388       352\r\n395    372         389        73\r\n396    373         390       289\r\n397    374         391       272\r\n398    375         392       153\r\n399    380         393        28\r\n400    381         394        89\r\n401    383         395       327\r\n402    384         396       174\r\n403    385         397       288\r\n404    386         398       439\r\n405    387         399       437\r\n406    389         400       270\r\n407    390         401       286\r\n408    391         402       290\r\n409    392         403       291\r\n410    393         404       315\r\n411    394         405       254\r\n412    395         406       164\r\n413    396         407       321\r\n414    398         408       370\r\n415    400         409       140\r\n416    401         410       168\r\n417    402         411       230\r\n418    404         412       233\r\n419    405         413       237\r\n420    407         414       238\r\n421    408         415       244\r\n422    411         416       311\r\n423    412         417       312\r\n424    414         418       313\r\n425    416         419       316\r\n426    417         420       328\r\n427    418         421       229\r\n428    419         423       135\r\n429    420         424       359\r\n430    421         425       151\r\n431    423         426       282\r\n432    424         427       111\r\n433    425         428       294\r\n434    426         429       332\r\n435    427         430       263\r\n436    428         431       180\r\n437    429         433       149\r\n438    430         435       296\r\n439    431         436       260\r\n440    435         437       283\r\n441    436         439        40\r\n442    440         440        86\r\n443    441         441       441\r\n444    442         442       442\r\n445    443         443       443\r\n\r\nWhich two actors have the highest betweenness and what is unique\r\nabout their role in the course?\r\nThe top two actors that have the highest betweeness are 444 and 445.\r\nThey are also the facilitators of the group\r\n\r\nDo these same two actors also have the highest closeness? How\r\nmight you interpret that?\r\nYes, they also have the highest number of closeness as well. They\r\nhave the shortest distance path to all other nodes.\r\n\r\n4. MODEL\r\nTo be connected to others matters. To be able to share and learn from\r\neach other matters. Carolan( 2014) explains, “Teachers who share best\r\npractices with others expand their own teaching repertoires.” We\r\nexplored the Southern region participants of a MOOC-Ed discussion\r\nthrough the visualization above.\r\nAsking whether years of experience make a difference in a discussion\r\nforum? What ways are the participants connected?\r\n\r\n\r\nShow code\r\n\r\ndlt1_network |>\r\n  activate(nodes) |>\r\n  filter(region == 'South')|>\r\n  mutate(degree=centrality_degree()) |> \r\n  filter(degree>0)|>\r\n  activate(edges) |>\r\n  mutate(betweenness = centrality_edge_betweenness()) |>\r\nggraph(layout = \"stress\") +\r\n  geom_edge_link0(aes(edge_alpha = betweenness), edge_color = \"grey66\") +\r\n  geom_node_point(aes(size = degree, shape = experience2, color = group)) +\r\n  scale_edge_width_continuous(range = c(0.2, 10)) +\r\n  scale_size_continuous(range = c(1, 8)) +\r\n  ggtitle( \"MOOC-Ed Southern Region Participants\" ) +\r\n  theme( legend.key = element_rect( fill = \"white\", colour = \"black\" ), \r\n  legend.title = element_text(face = \"bold\" )) +\r\n  guides(color =FALSE)+\r\n  theme_graph() +\r\n  theme(legend.position = \"right\", legend.text = element_text(size = 6, colour = \"black\"))\r\n\r\n\r\n\r\n\r\nWhat we found was that the blue group seemed to have higher\r\ncentrality degree and betweenness. The localized degree measurement\r\ncaptures many actors in the blue group with more years of experience are\r\nhigher connected to other actors regardless of how those other actors\r\nare related to each other.\r\nWe also looked at the gatekeeper function, and those same actors\r\nwith the highest degree also had a higher betweenness score.\r\nUsing this type of analysis, the facilitator could reach out to those\r\nwith high betweenness and closeness degrees to spread information and\r\nideas to the rest of the group.\r\nTo improve this analysis, I would first look at the closeness degree\r\nand include it as an edge color. Next, I would like to explore each\r\ngroup separately. I would be able to analyze each network and the\r\nactors’ brokerage to find out if there are any consultants.\r\nReferences\r\nKellogg, Shawn (2022). Unit 3: Components, Cliques, & Key Actors.\r\nECI 589 Social Network Analysis and Education\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-04-03-closeness-betweeness-socialnetworking/SNAMOOC.png",
    "last_modified": "2022-04-03T19:52:06-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-03-data-feminism-network-graph/",
    "title": "What can Tweets tell us about Data Feminism?",
    "description": "Using a tweet data we created a network graph to look at emerging data feminism topics.",
    "author": [
      {
        "name": "Jeanne McClure",
        "url": {}
      }
    ],
    "date": "2022-03-28",
    "categories": [],
    "contents": "\r\n1. PURPOSE\r\n1a. Motivation and Focus\r\nStudying social media in the digital age can illuminate themes within\r\norganizations, topics and even agents of change.\r\nData Feminism is a specific topic of interest for me. “Data\r\nFeminism offers strategies for data scientists seeking to learn how\r\nfeminism can help them work toward justice, and for feminists who want\r\nto focus their efforts on the growing field of data science. But Data\r\nFeminism is about much more than gender. It is about power, about who\r\nhas it and who doesn’t, and about how those differentials of power can\r\nbe challenged and changed” (@DIgnazio and @Klein, 2020).\r\nGuiding Questions:\r\nFeminist Joni Seager asserts, “What get’s counted, counts!” My\r\nguiding question is: - What do recent tweets say about “Data Feminism”\r\nsince the recent SoLar Convention?\r\nI pulled data over a week after the SoLAr confernce to try and\r\nunderstand what themes emerged.\r\n1b. Load Libraries\r\nFirst, we load libraries that we will use to wrangle our data and\r\nthen visualize it. We will not use the Twitter API here as the data set\r\nwas saved.\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\nlibrary(readxl)\r\nlibrary(tidytext)\r\nlibrary(textdata)\r\nlibrary(ggplot2)\r\nlibrary(kableExtra)\r\nlibrary(scales)\r\nlibrary(rtweet)\r\nlibrary(tidyr)\r\nlibrary(stringr)\r\n\r\n\r\nlibrary(vtree)\r\nlibrary(igraph)\r\nlibrary(ggraph)\r\nlibrary(tidygraph)\r\nlibrary(networkD3)\r\nlibrary(ggplot2)\r\n\r\n#SET PARAMETERS\r\n#define colors to use throughout\r\nmy_colors <- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#CC79A7\", \"#D55E00\", \"#D65E00\")\r\n\r\ntheme_plot <- function(aticks = element_blank(),\r\n                         pgminor = element_blank(),\r\n                         lt = element_blank(),\r\n                         lp = \"none\")\r\n{\r\n  theme(plot.title = element_text(hjust = 0.5), #center the title\r\n        axis.ticks = aticks, #set axis ticks to on or off\r\n        panel.grid.minor = pgminor, #turn on or off the minor grid lines\r\n        legend.title = lt, #turn on or off the legend title\r\n        legend.position = lp) #turn on or off the legend\r\n}\r\n\r\n\r\n\r\n2. METHOD\r\n2a. Read in and Wrangle\r\nthe tweet data\r\nWe will read in the previously pulled Data Feminism tweets. Using: -\r\n“#DataFeminism” - “Data Feminism” and - “#AfrofeministDataFutures”\r\nThen subset the rows and columns to pull only English language\r\ntexts\r\nWe will bind each separate data frame into one data frame named\r\ntweets().\r\nWe will need to create a unique identifying index column for later\r\nanalysis.\r\nFinally, let’s look at the head of our new tweets() data frame.\r\nWe have 491 tweets and 91 variables. We do not need all of that so we\r\nwill wrangle our data in the next section.\r\n\r\n\r\nShow code\r\n\r\ndataF_tweets <- read_excel(\"~/r-projects/mccluredistill/_posts/2022-04-03-data-feminism-network-graph/data/dataF_tweets.xlsx\")\r\n\r\n\r\n\r\n2b. Tidy Data\r\n\r\n\r\nShow code\r\n\r\ndataF_tidy <- dataF_tweets %>%\r\n  filter(lang == \"en\") %>%\r\n  select(screen_name, created_at, text)%>%\r\n  mutate(feminism = \"data feminism\") %>%\r\n  relocate(feminism)\r\n\r\ndataF_tidy %>%\r\n  head()%>%\r\n  kbl(caption = \"Restructured Data - Data Feminism data frame\") %>%\r\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\r\n\r\n\r\n\r\nTable 1: Restructured Data - Data Feminism data frame\r\n\r\n\r\nfeminism\r\n\r\n\r\nscreen_name\r\n\r\n\r\ncreated_at\r\n\r\n\r\ntext\r\n\r\n\r\ndata feminism\r\n\r\n\r\nnandaseth\r\n\r\n\r\n2022-03-25 00:53:31\r\n\r\n\r\nData Feminism! Data. 0s and 1s Binary. Idhula enna Feminism? What karmam\r\nis this? https://t.co/qBLPu9hrqZ\r\n\r\n\r\ndata feminism\r\n\r\n\r\ndanbouk\r\n\r\n\r\n2022-03-24 14:42:25\r\n\r\n\r\n@lokendrachauhan @Keviriah @zephoria Thank you for\r\nreading! I most do history, but a great text aimed at thinking about\r\nbuilding consensus and making data do good and useful things today is\r\nData Feminism by @kanarinka &amp; @laurenfklein https://t.co/4tIGU4sUx2\r\n\r\n\r\ndata feminism\r\n\r\n\r\n14prinsp\r\n\r\n\r\n2022-03-24 13:52:58\r\n\r\n\r\nCongratulations for the organisers of #LAK22 for being courageous in\r\nopening spaces to look at #learninganalytics through lenses such as\r\ndecolonisation and data feminism. Viva!\r\n\r\n\r\ndata feminism\r\n\r\n\r\n14prinsp\r\n\r\n\r\n2022-03-24 13:12:10\r\n\r\n\r\nFirst point of data feminism to consider in #learninganalytics is “In\r\ntoday’s world, data is power” @kanarinka #LAK22 The power is distributed\r\nunequally and those who are already vulnerable, are made even more\r\nvulnerable\r\n\r\n\r\ndata feminism\r\n\r\n\r\nMamtaShah\r\n\r\n\r\n2022-03-24 13:52:09\r\n\r\n\r\nThank you for a powerful and insightful keynote on data feminism\r\n@kanarinka https://t.co/AEqFSMb1SR\r\n#LAK22 https://t.co/7CCt7BnacG\r\n\r\n\r\ndata feminism\r\n\r\n\r\nOlgaOvi\r\n\r\n\r\n2022-03-24 13:48:33\r\n\r\n\r\n“Data feminism requires an expanded definition of data visualization and\r\ndata science!” #LAK22 @kanarinka\r\n\r\n\r\nTokenize words\r\nWe will tidy our text using the tidytext and dplyr packages to split\r\nthe text into two tokens (bigrams)creating a table with\r\none-token-per-row . The token is under a column called word(). Another\r\nstep to tidy the text is to remove the most common stop words such as a,\r\nthe, is, are, amp, and, etc.\r\nBefore we break them into bigrams let’s inspect one token to ee if\r\nthere is any other nonsense words we need to eliminate.\r\n\r\n\r\nShow code\r\n\r\n#tokenize tweets\r\ntweet_tokens <- \r\n  dataF_tidy %>%\r\n  unnest_tokens(output = word, \r\n                input = text, \r\n                token = \"tweets\")\r\n\r\n#Tidy text and get rid of #art (nonsenese word that turned up with Canvas)\r\ndataFem_tweets <-\r\n  tweet_tokens %>%\r\n  anti_join(stop_words, by = \"word\")\r\n\r\ndataFem_tweets%>%\r\n  head%>%\r\n  kbl(caption = \"tokenized dataFem data frame\") %>%\r\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\r\n\r\n\r\n\r\nTable 2: tokenized dataFem data frame\r\n\r\n\r\nfeminism\r\n\r\n\r\nscreen_name\r\n\r\n\r\ncreated_at\r\n\r\n\r\nword\r\n\r\n\r\ndata feminism\r\n\r\n\r\nnandaseth\r\n\r\n\r\n2022-03-25 00:53:31\r\n\r\n\r\ndata\r\n\r\n\r\ndata feminism\r\n\r\n\r\nnandaseth\r\n\r\n\r\n2022-03-25 00:53:31\r\n\r\n\r\nfeminism\r\n\r\n\r\ndata feminism\r\n\r\n\r\nnandaseth\r\n\r\n\r\n2022-03-25 00:53:31\r\n\r\n\r\ndata\r\n\r\n\r\ndata feminism\r\n\r\n\r\nnandaseth\r\n\r\n\r\n2022-03-25 00:53:31\r\n\r\n\r\n0s\r\n\r\n\r\ndata feminism\r\n\r\n\r\nnandaseth\r\n\r\n\r\n2022-03-25 00:53:31\r\n\r\n\r\n1s\r\n\r\n\r\ndata feminism\r\n\r\n\r\nnandaseth\r\n\r\n\r\n2022-03-25 00:53:31\r\n\r\n\r\nbinary\r\n\r\n\r\n3. Explore\r\n3a. Tokenized single word\r\ncount\r\nLet’s look the word count for the dataFem_tweets to see if we see any\r\nemerging themes. We can see a high number if Data Science themes and\r\nhashtags. We can go ahead and create our bigrams in the next\r\nsection.\r\n\r\n\r\nShow code\r\n\r\ndataFem_tweets %>%\r\n  count(word, sort = TRUE) \r\n\r\n\r\n# A tibble: 2,793 x 2\r\n   word              n\r\n   <chr>         <int>\r\n 1 #femtech        398\r\n 2 100daysofcode   124\r\n 3 #womenwhocode   122\r\n 4 #womenintech    109\r\n 5 #ml             103\r\n 6 #iot             94\r\n 7 #ai              72\r\n 8 #iiot            66\r\n 9 #python          66\r\n10 #flutter         63\r\n# ... with 2,783 more rows\r\n\r\n3b. Create Bigram\r\nBelow let’s create our Bigrams by removing hashtags, and other\r\nnonsense words. You now see that we have 145 observations and two\r\nvariables\r\n\r\n\r\nShow code\r\n\r\n# regex for parsing tweets\r\nreplace_reg <- \"https?://[^\\\\s]+|&amp;|&lt;|&gt;|&d2l;|&aristotlemrs;|&aleks;|\\bRT\\\\b\"\r\n# split into word pairs\r\ndataF_bigrams <- dataF_tidy %>% \r\n  mutate(text = str_replace_all(text, replace_reg, \"\")) %>%\r\n  unnest_tokens(bigram, text, token = \"ngrams\", n = 2)\r\n\r\n# remove stop words\r\ndataF_bigrams <- dataF_bigrams %>%\r\n  separate(bigram, into = c(\"first\",\"second\"), sep = \" \", remove = FALSE) %>%\r\n  anti_join(stop_words, by = c(\"first\" = \"word\")) %>%\r\n  anti_join(stop_words, by = c(\"second\" = \"word\")) %>%\r\n  filter(str_detect(first, \"[a-z]\") &\r\n         str_detect(second, \"[a-z]\"))\r\n\r\nbigrams_united <- dataF_bigrams%>%\r\n  unite(bigram, first, second, sep = \" \")\r\n\r\nbigrams_united\r\n\r\n\r\n# A tibble: 5,805 x 4\r\n   feminism      screen_name created_at          bigram               \r\n   <chr>         <chr>       <dttm>              <chr>                \r\n 1 data feminism nandaseth   2022-03-25 00:53:31 data feminism        \r\n 2 data feminism nandaseth   2022-03-25 00:53:31 feminism data        \r\n 3 data feminism nandaseth   2022-03-25 00:53:31 data 0s              \r\n 4 data feminism nandaseth   2022-03-25 00:53:31 1s binary            \r\n 5 data feminism nandaseth   2022-03-25 00:53:31 binary idhula        \r\n 6 data feminism nandaseth   2022-03-25 00:53:31 idhula enna          \r\n 7 data feminism nandaseth   2022-03-25 00:53:31 enna feminism        \r\n 8 data feminism danbouk     2022-03-24 14:42:25 lokendrachauhan kevi~\r\n 9 data feminism danbouk     2022-03-24 14:42:25 keviriah zephoria    \r\n10 data feminism danbouk     2022-03-24 14:42:25 text aimed           \r\n# ... with 5,795 more rows\r\n\r\nShow code\r\n\r\n#count up new birgams and create a new column called n only keep more than 5 counts\r\ndataF_bigrams_count <- dataF_bigrams %>%\r\n  group_by(screen_name, bigram, first, second)%>%\r\n  summarise(n=n())%>%\r\n  filter(n >= 5)%>%\r\n  arrange(-n)%>%\r\n  ungroup()\r\n\r\n\r\ndataF_bigrams_count %>%\r\n  count(bigram, sort = TRUE) \r\n\r\n\r\n# A tibble: 145 x 2\r\n   bigram                    n\r\n   <chr>                 <int>\r\n 1 iot iiot                  3\r\n 2 100daysofcode femtech     2\r\n 3 ai ml                     2\r\n 4 analytics rstats          2\r\n 5 ar ml                     2\r\n 6 cloud bigdata             2\r\n 7 femtech ar                2\r\n 8 flutter javascript        2\r\n 9 iiot nlp                  2\r\n10 java 100daysofcode        2\r\n# ... with 135 more rows\r\n\r\nAgain, we see a high prevalence of Data Science terms.\r\n4 Model\r\n4a. GGRAPH of Bigrams\r\nHere we will plot our bigrams in a network graph using ggraph\r\npackage. We can see that there is some central bigrams with radiating\r\nnodes.\r\n\r\n\r\nShow code\r\n\r\n# Rename and reorder columns (so we can make the graphs more easily)\r\ndataF_bigram_tbl <- dataF_bigrams_count %>%\r\n  dplyr::select(c('first','second', 'n'))\r\n\r\n\r\nbigram_graph <- dataF_bigram_tbl %>%\r\n  filter(n > 10) %>%\r\n  graph_from_data_frame()\r\n\r\n\r\nset.seed(123)\r\n\r\n\r\np <- ggraph(bigram_graph, layout = \"fr\") +\r\n    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE) +\r\n    geom_node_point(color = \"lightblue\", size = 5) +\r\n    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\r\n theme_graph() +\r\n  theme(legend.position = \"none\")\r\n\r\np\r\n\r\n\r\n\r\n\r\n5. COMMUNICATE\r\nPurpose - The purpose of the case study is to look at the **social\r\nnetwork* of Bigrams from a Tweet Dataset on Data Feminism pulled\r\npreviously during the SoLar Conference. Understanding how information is\r\nshared within the network is important to understand what topics or\r\nthemes for future research.\r\nMethods - For this independent analysis I explored tweet Bigrams\r\nwhich is a text mining process.\r\nFindings - Several top Cluster themes stood out: - Women who Code -\r\nfemtech - IOT (Internet of Things) - ML (Machine Learning)\r\nThe words are paired by co-occurrence.\r\nDiscussion - Bigrams network might show the general idea of the\r\ncontent of the information gathered in twitter posts. Insights from a\r\ncase study like this may be used to guide Public and Private\r\norganizations looking to monitor how information regarding research or\r\nproduct launch. A Bigram analysis from collected Tweets may show terms\r\nthat may not be identical to other analysis.\r\nReferences: D’ignazio, C., & Klein, L. F. (2020). Data feminism.\r\nMIT press.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-04-03-data-feminism-network-graph/dfnetwork.png",
    "last_modified": "2022-04-03T18:47:01-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-03-bigrams-of-lms/",
    "title": "Social Network Analysis of Tweet Bigrams from Sentiment of four popular Learning Management Systems",
    "description": "Early work using ggraph and igraph",
    "author": [
      {
        "name": "Jeanne McClure",
        "url": {}
      }
    ],
    "date": "2022-02-10",
    "categories": [],
    "contents": "\r\n1. PURPOSE\r\n1a. Motivation and Focus\r\nWe completed a sentiment analysis on four popular\r\n*Learning Management Systems (LMS); Google Classroom,\r\nCanvas, Moodle, and Blackboard, in a previous case study. We evaluated\r\nemotions and sentiment towards each LMS by assessing the most common\r\nuniwords. We evaluated strengths and weaknesses by pulling public\r\nopinion from the Twitter Resting API.\r\nWe will evaluate connections between the most frequent combination of\r\nwords (Bigrams) through Social Network Analysis. Here we’ll explore this\r\noption for the tweets made in English for the 4 LMS previously\r\nobserved.\r\nGuiding Questions:\r\nAre there networks from the co-occurrence of Bigrams?\r\nWhat does the mathematical analysis of the Bigram network tell\r\nus?\r\n1b. Load Libraries\r\nLet’s first load our libraries to read in packages that we will use\r\nto answer our questions. We will also create a function called\r\nreplace_reg() by looking for and deleting strings (nonsense words),\r\nnumbers, and other manual stop characters and numbers.\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidytext)\r\nlibrary(tidyverse)\r\nlibrary(network)\r\nlibrary(sna)\r\nlibrary(visNetwork)\r\nlibrary(threejs)\r\nlibrary(ndtv)\r\nlibrary(qgraph)\r\nlibrary(splitstackshape)\r\nlibrary(tidyr)\r\nlibrary(stringr)\r\nlibrary(readxl)\r\nlibrary(readr)\r\n\r\n# For visualizations\r\nlibrary(vtree)\r\nlibrary(igraph)\r\nlibrary(ggraph)\r\nlibrary(tidygraph)\r\nlibrary(networkD3)\r\nlibrary(ggplot2)\r\n\r\n# regex for parsing tweets\r\nreplace_reg <- \"https?://[^\\\\s]+|&amp;|&lt;|&gt;|&d2l;|&aristotlemrs;|&aleks;|\\bRT\\\\b\"\r\n\r\n# Custom Color Palette\r\nmy_colors <- c(\"#05A4C0\", \"#85CEDA\", \"#D2A7D8\", \"#A67BC5\", \"#BB1C8B\", \"#8D266E\")\r\n\r\n\r\n\r\n2. METHOD\r\nOur initial read-in data frame includes 4521 tweets \r\nobjects in the text to evaluate. After tokenizing the Bigrams and\r\nrestructuring the data objects, we will include Bigrams mentioned more\r\nthan five times. Once tidyed, the data consists of 1407\r\nbigrams left to evaluate with a social network approach.\r\n2a. Read and Restructure Data\r\nRead in the previously evaluated LMS data for Google Classroom\r\ntweets, Blackboard tweets, Canvas tweets, and Moodle tweets.\r\nSubset columns to pull only index, lms and text columns.\r\nVisualize the initial number of tweets for each LMS.\r\n\r\n\r\nShow code\r\n\r\ntweets <- read_excel(\"data/tweets.xlsx\")\r\n\r\n#select lms, text and index, grouping by lms\r\ntweets_data2 <- tweets %>% \r\n  select(c('index', 'lms', 'text')) %>% \r\n  group_by(lms) %>%\r\n  na.omit()\r\n\r\n\r\nvtree(tweets_data2, \"lms\", horiz=FALSE, palette = 4, sortfill = TRUE, title=\"Initial LMS Tweets Data\")\r\n\r\n\r\n\r\n\r\n2b. Tidytext and Initiate\r\nBigram\r\nUsing the tidytext and dplyr packages we split the text\r\ninto tokens creating a table with two-tokens-per-row. The token is under\r\na column called “bigram.”\r\nSubset the bigram columns by separating and adding two columns\r\n“first” and “second.””\r\nRemove stop words and manual stop words using our str_detect()\r\ndictionary and remove words that are not letter strings.\r\nGroup our lms_bigram() to count up the bigrams, summarize keeping\r\nonly those that appear more than 5 times.\r\nVisualizing the new numbers for each LMS.\r\n\r\n\r\nShow code\r\n\r\n# split into word pairs\r\nlms_bigrams <- tweets_data2 %>% \r\n  mutate(text = str_replace_all(text, replace_reg, \"\")) %>%\r\n  unnest_tokens(bigram, text, token = \"ngrams\", n = 2)\r\n\r\n# remove stop words\r\nlms_bigrams <- lms_bigrams %>%\r\n  separate(bigram, into = c(\"first\",\"second\"), sep = \" \", remove = FALSE) %>%\r\n  anti_join(stop_words, by = c(\"first\" = \"word\")) %>%\r\n  anti_join(stop_words, by = c(\"second\" = \"word\")) %>%\r\n  filter(str_detect(first, \"[a-z]\") &\r\n         str_detect(second, \"[a-z]\"))\r\n\r\n#count up new birgams and create a new column called n only keep more than 5 counts\r\nlms_bigrams_count <- lms_bigrams %>%\r\n  group_by(lms, bigram, first, second)%>%\r\n  summarise(n=n())%>%\r\n  filter(n >= 5)%>%\r\n  arrange(-n)%>%\r\n  ungroup()\r\n\r\n#visualize new number of rows (previously counting tweets)\r\nvtree(lms_bigrams_count, \"lms\", horiz=FALSE, palette = 4, sortfill = TRUE, title=\"Bigram LMS Tweets Data\")\r\n\r\n\r\n\r\n\r\n3. EXPLORE\r\n3a. Subset Coloumns\r\nand visualize Bigrams\r\nSelect first, second and n columns create lms_bigram_tble data frame\r\nto use later in the Social Network Analysis.\r\nVisually inspect Bigrams mentioned more than 35 times through an\r\nigraph to observe any communities in the network.\r\n\r\n\r\nShow code\r\n\r\n# Rename and reorder columns (so we can make the graphs more easily)\r\nlms_bigram_tbl <- lms_bigrams_count %>%\r\n  dplyr::select(c('first','second', 'n'))\r\n\r\n\r\nbigram_graph <- lms_bigram_tbl %>%\r\n  filter(n > 35) %>%\r\n  graph_from_data_frame()\r\n\r\n\r\nset.seed(123)\r\n\r\na <- grid::arrow(type = \"closed\", length = unit(.15, \"inches\"))\r\n\r\nggraph(bigram_graph, layout = \"fr\") +\r\n    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a) +\r\n    geom_node_point(color = \"lightblue\", size = 5) +\r\n    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\r\n    theme_void()\r\n\r\n\r\n\r\n\r\n4. MODEL\r\nTo evaluate Social Network for Bigrams we will create a igraph and\r\ntable graph class network. This will easily allow for visualizing the\r\nconnections and explaining the network mathmatically.\r\n4a. Edges and Nodes\r\nNodes are the unique words - each word has an identification ID edges\r\nare the bigrams, meaning that they show how frequently we find a\r\ncombination of 2 words (represented by their unique ID).\r\nCreate a source for the first word of the bigram\r\nCreate a destination for the second word of the bigram\r\nCreate Nodes\r\nCreate Edges\r\nSelect only to, from and weight\r\nInspect i. head of Node and ii. head of Edges and save for later\r\nuse.\r\n\r\n\r\nShow code\r\n\r\n#filter to Bigrams that are mentioned more than 35 times.\r\nlms_df <- lms_bigram_tbl %>%\r\n  filter(n > 35) \r\n# Distinct first (part of bigram)\r\nsources <- lms_df%>% \r\n                distinct(first) %>% \r\n                rename(label = first)\r\n\r\n# Distinct second (part of bigram)\r\ndestinations <- lms_df %>% \r\n                    distinct(second) %>% \r\n                    rename(label = second)\r\n\r\n#NODES AND EDGES BELOW:\r\n\r\n# ----- NODES -----\r\n# Unique Items + create unique ID\r\nnodes <- full_join(sources, destinations, by=\"label\") %>% rowid_to_column(\"id\")\r\n\r\n# ----- EDGES -----\r\n# Adds unique ID of Item 1 to data\r\nedges <- lms_df %>% \r\n            left_join(nodes, by = c(\"first\" = \"label\")) %>% \r\n            rename(from = id)\r\n\r\n# Adds unique ID of Item 2 to data\r\nedges <- edges %>% \r\n            left_join(nodes, by = c(\"second\" = \"label\")) %>% \r\n            rename(to = id) %>% \r\n            rename(weight = n)\r\n\r\n# Select only From | To | Weight (frequency)\r\nedges <- edges %>% select(from, to, weight)\r\n\r\n\r\n\r\nInspect head of node\r\n\r\n\r\nShow code\r\n\r\n# inspect head of nodes and edges\r\nnodes %>% \r\n  head(5)\r\n\r\n\r\n\r\n# A tibble: 5 x 2\r\n     id label  \r\n  <int> <chr>  \r\n1     1 google \r\n2     2 canvas \r\n3     3 essay  \r\n4     4 pearson\r\n5     5 aleks  \r\n\r\nInspect head of edges\r\n\r\n\r\nShow code\r\n\r\nedges %>% \r\n  head(5)\r\n\r\n\r\n\r\n# A tibble: 5 x 3\r\n   from    to weight\r\n  <int> <int>  <int>\r\n1     1    83   1688\r\n2     2     4    309\r\n3     3     9    232\r\n4     3    10    187\r\n5     4     7    182\r\n\r\nShow code\r\n\r\n# Export the nodes & edges data as we may want to use it in the future.\r\nwrite.csv(nodes,\"data/nodes.csv\", row.names = FALSE)\r\nwrite.csv(edges,\"data/edges.csv\", row.names = FALSE)\r\n\r\n\r\n\r\n4b. igraph\r\nCreate igraph\r\nInspect Edges and Vertices of net1 object ii.Inspect the igraph\r\nvisually.\r\n\r\n\r\nShow code\r\n\r\n# Create network\r\nnet1 <- graph_from_data_frame(d = edges, vertices = nodes, directed = TRUE)\r\n\r\n\r\n\r\nThe edges of the “net” object\r\n\r\n\r\nShow code\r\n\r\nE(net1)       # The edges of the \"net\" object\r\n\r\n\r\n\r\n+ 115/115 edges from f4684d2 (vertex names):\r\n [1] 1 ->83  2 ->4   3 ->9   3 ->10  4 ->7   5 ->2   6 ->13  7 ->5  \r\n [9] 8 ->11  9 ->10  4 ->5   10->3   11->10  12->89  13->14  14->90 \r\n[17] 15->2   16->72  17->91  2 ->92  18->93  19->1   5 ->7   20->26 \r\n[25] 21->20  22->25  23->21  24->94  25->33  26->27  27->29  28->32 \r\n[33] 29->30  30->31  31->28  10->95  2 ->71  32->66  16->51  2 ->16 \r\n[41] 33->28  34->16  35->37  36->39  37->36  38->70  39->41  40->2  \r\n[49] 28->7   41->43  42->40  43->42  44->48  16->50  45->46  46->49 \r\n[57] 47->44  48->45  49->16  50->38  51->47  52->96  2 ->75  53->97 \r\n[65] 6 ->98  54->99  55->2   56->55  9 ->59  57->100 58->3   22->4  \r\n[73] 14->95  11->9   59->53  60->10  61->101 62->63  63->2   64->102\r\n+ ... omitted several edges\r\n\r\nThe vertices of the “net” object\r\n\r\n\r\nShow code\r\n\r\nV(net1)       # The vertices of the \"net\" object\r\n\r\n\r\n\r\n+ 112/112 vertices, named, from f4684d2:\r\n  [1] 1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16 \r\n [17] 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32 \r\n [33] 33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48 \r\n [49] 49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \r\n [65] 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \r\n [81] 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96 \r\n [97] 97  98  99  100 101 102 103 104 105 106 107 108 109 110 111 112\r\n\r\nVisualize the igraph\r\nWe reduced the Bigrams to only include more than 35 mentions but the\r\nvisualization is cluttered with the names of the bigrams and hard to\r\nread.\r\n\r\n\r\nShow code\r\n\r\nedge.start <- ends(net1, es=E(net1), names=F)[,1]\r\n\r\nedge.col <- V(net1)$color[edge.start]\r\n\r\nplot(net1, edge.color=edge.col, edge.curved=.1) \r\n\r\n\r\n\r\n\r\n4c. Convert to Table Graph\r\nclass\r\nInspect class() of object networks.\r\nConvert to table graph.\r\n+We can see that net1 is a class of igraph. TO go further we need to\r\nchange to table graph class, this will add a weight column. Second, we\r\nwill visualize our added weight column.\r\nnet1 class\r\n\r\n\r\nShow code\r\n\r\n#check class\r\nclass(net1)\r\n\r\n\r\n\r\n[1] \"igraph\"\r\n\r\nConvert to table graph and inspect class.\r\n\r\n\r\nShow code\r\n\r\n#update to table graph for weight\r\nnet2 <- as_tbl_graph(net1)\r\nclass(net2)\r\n\r\n\r\n\r\n[1] \"tbl_graph\" \"igraph\"   \r\n\r\nVisualize the table graph with weight\r\n\r\n\r\nShow code\r\n\r\nggraph(net2, layout = \"fr\") +\r\n  geom_node_point(size = 3) +\r\n  geom_edge_link(aes(colour = weight)) +\r\n  theme_graph()\r\n\r\n\r\n\r\n\r\n\r\n4d. Describe the Network\r\nMathematically\r\nNetwork Size\r\nCentrality\r\nDensity\r\nReciprocity\r\nTransitivity\r\nDiameter and Density\r\nMean\r\nHubs and Authorities\r\na. Network Size\r\nThe size of a network centers around the number of nodes and edges in\r\na network. Here we can see: - i. number of vertices is 112. -\r\nii. number of edges is 115.\r\nnumber of vertices\r\n\r\n\r\nShow code\r\n\r\n#number of vertices\r\ngorder(net2)\r\n\r\n\r\n\r\n[1] 112\r\n\r\nnumber of edges\r\n\r\n\r\nShow code\r\n\r\n#number of edges\r\ngsize(net2)\r\n\r\n\r\n\r\n[1] 115\r\n\r\nb. Centrality\r\nDegree measures the extent to which relations are focused on one or a\r\nsmall set of actors. Degree refers to the number of ties an actor either\r\nsends (out-degree), receives (in-degree), or in the case of a\r\nnon-directed network or both sent and received in a directed network,\r\nsimply just “degree” for all actors to which one is connected.\r\nAll centrality Score of 0.054.\r\n\r\nIn-degree centrality score of 0.072.\r\n\r\nOut-degree centrality score of 0.036.\r\n\r\nThe Bigram network seems to have a very decentralize graph, slightly\r\nmore centralized around in-degree.\r\nCalculate “all” degree centrality score and run centrality - “all”\r\nand add to out network\r\n\r\n\r\nShow code\r\n\r\n#calculate all-degree score\r\ncentr_degree(net2, mode = \"all\")\r\n\r\n\r\n\r\n$res\r\n  [1]  2 14  5  4  4  2  6  1  7  8  4  1  2  3  2  8  2  1  1  2  2\r\n [22]  2  1  1  2  2  2  4  2  2  2  2  2  1  2  2  2  2  2  2  2  2\r\n [43]  2  2  2  2  2  2  2  2  2  1  5  1  2  1  2  1  2  2  1  1  2\r\n [64]  1  2  2  2  2  2  2  3  2  1  1  2  1  2  3  2  2  1  2  2  1\r\n [85]  1  2  1  1  1  1  1  1  1  2  2  1  1  1  1  1  1  1  1  1  1\r\n[106]  1  1  1  1  1  1  1\r\n\r\n$centralization\r\n[1] 0.05429754\r\n\r\n$theoretical_max\r\n[1] 24642\r\n\r\nShow code\r\n\r\n#activate the actors degree\r\nnet2 <- net2 |>\r\n  activate(nodes) |>\r\n  mutate(degree = centrality_degree(mode = \"all\"))\r\n\r\n\r\n\r\nCalculate “in” degree centrality score and run centrality - “in” and\r\nadd to out network\r\n\r\n\r\nShow code\r\n\r\n#calculate in-degree score\r\ncentr_degree(net2, mode = \"in\")\r\n\r\n\r\n\r\n$res\r\n  [1] 1 9 3 2 2 0 3 0 3 4 2 0 1 1 0 3 1 0 0 1 1 0 0 0 1 1 1 2 1 1 1 1\r\n [33] 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 0 1 0 1 0 1 1 0 0 1 0\r\n [65] 1 1 1 1 1 1 2 1 0 0 1 0 1 2 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 2 2 1\r\n [97] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n\r\n$centralization\r\n[1] 0.07183076\r\n\r\n$theoretical_max\r\n[1] 12432\r\n\r\nShow code\r\n\r\n#activate the actors degree\r\nnet2 <- net2 |>\r\n  activate(nodes) |>\r\n  mutate(degree = centrality_degree(mode = \"in\"))\r\n\r\n\r\n\r\nCalculate “out” degree centrality score and Run centrality - “out”\r\nand add to out network.\r\n\r\n\r\nShow code\r\n\r\n#calculate out-degree score\r\ncentr_degree(net2, mode = \"out\")\r\n\r\n\r\n\r\n$res\r\n  [1] 1 5 2 2 2 2 3 1 4 4 2 1 1 2 2 5 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1\r\n [33] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1\r\n [65] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\r\n [97] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n\r\n$centralization\r\n[1] 0.03579472\r\n\r\n$theoretical_max\r\n[1] 12432\r\n\r\nShow code\r\n\r\n#activate the actors degree\r\nnet2 <- net2 |>\r\n  activate(nodes) |>\r\n  mutate(degree = centrality_degree(mode = \"out\"))\r\n\r\n\r\n\r\nVisualize Centrality degree\r\n\r\n\r\nShow code\r\n\r\n#Inspect degree visually\r\nggraph(net2) +\r\n  geom_node_point(aes(size = degree, color = degree)) +\r\n  geom_edge_link(aes(color = weight)) +\r\n  theme_graph()\r\n\r\n\r\n\r\n\r\n\r\nc. Density\r\nWe can see that we have a very low density at 0.0093. The\r\ncloser this number is to 1.0, the denser the network. It appears that\r\nout network does not have very many ties.\r\n\r\n\r\nShow code\r\n\r\n#calculate edge density\r\ngraph.density(net2)\r\n\r\n\r\n[1] 0.009250322\r\n\r\nd. Reciprocity\r\nReciprocity reveals the direction through which resources in networks\r\nflow between dyads and whether or not it flows in both directions.\r\nCalculate reciprocity.\r\nView reciprocity between dyads.\r\nInspect reciprocity Visually.\r\nThe reciprocity of 0.087 implies that response between\r\nactors with positive action is low.\r\nCalculate reciprocity\r\n\r\n\r\nShow code\r\n\r\n#calculate reciprocity\r\nreciprocity(net2)\r\n\r\n\r\n\r\n[1] 0.08695652\r\n\r\nView table graph reciprocity between actors.\r\n\r\n\r\nShow code\r\n\r\nnet2 <- net2 |>\r\n  activate(edges) |>\r\n  mutate(reciprocated = edge_is_mutual())\r\nnet2\r\n\r\n\r\n\r\n# A tbl_graph: 112 nodes and 115 edges\r\n#\r\n# A directed simple graph with 13 components\r\n#\r\n# Edge Data: 115 x 4 (active)\r\n   from    to weight reciprocated\r\n  <int> <int>  <int> <lgl>       \r\n1     1    83   1688 FALSE       \r\n2     2     4    309 FALSE       \r\n3     3     9    232 TRUE        \r\n4     3    10    187 TRUE        \r\n5     4     7    182 FALSE       \r\n6     5     2    170 FALSE       \r\n# ... with 109 more rows\r\n#\r\n# Node Data: 112 x 3\r\n  name  label  degree\r\n  <chr> <chr>   <dbl>\r\n1 1     google      1\r\n2 2     canvas      5\r\n3 3     essay       2\r\n# ... with 109 more rows\r\n\r\nVisualize the reciprocity\r\n\r\n\r\nShow code\r\n\r\nggraph(net2) +\r\n  geom_node_point(aes(size = degree)) +\r\n  geom_edge_link(aes(color = reciprocated)) +\r\n  theme_graph()\r\n\r\n\r\n\r\n\r\n\r\ne. Transitivity\r\nTransitivity focuses on triads, or any “triple” of actors.\r\nTransitivity is connected to actors’ tendencies to divide into exclusive\r\nsubgroups or cluster over time, especially around positive relations\r\nsuch as friendship.\r\nTransitivity of 0.105\r\n\r\n\r\nShow code\r\n\r\n#calculate transitivity\r\ntransitivity(net2)\r\n\r\n\r\n[1] 0.1052632\r\n\r\nf. Diameter and Distance\r\nA network diameter is the longest geodesic distance (length of the\r\nshortest path between two nodes) in the network.\r\nView diameter.\r\nInspect diameter visually.\r\nDiamter calculation\r\n\r\nShow code\r\n\r\ndiam <- get_diameter(net2, directed=T)\r\ndiam\r\n\r\n\r\n\r\n+ 4/112 vertices, named, from f4684d2:\r\n[1] 19  1   83  109\r\n\r\nInspect diameter visually.\r\n\r\n\r\nShow code\r\n\r\nvcol <- rep(\"gray40\", vcount(net2))\r\n\r\nvcol[diam] <- \"gold\"\r\n\r\necol <- rep(\"gray80\", ecount(net2))\r\n\r\necol[E(net2, path=diam)] <- \"orange\" \r\n\r\n# E(net, path=diam) finds edges along a path, here 'diam'\r\n\r\nplot(net2, vertex.label=NA, vertex.color=vcol, edge.color=ecol, edge.arrow.mode=0)\r\n\r\n\r\n\r\n\r\ng. Mean Distance\r\nThe average path length, measures the mean distance between all pairs\r\nof actors in the network.\r\nCalculate mean distance\r\n\r\n\r\nShow code\r\n\r\n#calculate the mean distance\r\nmean_distance(net2) \r\n\r\n\r\n[1] 6.883668\r\n\r\nh. Hubs and Authorities\r\nHubs expect to contain large number of outgoing links and authorities\r\nget many incoming links from hubs.\r\nThe graphical visualization of our network seems to have very little\r\ncoming into authorities from the Hubs.\r\nInspect Hubs and Authorities visually.\r\n\r\n\r\nShow code\r\n\r\n\r\nhs <- hub_score(net2, weights=NA)$vector\r\n\r\nas <- authority_score(net2, weights=NA)$vector\r\npar(mfrow=c(1,2))\r\nplot(net2, vertex.label=NA, vertex.size=hs*50,\r\nmain=“Hubs”)\r\nplot(net2, vertex.label=NA, vertex.size=as*30,\r\nmain=“Authorities”) \r\n\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\n# compute degree as node size\r\nV(net2)$size <- degree(net2)\r\nnet2\r\n\r\n\r\n# A tbl_graph: 112 nodes and 115 edges\r\n#\r\n# A directed simple graph with 13 components\r\n#\r\n# Edge Data: 115 x 4 (active)\r\n   from    to weight reciprocated\r\n  <int> <int>  <int> <lgl>       \r\n1     1    83   1688 FALSE       \r\n2     2     4    309 FALSE       \r\n3     3     9    232 TRUE        \r\n4     3    10    187 TRUE        \r\n5     4     7    182 FALSE       \r\n6     5     2    170 FALSE       \r\n# ... with 109 more rows\r\n#\r\n# Node Data: 112 x 4\r\n  name  label  degree  size\r\n  <chr> <chr>   <dbl> <dbl>\r\n1 1     google      1     2\r\n2 2     canvas      5    14\r\n3 3     essay       2     5\r\n# ... with 109 more rows\r\n\r\nShow code\r\n\r\nggraph(net2,layout = \"stress\") +\r\n  geom_edge_link0(aes(),edge_colour = \"grey66\") +\r\n  geom_node_point(aes(size = degree),shape = 21) +\r\n  geom_node_text(aes(filter = size >= 26, label = name),\r\n                 family=\"serif\") +\r\n  scale_size(range = c(1,6)) +\r\n  theme_graph() +\r\n  theme(legend.position = \"right\") +\r\n  labs(size = \"# Connections\") +\r\n  labs(title = \"District Administrator Network\", subtitle = \r\n       \"Connections & Key Actors\")\r\n\r\n\r\n\r\n\r\n5. COMMUNICATE\r\nPurpose -  The purpose of the case study is to\r\nlook at the **social network* of Bigrams from a Tweet data set pulled\r\npreviously on Sentiment for four popular Learning Management\r\nSystems(LMS); Google Classroom, Canvas, Moodle, and Blackboard.\r\nUnderstanding how information is shared within the network is important\r\nto understand for why a LMS may be mentioned more than another LMS on\r\nTwitter.\r\nMethods - For this independent analysis I\r\nexplored tweet Bigrams, Social Networks, and Network Analysis\r\nMathematically.\r\nFindings - The LMS, Google Classroom, Canvas,\r\nMoodle, and Blackboard did not seems to have a very good flow of\r\ninformation.\r\nThe words are paired by co-occurrence. by networks. ++ Canvas\r\nbeing a top network.\r\nA slightly higher In-Degree connection.\r\nThe authorities did not receive very much coming from the\r\nHubs.\r\nDiscussion - Bigrams network might show the\r\ngeneral idea of the content of the information gathered in twitter\r\nposts. Insights from a case study like this may be used to guide Public\r\nand Private organizations looking to monitor how information regarding\r\nthe product is transmitted. A Bigram analysis from collected Tweets may\r\nshow terms that may not be identical to other analysis. We did not\r\ninclude retweets within out data. I suggest leaving retweets in and\r\nevaluating 2 LMS at a time to see if the passing of information within a\r\nnetwork is higher.\r\nReferences:\r\nHachaj, T., & Ogiela, M. R. (2018, October). What Can Be Learned\r\nfrom Bigrams Analysis of Messages in Social Network?. In 2018 11th\r\nInternational Congress on Image and Signal Processing, BioMedical\r\nEngineering and Informatics (CISP-BMEI) (pp. 1-4). IEEE.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-04-03-bigrams-of-lms/centrality.png",
    "last_modified": "2022-04-03T21:10:19-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-03-sentiment-analysis-lms/",
    "title": "LMS Twitter Sentiment Analysis",
    "description": "A Project using Twitter Data of four popular Learning Management Systems",
    "author": [
      {
        "name": "Jeanne McClure",
        "url": {}
      }
    ],
    "date": "2022-02-06",
    "categories": [],
    "contents": "\r\n1 PURPOSE\r\n1a. Motivation and Focus\r\nIn today’s society, it is pretty normal to share your opinion about a\r\nproduct or service through Social Media platforms like Facebook,\r\nInstagram or Twitter. Organizations want to know public views on their\r\nproducts and services to optimize their customer base and revenue. The\r\npublic also wants to understand public opinion before buying or using an\r\norganization’s product or service.\r\nIn public and private programs, the education of students and\r\nemployees relies heavily on using the right Learning Management\r\nSystem (LMS) to share information and educate in K-12, University,\r\nfor-profit or non-profit sectors. Today, we are in a time of\r\nuncertainty. It is more important than ever to choose the suitable LMS\r\nas you may need to “go online” at the drop of a hat or instead do I dare\r\nshutter the word - “quarantine.” The investment is too significant not\r\nto understand the users’ sentiments on using the most popular Learning\r\nManagement Systems on the market today; Google Classroom, Canvas,\r\nMoodle, and Blackboard.\r\nOne way to understand a Learning Management Systems strengths and\r\nweaknesses are by pulling public opinion from Twitter API to evaluate\r\nusing an Unstructured ML approach with Text (opinion) Mining and\r\nSentiment Analysis. We will assess the public sentiment of\r\nthese four popular Learning Management Systems, identifying public\r\nsentiment and by asking the following questions:\r\nWhat are the most frequent words used in reference to tweets\r\nabout four popular Learning Management Systems?\r\nWhich Learning Management System is the most popular in tweets\r\nfrom January 30 - February 1, 2022.\r\nHow does the current sentiments in each lexicon compare\r\nbetween:\r\nGoogle Classroom\r\nCanvas\r\nMoodle\r\nBlackboard\r\n\r\n1b. Load Libraries\r\nLet’s first load our libraries to read in packages that we will use\r\nto answer our questions. Additionally, let’s set colors to use\r\nthroughout and write a function to save in our Global Environment to use\r\nlater with ggplot in the MODEL Section.\r\n\r\n\r\nShow code\r\n\r\n#Instal packages for wrangling\r\nlibrary(dplyr)\r\nlibrary(tidyverse)\r\nlibrary(readr)\r\nlibrary(tidyr)\r\nlibrary(rtweet) \r\nlibrary(writexl)\r\nlibrary(readxl)\r\nlibrary(tidytext)\r\nlibrary(textdata)\r\n\r\n# for visualizations\r\nlibrary(ggplot2)\r\nlibrary(scales)\r\nlibrary(wordcloud2)\r\nlibrary(gridExtra) \r\nlibrary(knitr) \r\nlibrary(kableExtra) \r\nlibrary(formattable) \r\nlibrary(yarrr)  \r\nlibrary(radarchart) \r\nlibrary(igraph) \r\nlibrary(ggraph) \r\n\r\n#Define some colors to use throughout\r\nmy_colors <- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#CC79A7\", \"#D55E00\", \"#D65E00\")\r\n\r\n#Customize ggplot2's default theme settings\r\ntheme_lms <- function(aticks = element_blank(),\r\n                         pgminor = element_blank(),\r\n                         lt = element_blank(),\r\n                         lp = \"none\")\r\n{\r\n  theme(plot.title = element_text(hjust = 0.5), #Center the title\r\n        axis.ticks = aticks, #Set axis ticks to on or off\r\n        panel.grid.minor = pgminor, #Turn the minor grid lines on or off\r\n        legend.title = lt, #Turn the legend title on or off\r\n        legend.position = lp) #Turn the legend on or off\r\n}\r\n\r\n\r\n\r\n2 METHOD\r\n2a. Connecting to API and\r\npulling Data\r\nTo begin, after loading the libraries, we connect to the Twitter\r\nResting API and pull tweets for Google Classroom, Canvas,\r\nBlackboard, and Moodle Learning Management Systems. You will not view\r\nthe codes used to connect to Twitter API as I saved them to a\r\nget_token() function. I use the get_token function to connect\r\ndirectly to Twitter’s Resting API.\r\nTo know which hashtags or words to pull tweets with, I went directly\r\nto Twitter and searched the LMS names to view the results. Canvas and\r\nBlackboard were tricky since the name “Canvas” is closely associated\r\nwith art and links to companies like Micheal’s Craft Store, which sells\r\ndifferent art canvas sizes for painters. Blackboard is closely\r\nassociated with a Game that I was not familiar with. Since Twitter\r\nchanges and restrictions on the dates and amount of tweets you can pull,\r\nwe will write the data files to save and read in a later code chunk.\r\n\r\n\r\nShow code\r\n\r\n#connect to Twitter API\r\nget_token()\r\n\r\n#PULL Google Classroom\r\ngc_dictionary <- c(\"#Google Classroom\", '\"Google Classroom\"') \r\ngctweets <- \r\ngc_dictionary %>% \r\n  search_tweets2(n=5000, include_rts = FALSE)\r\n\r\n#write to save\r\ngc_tweets <- write_xlsx(gctweets, \"data/gctweets.xlsx\")\r\n\r\n#PULL Canvas LMS\r\ncanvas_dictionary <- c(\"#canvas\", '\"Canvas lms\"') \r\ncanvastweets <- \r\n canvas_dictionary %>% \r\n  search_tweets2(n=5000, include_rts = FALSE)\r\n\r\n#write to save\r\ncanvastweets <- write_xlsx(canvastweets, \"data/canvastweets.xlsx\")\r\n\r\n#PULL Blackboard tweets and save as excel file\r\n\r\nbb_dictionary <- c(\"#blackboard lms\", '\"blackboard lms\"') \r\nblackboardtweets <- \r\n bb_dictionary %>% \r\n  search_tweets2(n=5000, include_rts = FALSE)\r\n\r\n#write to save\r\nblackboard_tweets <- write_xlsx(blackboardtweets, \"data/blackboard.xlsx\")\r\n\r\n\r\n#PULL Moodle tweets and save as excel file\r\n\r\nmoodle_dictionary <- c(\"#moodle lms\", '\"Moodle\"') \r\nmoodletweets <- \r\n moodle_dictionary %>% \r\n  search_tweets2(n=5000, include_rts = FALSE)\r\n\r\n#write to save\r\nmoodletweets <- write_xlsx(moodletweets, \"data/moodle.xlsx\")\r\n\r\n\r\n\r\n2b. Read and Restructure Data\r\nLet’s read in the previously saved LMS data for Google Classroom\r\ntweets, Blackboard tweets, Canvas tweets, and Moodle tweets.\r\nThen subset the rows and columns to pull only English language\r\ntexts\r\nWe will bind each separate data frame into one data frame\r\nnamed tweets().\r\nWe will need to create a unique identifying index column for later\r\nanalysis.\r\nFinally, let’s look at the head of our new tweets() data\r\nframe.\r\n\r\n\r\nShow code\r\n\r\n#read in previously pulled tweets for Google Classroom, Blackboard and Canvas\r\ngc_tweets <- read_xlsx(\"data/gctweets.xlsx\")\r\nbb_tweets <- read_xlsx(\"data/blackboard.xlsx\")\r\ncanvas_tweets <- read_xlsx(\"data/canvastweets.xlsx\")\r\nmoodle_tweets <- read_xlsx(\"data/moodle.xlsx\")\r\n\r\n#subset rows and colums in the english language, add a column for quickly identifying the LMS software.\r\ngc_text <- gc_tweets %>%\r\n  filter(lang == \"en\") %>%\r\n  select(screen_name, created_at, text)%>%\r\n  mutate(lms = \"Google Classroom\") %>%\r\n  relocate(lms)\r\n\r\n\r\nbb_text <- bb_tweets %>%\r\n  filter(lang == \"en\") %>%\r\n  select(screen_name, created_at, text) %>%\r\n  mutate(lms = \"Blackboard\") %>%\r\n  relocate(lms)\r\n\r\ncanvas_text <- canvas_tweets %>%\r\n  filter(lang == \"en\") %>%\r\n  select(screen_name, created_at, text) %>%\r\n  mutate(lms = \"Canvas\")%>%\r\n  relocate(lms)\r\n\r\nmoodle_text <- moodle_tweets %>%\r\n  filter(lang == \"en\") %>%\r\n  select(screen_name, created_at, text) %>%\r\n  mutate(lms = \"Moodle\")%>%\r\n  relocate(lms)\r\n\r\n#combine data frames\r\ntweets <- bind_rows(canvas_text, gc_text, moodle_text, bb_text)\r\ntweets <- tibble::rowid_to_column(tweets, \"index\") #add unique identifier\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\ntweets %>%\r\n  head()%>%\r\n  kbl(caption = \"Restructured Data - tidy_tweets data frame\") %>%\r\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\r\n\r\n\r\n\r\nTable 1: Restructured Data - tidy_tweets data frame\r\n\r\n\r\nindex\r\n\r\n\r\nlms\r\n\r\n\r\nscreen_name\r\n\r\n\r\ncreated_at\r\n\r\n\r\ntext\r\n\r\n\r\n1\r\n\r\n\r\nCanvas\r\n\r\n\r\nVanOnCanvas\r\n\r\n\r\n2022-02-03 21:05:25\r\n\r\n\r\nhttps://t.co/dhhQo2XrgM Vancouver Shiny Resin Clear\r\nCoatings on #Canvas\r\n\r\n\r\n2\r\n\r\n\r\nCanvas\r\n\r\n\r\nLucentDesigns\r\n\r\n\r\n2022-02-03 21:04:29\r\n\r\n\r\n<U+2728> Here’s the next #WIP preview on my next #watercolor\r\n#canvas #painting project! Current progress is about 60% complete. I\r\nwill post more updates soon! See the rest of my works in the meantime!\r\n<U+0001F3A8>\r\nDeviantArt Paintings Gallery: https://t.co/cdlb8TcO0d\r\n#rtArtBoost #art https://t.co/aDnFYVmqJ4\r\n\r\n\r\n3\r\n\r\n\r\nCanvas\r\n\r\n\r\nLucentDesigns\r\n\r\n\r\n2022-02-03 09:54:26\r\n\r\n\r\n#ThrowbackThursday!\r\nHere’s an early art piece I painted a few years back, using a black\r\nink graphic pen and acrylic on canvas. Let me know what you think!\r\n<U+2764><U+FE0F>\r\nSee more of my paintings here: https://t.co/gqvZtTrR4J\r\n#Painting #Canvas #tbt #Art #rtArtBoost https://t.co/Dd2y9u9ecT\r\n\r\n\r\n4\r\n\r\n\r\nCanvas\r\n\r\n\r\nLucentDesigns\r\n\r\n\r\n2022-02-02 01:26:21\r\n\r\n\r\n<U+2728> Here’s the next #WIP preview on my next #watercolor\r\n#canvas #painting project! Current progress is about 20% complete. I\r\nwill post more progress updates soon! See the rest of my works in the\r\nmeantime! <U+0001F3A8>\r\nDeviantArt Paintings Gallery: https://t.co/cdlb8TcO0d\r\n#rtArtBoost #art https://t.co/YGzAXUi2Pd\r\n\r\n\r\n5\r\n\r\n\r\nCanvas\r\n\r\n\r\nLucentDesigns\r\n\r\n\r\n2022-01-27 08:54:22\r\n\r\n\r\n#ThrowbackThursday!\r\nHere’s a really early canvas art piece I painted a few years back,\r\nlet me know what you think! <U+2764><U+FE0F>\r\nSee more of my paintings here: https://t.co/gqvZtTrR4J\r\n#Painting #Canvas #tbt #Art #rtArtBoost https://t.co/mmdfWw5WG3\r\n\r\n\r\n6\r\n\r\n\r\nCanvas\r\n\r\n\r\nlaistakanashi\r\n\r\n\r\n2022-02-03 20:44:09\r\n\r\n\r\nLittle corner in my studio ! #Art #FineArt #Artist #Studio #ArtGallery\r\n#ModernArt #Picasso #Drawing #Painting #Canvas #SalvadorDalí #Manga\r\n#Vinyl #StreetFighter #Monet https://t.co/aNSHkyrktr\r\n\r\n\r\n2c. Tidy Text format\r\nWe will tidy our text using the tidytext and dplyr packages\r\nto split the text into tokens creating a table with one-token-per-row.\r\nThe token is under a column called word(). Another step to tidy the text\r\nis to remove the most common stop words such as a, the, is, are and\r\netc. As mentioned previously, “art” is commonly connected to\r\nCanvas; therefore, we need to filter out “art.” We will take another\r\nlook at the head of our tokenized text.\r\n\r\n\r\nShow code\r\n\r\n#tokenize tweets\r\ntweet_tokens <- \r\n  tweets %>%\r\n  unnest_tokens(output = word, \r\n                input = text, \r\n                token = \"tweets\")\r\n\r\n#Tidy text and get rid of #art (nonsenese word that turned up with Canvas)\r\ntidy_tweets <-\r\n  tweet_tokens %>%\r\n  anti_join(stop_words, by = \"word\")%>%\r\n    filter(!word == \"#art\") # get rid of #art \r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\ntidy_tweets%>%\r\n  head%>%\r\n  kbl(caption = \"Tidy Text - tidy_tweets data frame\") %>%\r\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\r\n\r\n\r\n\r\nTable 2: Tidy Text - tidy_tweets data frame\r\n\r\n\r\nindex\r\n\r\n\r\nlms\r\n\r\n\r\nscreen_name\r\n\r\n\r\ncreated_at\r\n\r\n\r\nword\r\n\r\n\r\n1\r\n\r\n\r\nCanvas\r\n\r\n\r\nVanOnCanvas\r\n\r\n\r\n2022-02-03 21:05:25\r\n\r\n\r\nhttps://t.co/dhhqo2xrgm\r\n\r\n\r\n1\r\n\r\n\r\nCanvas\r\n\r\n\r\nVanOnCanvas\r\n\r\n\r\n2022-02-03 21:05:25\r\n\r\n\r\nvancouver\r\n\r\n\r\n1\r\n\r\n\r\nCanvas\r\n\r\n\r\nVanOnCanvas\r\n\r\n\r\n2022-02-03 21:05:25\r\n\r\n\r\nshiny\r\n\r\n\r\n1\r\n\r\n\r\nCanvas\r\n\r\n\r\nVanOnCanvas\r\n\r\n\r\n2022-02-03 21:05:25\r\n\r\n\r\nresin\r\n\r\n\r\n1\r\n\r\n\r\nCanvas\r\n\r\n\r\nVanOnCanvas\r\n\r\n\r\n2022-02-03 21:05:25\r\n\r\n\r\ncoatings\r\n\r\n\r\n1\r\n\r\n\r\nCanvas\r\n\r\n\r\nVanOnCanvas\r\n\r\n\r\n2022-02-03 21:05:25\r\n\r\n\r\n#canvas\r\n\r\n\r\n3. EXPLORE\r\nIn this section we will explore word counts by ungrouping the\r\ntokenized words to view in a word cloud.\r\n3a. WordClouds\r\nWe can get a sense of the most common words in the combined LMS\r\nSentiment Analysis by looking at a word cloud of the word counts. By\r\nlooking at the top 50 words from the word count, we can see that\r\n#Classroom, #Canvas, and Moodle are very popular within the\r\nTweets, along with Moodle.\r\n\r\n\r\nShow code\r\n\r\ntop_tokens <- tidy_tweets %>%\r\n  ungroup ()%>%  #ungroup the tokenize data to create a wordcloud\r\n  count(word, sort = TRUE) %>%\r\n  top_n(50)\r\n\r\nwordcloud2(top_tokens)\r\n\r\n\r\n\r\n{\"x\":{\"word\":[\"#canvas\",\"google\",\"classroom\",\"moodle\",\"due\",\"pay\",\"canvas\",\"students\",\"essay\",\"#pearson\",\"#blackboard\",\"check\",\"#painting\",\"assignments\",\"assignment\",\"paper\",\"online\",\"class\",\"homework\",\"#aleks\",\"art\",\"day\",\"amp\",\"school\",\"learning\",\"#essay\",\"write\",\"teachers\",\"history\",\"#pay\",\"#artwork\",\"dm\",\"#homework\",\"#acrylic\",\"#artist\",\"post\",\"classes\",\"#ncat\",\"exam\",\"#cengage\",\"#essayhelp\",\"february\",\"im\",\"time\",\"#abstract\",\"#essaypay\",\"#python\",\"research\",\"#iot\",\"#assignments\"],\"freq\":[1987,1781,1720,723,578,551,445,433,427,372,371,371,354,350,347,331,328,327,322,315,283,278,250,240,227,211,209,201,197,190,188,186,182,172,169,164,161,158,156,153,151,151,142,142,141,140,140,138,137,136],\"fontFamily\":\"Segoe UI\",\"fontWeight\":\"bold\",\"color\":\"random-dark\",\"minSize\":0,\"weightFactor\":0.0905888273779567,\"backgroundColor\":\"white\",\"gridSize\":0,\"minRotation\":-0.785398163397448,\"maxRotation\":0.785398163397448,\"shuffle\":true,\"rotateRatio\":0.4,\"shape\":\"circle\",\"ellipticity\":0.65,\"figBase64\":null,\"hover\":null},\"evals\":[],\"jsHooks\":{\"render\":[{\"code\":\"function(el,x){\\n                        console.log(123);\\n                        if(!iii){\\n                          window.location.reload();\\n                          iii = False;\\n\\n                        }\\n  }\",\"data\":null}]}}\r\n3b. Frequency Rank\r\nThe Frequency Rank data table exhibits a new column showing\r\nwe measured the importance of a word by how frequently a word occurs in\r\nthe tweet.\r\nBy calculating the term frequency logarithmically, we can see the\r\ninversely proportional relationship of the negative slope for each LMS.\r\nIn the log-log plotted diagram, we see a lot of deviation at various\r\nrank levels. The deviations at the lower rank show that the various LMS\r\ntweets use a lower percentage of the most common words than many\r\ncollections of language.\r\n\r\n\r\nShow code\r\n\r\nwords_by_LMS <- tidy_tweets%>%\r\n  count(lms, word, sort = TRUE) %>%\r\n  ungroup()\r\n\r\ntotal_words <- words_by_LMS %>% \r\n  group_by(lms) %>% \r\n  summarize(total = sum(n))\r\n\r\nwords_by_LMS <- left_join(words_by_LMS, total_words)\r\n\r\n\r\nfreq_by_rank <- words_by_LMS %>% \r\n  group_by(lms) %>% \r\n  mutate(rank = row_number(), \r\n         `term frequency` = n/total) %>%\r\n  ungroup()\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nfreq_by_rank%>%\r\n  head()%>%\r\n  kbl(caption = \"Learning Management Systems - word freq_by_rank data frame\") %>%\r\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) \r\n\r\n\r\n\r\nTable 3: Learning Management Systems - word freq_by_rank\r\ndata frame\r\n\r\n\r\nlms\r\n\r\n\r\nword\r\n\r\n\r\nn\r\n\r\n\r\ntotal\r\n\r\n\r\nrank\r\n\r\n\r\nterm frequency\r\n\r\n\r\nCanvas\r\n\r\n\r\n#canvas\r\n\r\n\r\n1969\r\n\r\n\r\n43536\r\n\r\n\r\n1\r\n\r\n\r\n0.0452269\r\n\r\n\r\nGoogle Classroom\r\n\r\n\r\ngoogle\r\n\r\n\r\n1773\r\n\r\n\r\n23982\r\n\r\n\r\n1\r\n\r\n\r\n0.0739304\r\n\r\n\r\nGoogle Classroom\r\n\r\n\r\nclassroom\r\n\r\n\r\n1710\r\n\r\n\r\n23982\r\n\r\n\r\n2\r\n\r\n\r\n0.0713035\r\n\r\n\r\nMoodle\r\n\r\n\r\nmoodle\r\n\r\n\r\n717\r\n\r\n\r\n10316\r\n\r\n\r\n1\r\n\r\n\r\n0.0695037\r\n\r\n\r\nCanvas\r\n\r\n\r\npay\r\n\r\n\r\n549\r\n\r\n\r\n43536\r\n\r\n\r\n2\r\n\r\n\r\n0.0126103\r\n\r\n\r\nCanvas\r\n\r\n\r\ndue\r\n\r\n\r\n445\r\n\r\n\r\n43536\r\n\r\n\r\n3\r\n\r\n\r\n0.0102214\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nfreq_by_rank %>% \r\n  ggplot(aes(rank, `term frequency`, color = lms)) + \r\n  geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) + \r\n  scale_x_log10() +\r\n  scale_y_log10() +\r\n  labs()\r\n\r\n\r\n\r\n\r\n4 MODEL\r\nTo evaluate sentiment for each lexicon: Bing, NRC, AFINN and Loughran\r\nwe will first load them, evaluate each sentiment and bind them into one\r\nsummary sentiment data frame. Secondly, we will compare Sentiment using\r\nthe NRC Lexicon. I chose this lexicon after reading that it has a more\r\naccurate sentiment scale for shorter texts.\r\n4a. Sentiment Analysis\r\nHere we will load the sentiment lexicons and then rate the words\r\naccording to the lexicon identifier, joining each separate data frame\r\ninto one called summary_sentiment(). a. The first table in this section\r\nshows the combined data frame. b. The bar graph below allows\r\nvisualization for the summary_sentiment() data frame.\r\nIn both the summary_sentiment() data frame and the bar graph, we see\r\nthat each LMS is overly positive. Canvas has the most unique words, and\r\nBlackboard with the least total words. Further, we can conclude that\r\nduring the period, Canvas is the most talked about on\r\nTwitter from January 30 - February 1, 2022.\r\n\r\n\r\nShow code\r\n\r\nafinn <- get_sentiments(\"afinn\")\r\nnrc <- get_sentiments(\"nrc\")\r\nbing <- get_sentiments(\"bing\")\r\nloughran <- get_sentiments(\"loughran\")\r\n\r\nsentiment_afinn <- inner_join(tidy_tweets, afinn, by = \"word\")\r\nsentiment_bing <- inner_join(tidy_tweets, bing, by = \"word\")\r\nsentiment_nrc <- inner_join(tidy_tweets, nrc, by = \"word\")\r\nsentiment_loughran <- inner_join(tidy_tweets, loughran, by = \"word\")\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nsummary_afinn2 <- sentiment_afinn %>% \r\n  group_by(lms) %>% \r\n  filter(value != 0) %>%\r\n  mutate(sentiment = if_else(value < 0, \"negative\", \"positive\")) %>% \r\n  count(sentiment, sort = TRUE) %>% \r\n  mutate(method = \"AFINN\")\r\n\r\nsummary_bing2 <- sentiment_bing %>% \r\n  group_by(lms) %>% \r\n  count(sentiment, sort = TRUE) %>% \r\n  mutate(method = \"bing\")\r\n\r\nsummary_nrc2 <- sentiment_nrc %>% \r\n  filter(sentiment %in% c(\"positive\", \"negative\")) %>%\r\n  group_by(lms) %>% \r\n  count(sentiment, sort = TRUE) %>% \r\n  mutate(method = \"nrc\") \r\n\r\nsummary_loughran2 <- sentiment_loughran %>% \r\n  filter(sentiment %in% c(\"positive\", \"negative\")) %>%\r\n  group_by(lms) %>% \r\n  count(sentiment, sort = TRUE) %>% \r\n  mutate(method = \"loughran\") \r\n\r\nsummary_sentiment <- bind_rows(summary_afinn2,\r\n                               summary_bing2,\r\n                               summary_nrc2,\r\n                               summary_loughran2) %>%\r\n  arrange(method, lms) %>%\r\n  relocate(method)\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nsummary_sentiment%>%\r\n  head()%>%\r\n  kbl(caption = \"Learning Management Systems - Total summary sentiment data frame\") %>%\r\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) \r\n\r\n\r\n\r\nTable 4: Learning Management Systems - Total summary\r\nsentiment data frame\r\n\r\n\r\nmethod\r\n\r\n\r\nlms\r\n\r\n\r\nsentiment\r\n\r\n\r\nn\r\n\r\n\r\nAFINN\r\n\r\n\r\nBlackboard\r\n\r\n\r\npositive\r\n\r\n\r\n4\r\n\r\n\r\nAFINN\r\n\r\n\r\nCanvas\r\n\r\n\r\nnegative\r\n\r\n\r\n730\r\n\r\n\r\nAFINN\r\n\r\n\r\nCanvas\r\n\r\n\r\npositive\r\n\r\n\r\n583\r\n\r\n\r\nAFINN\r\n\r\n\r\nGoogle Classroom\r\n\r\n\r\npositive\r\n\r\n\r\n881\r\n\r\n\r\nAFINN\r\n\r\n\r\nGoogle Classroom\r\n\r\n\r\nnegative\r\n\r\n\r\n476\r\n\r\n\r\nAFINN\r\n\r\n\r\nMoodle\r\n\r\n\r\npositive\r\n\r\n\r\n385\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nggplot(summary_sentiment, aes(n, sentiment, fill = lms)) +\r\n  geom_col(show.legend = FALSE) +\r\n  facet_wrap(~lms, ncol = 2, scales = \"free_x\")\r\n\r\n\r\n\r\n\r\nLexicon\r\nPercent for each Learning Management System\r\nLooking at the Sentiment percents by Lexicon we can see that NRC reveals\r\nthe most positive score for all the LMS and Loughran measures the least\r\npositive. Blackboard had such a small number of words that it is\r\npositive on all lexicons.\r\n\r\n\r\nShow code\r\n\r\n#create a new data frame that has the total word counts for each LMS and each method\r\ntotal_counts <- summary_sentiment %>%\r\n  group_by(method, lms) %>%\r\n  summarise(total = sum(n))\r\n\r\n#join to the summary_sentiment data frame\r\nsentiment_counts <- left_join(summary_sentiment, total_counts)\r\n\r\n#calculates the percentage of positive and negative words for each LMS\r\nsentiment_percents <- sentiment_counts %>%\r\n  mutate(percent = n/total * 100)\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nsentiment_percents%>%\r\n  head()%>%\r\n  kbl(caption = \"Learning Management Systems - Sentiment Percents\") %>%\r\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) \r\n\r\n\r\n\r\nTable 5: Learning Management Systems - Sentiment Percents\r\n\r\n\r\nmethod\r\n\r\n\r\nlms\r\n\r\n\r\nsentiment\r\n\r\n\r\nn\r\n\r\n\r\ntotal\r\n\r\n\r\npercent\r\n\r\n\r\nAFINN\r\n\r\n\r\nBlackboard\r\n\r\n\r\npositive\r\n\r\n\r\n4\r\n\r\n\r\n4\r\n\r\n\r\n100.00000\r\n\r\n\r\nAFINN\r\n\r\n\r\nCanvas\r\n\r\n\r\nnegative\r\n\r\n\r\n730\r\n\r\n\r\n1313\r\n\r\n\r\n55.59787\r\n\r\n\r\nAFINN\r\n\r\n\r\nCanvas\r\n\r\n\r\npositive\r\n\r\n\r\n583\r\n\r\n\r\n1313\r\n\r\n\r\n44.40213\r\n\r\n\r\nAFINN\r\n\r\n\r\nGoogle Classroom\r\n\r\n\r\npositive\r\n\r\n\r\n881\r\n\r\n\r\n1357\r\n\r\n\r\n64.92262\r\n\r\n\r\nAFINN\r\n\r\n\r\nGoogle Classroom\r\n\r\n\r\nnegative\r\n\r\n\r\n476\r\n\r\n\r\n1357\r\n\r\n\r\n35.07738\r\n\r\n\r\nAFINN\r\n\r\n\r\nMoodle\r\n\r\n\r\npositive\r\n\r\n\r\n385\r\n\r\n\r\n641\r\n\r\n\r\n60.06240\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\nsentiment_percents %>%\r\n  ggplot(aes(x = lms, y = percent, fill=sentiment)) +\r\n  geom_bar(width = .8, stat = \"identity\") +\r\n  facet_wrap(~method, ncol = 1) +\r\n  coord_flip() +\r\n  labs(title = \"Public Sentiment on Twitter\", \r\n       subtitle = \"Google Classroom, Moodle, Canvas & BlackBoard \",\r\n       x = \"Learning Management System\", \r\n       y = \"Percentage of Words\")\r\n\r\n\r\n\r\n\r\n4b. Visualizing\r\nsentiment with the NRC lexicon\r\nIt is essential to look at a time graph to visualize a sentiment\r\nspike throughout data collection. Insights from this type of graph would\r\nallow for further investigation. This particular plot looks at NRC\r\nsentiment for all LMS during Twitter data collection. Interestingly it\r\nshows that between January 30 - February 1 fear, disgust, and\r\npain sentiment seems to increase with negative emotions. This spike\r\nindicates that further investigation is needed to understand the\r\ncause.\r\n\r\n\r\nShow code\r\n\r\nlibrary(ggjoy)\r\n\r\n  ggplot(sentiment_nrc) +\r\n    geom_joy(aes(\r\n      x = created_at,\r\n      y = sentiment, \r\n      fill = sentiment),\r\n      rel_min_height = 0.01,\r\n      alpha = 0.7,\r\n      scale = 3) +\r\n    theme_joy() +\r\n    labs(title = \"LMS Twitter NRC Sentiment during 1/26/22 - 2/5/22 \",\r\n         x = \"Tweet Date\",\r\n         y = \"Sentiment\") + \r\n    scale_fill_discrete(guide=FALSE)\r\n\r\n\r\n\r\n\r\nCommon words\r\nwithin each NRC sentiment category\r\nFinally, let’s also look at the common words within categories\r\nassociated with the NRC Lexicon for each Learning Management System.\r\nLooking at the words we we get a better sense of what words we would\r\nexcept to be in the categories of anger, anticipation, disgust, fear\r\njoy, negative, positive, sadness , surprise  and\r\ntrust.\r\nYou will also notice within the categories words that may not belong\r\nin those categories as they were used sarcastically. A deeper dive\r\nlooking at Bigram would help us understand the words that these words\r\nare connected to.\r\nNRC sentiment\r\ncategories for Google Classroom\r\n\r\n\r\nShow code\r\n\r\nlibrary(ggrepel)\r\nplot_words1 <- sentiment_nrc %>%\r\n  filter(lms == \"Google Classroom\") %>%\r\n  group_by(sentiment) %>%\r\n  count(word, sort = TRUE) %>%\r\n  arrange(desc(n)) %>%\r\n  slice(seq_len(10)) %>%\r\n  ungroup()\r\n\r\n#Same comments as previous graph\r\ngoggle_words<- plot_words1 %>%\r\n  ggplot(aes(word, 1, label = word, fill = sentiment )) +\r\n  geom_point(color = \"transparent\") +\r\n  geom_label_repel(force = 1,nudge_y = .5,  \r\n                   direction = \"y\",\r\n                   box.padding = 0.05,\r\n                   segment.color = \"transparent\",\r\n                   size = 3) +\r\n  theme_lms()+\r\n  facet_grid(~sentiment) +\r\n  theme(axis.text.y = element_blank(), axis.text.x = element_blank(),\r\n        axis.title.x = element_text(size = 6),\r\n        panel.grid = element_blank(), panel.background = element_blank(),\r\n        panel.border = element_rect(\"lightgray\", fill = NA),\r\n        strip.text.x = element_text(size = 9)) +\r\n  xlab(NULL) + ylab(NULL) +\r\n  ggtitle(\"Google Classroom NRC Sentiment\") +\r\n  coord_flip()\r\n\r\ngoggle_words\r\n\r\n\r\n\r\n\r\nNRC sentiment categories\r\nfor Moodle\r\n\r\n\r\nShow code\r\n\r\nplot_words2 <- sentiment_nrc %>%\r\n  filter(lms == \"Moodle\") %>%\r\n  group_by(sentiment) %>%\r\n  count(word, sort = TRUE) %>%\r\n  arrange(desc(n)) %>%\r\n  slice(seq_len(10)) %>%\r\n  ungroup()\r\n\r\n\r\nmoodle_words <- plot_words2 %>%\r\n  ggplot(aes(word, 1, label = word, fill = sentiment )) +\r\n  geom_point(color = \"transparent\") +\r\n  geom_label_repel(force = 1,nudge_y = .5,  \r\n                   direction = \"y\",\r\n                   box.padding = 0.05,\r\n                   segment.color = \"transparent\",\r\n                   size = 3) +\r\n  theme_lms()+\r\n  facet_grid(~sentiment) +\r\n  theme(axis.text.y = element_blank(), axis.text.x = element_blank(),\r\n        axis.title.x = element_text(size = 6),\r\n        panel.grid = element_blank(), panel.background = element_blank(),\r\n        panel.border = element_rect(\"lightgray\", fill = NA),\r\n        strip.text.x = element_text(size = 9)) +\r\n  xlab(NULL) + ylab(NULL) +\r\n  ggtitle(\"Moodle NRC Sentiment\") +\r\n  coord_flip()\r\nmoodle_words\r\n\r\n\r\n\r\n\r\nNRC sentiment categories\r\nfor Canvas\r\n\r\n\r\nShow code\r\n\r\nplot_words3 <- sentiment_nrc %>%\r\n  filter(lms == \"Canvas\") %>%\r\n  group_by(sentiment) %>%\r\n  count(word, sort = TRUE) %>%\r\n  arrange(desc(n)) %>%\r\n  slice(seq_len(10)) %>%\r\n  ungroup()\r\n\r\n\r\ncanvas_words <- plot_words3 %>%\r\n  ggplot(aes(word, 1, label = word, fill = sentiment )) +\r\n  geom_point(color = \"transparent\") +\r\n  geom_label_repel(force = 1,nudge_y = .5,  \r\n                   direction = \"y\",\r\n                   box.padding = 0.05,\r\n                   segment.color = \"transparent\",\r\n                   size = 3) +\r\n  theme_lms()+\r\n  facet_grid(~sentiment) +\r\n  theme(axis.text.y = element_blank(), axis.text.x = element_blank(),\r\n        axis.title.x = element_text(size = 6),\r\n        panel.grid = element_blank(), panel.background = element_blank(),\r\n        panel.border = element_rect(\"lightgray\", fill = NA),\r\n        strip.text.x = element_text(size = 9)) +\r\n  xlab(NULL) + ylab(NULL) +\r\n  ggtitle(\"Canvas NRC Sentiment\") +\r\n  coord_flip()\r\n\r\ncanvas_words\r\n\r\n\r\n\r\n\r\nNRC sentiment\r\ncategories for Blackboard\r\n\r\n\r\nShow code\r\n\r\nplot_words4 <- sentiment_nrc %>%\r\n  filter(lms == \"Blackboard\") %>%\r\n  group_by(sentiment) %>%\r\n  count(word, sort = TRUE) %>%\r\n  arrange(desc(n)) %>%\r\n  slice(seq_len(10)) %>%\r\n  ungroup()\r\n\r\n\r\nBB_words <- plot_words4 %>%\r\n  ggplot(aes(word, 1, label = word, fill = sentiment )) +\r\n  geom_point(color = \"transparent\") +\r\n  geom_label_repel(force = 1,nudge_y = .5,  \r\n                   direction = \"y\",\r\n                   box.padding = 0.05,\r\n                   segment.color = \"transparent\",\r\n                   size = 3) +\r\n  theme_lms()+\r\n  facet_grid(~sentiment) +\r\n  theme(axis.text.y = element_blank(), axis.text.x = element_blank(),\r\n        axis.title.x = element_text(size = 6),\r\n        panel.grid = element_blank(), panel.background = element_blank(),\r\n        panel.border = element_rect(\"lightgray\", fill = NA),\r\n        strip.text.x = element_text(size = 9)) +\r\n  xlab(NULL) + ylab(NULL) +\r\n  ggtitle(\"Blackboard NRC Sentiment\") +\r\n  coord_flip()\r\n  \r\n\r\nBB_words\r\n\r\n\r\n\r\n\r\n5. COMMUNICATE\r\nPurpose -  The purpose of the case study is to\r\nproduce a sentiment analysis examining Twitter public sentiment for four\r\npopular Learning Management Systems; Google Classroom, Canvas,\r\nBlackboard, and Moodle. We looked closely at the lexicons and their\r\npercentage for each LMS sentiment as more positive or negative. Finally,\r\nwe looked at words that fit into the sentiment categories identifying\r\nareas that may need a closer look.\r\nMethods - For this independent analysis I\r\nexplored tweet counts, sentiment analysis, and unique sentiment\r\nwords.\r\nFindings - The LMS, Google Classroom, Canvas,\r\nMoodle, and Blackboard sentiment was positively skewed. I was amazed\r\nthat the words online, virtual, or e-learning did not appear as top\r\nsentiment words for any LMS. In most cases, the top words associated\r\nwith the LMS names include Google, Classroom, Canvas, Moodle, which is\r\nnot surprising since they are typically hashtagged. Canvas was the most\r\npopular on Twitter from January 26 to February 5, 2022.\r\n   Finally, Blackboard had the lowest counts and\r\nwas the least tweeted for this\r\n   case study.\r\nDiscussion - Insights from a case study like\r\nthis can be used to guide Public and Private organizations looking to\r\npurchase a Learning Management System or of the companies who own the\r\nLMS.\r\nA public or Private organization looking to purchase LMS may use the\r\ninsights to look at the negative and positive sentiment to see what\r\ncurrent customers are commenting on and if the product would be a “best\r\nfit” for their organization.\r\nThe LMS software companies may monitor sentiment analysis to\r\ndetermine customer concerns and, in some cases, develop or improve\r\nfeatures that meet customer needs.\r\nThe LMS companies can monitor negative or positive sentiments about\r\ntheir competitors to improve their own products.\r\nAdditional research should be taken to understand why there was a\r\nspike in negative sentiment during the time periods of January 29 -\r\nFebruary 3. Monitoring those features may provide insights and prevent a\r\nreduction in customer base.\r\n Additional analysis would be beneficial to\r\nunderstand customer sentiment\r\nanalysis over a longer period. Monitoring with a dashboard may also be\r\nan option\r\nto analyze spikes in positive or negative sentiment quickly address\r\nthose\r\nfeatures and concerns.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-04-03-sentiment-analysis-lms/lmstimesentiment.png",
    "last_modified": "2022-04-03T17:51:08-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-03-soar-project/",
    "title": "Understanding student goals - a Topic Modeling approach",
    "description": "Looking at student goals for emerging topics or themes.",
    "author": [
      {
        "name": "Jeanne McClure",
        "url": {}
      }
    ],
    "date": "2021-11-27",
    "categories": [],
    "contents": "\r\n1 Prepare\r\nBackground\r\nWhile at my Graduate position in the Media and Education Technology\r\nResource Center (METRC) we wanted to have an event that would get\r\nstudents into METRC. The idea was that students would come into METRC to\r\nhand write a yearly goal on a paper feather during October through\r\nNovember. The goals would then be combined into a collaborative wing\r\nmural that would be installed before Education Week so that students\r\ncould come and take photos.\r\nResearch Questions\r\nWhat are the Student goals about?\r\nHow are student’s feeling about their Goals?\r\nHow do we quantify what the Student Goals are about?\r\nMethods\r\nCommon Word Counts Text Mining IF - ITF Sentiment Analysis Topic\r\nModeling\r\n\r\n\r\nlibrary(readr)\r\nlibrary(tidyverse)\r\nlibrary(dplyr)\r\nlibrary(ggplot2)\r\nlibrary(tidytext)\r\nlibrary(SnowballC)\r\nlibrary(topicmodels)\r\nlibrary(stm)\r\nlibrary(ldatuning)\r\nlibrary(knitr)\r\nlibrary(tidyr)\r\nlibrary(topicmodels)\r\nlibrary(wordcloud2)\r\nlibrary(vader)\r\n\r\n\r\n\r\n2. Wrangle\r\nHere we will ‘wrangle’ the data by a. Reading the\r\nData, b. Data Reduction and c. Tidying\r\nthe Data (Krumm et al., 2018).\r\nIt shows that we have 213 observations and 3 variables.\r\na. READ Data\r\nLet’s read our data into our Environment and assign it to a variable\r\nname soar_data1.\r\n\r\n\r\nsoar_data1 <- read_csv(\"data/Soar-resposes.csv\")\r\n\r\nsoar_data1\r\n\r\n\r\n# A tibble: 215 x 3\r\n   Timestamp          Department             Goal                     \r\n   <chr>              <chr>                  <chr>                    \r\n 1 11/9/2021 10:00:18 Distance Graduate TELS Deeper understanding of ~\r\n 2 11/9/2021 10:00:46 Distance Graduate TELS Choose a dissertation to~\r\n 3 11/9/2021 10:01:05 Distance Graduate TELS 4.0 Baby                 \r\n 4 11/9/2021 10:01:16 Distance Graduate TELS To Graduate              \r\n 5 11/9/2021 10:01:28 Distance Graduate TELS Finish my Book           \r\n 6 11/9/2021 10:02:00 Graduate TELS          Learn about 3 topics and~\r\n 7 11/9/2021 10:02:25 Graduate TELS          Reamin mentally, physica~\r\n 8 11/9/2021 10:03:02 Graduate TELS          Balance of learning, bei~\r\n 9 11/9/2021 10:03:22 Graduate TELS          To stay healthy and lear~\r\n10 11/9/2021 10:03:39 Graduate TELS          Better time management a~\r\n# ... with 205 more rows\r\n\r\nb. Data Reduction\r\nThe initial Soar Data shows that we have 213 observations and 3\r\nvariables. However, we need to clean it up selecting only the students\r\nand adding a unique identifier.\r\n\r\n\r\n#Clean Data to omit staff, include unique identifier\r\nsoar_data2 <- soar_data1 %>% \r\n  select(c('Department', 'Goal')) %>% # only select Department and the goal data\r\n  filter(Department == \"Distance Graduate TELS\" | Department == \"Graduate TELS\"\r\n         | Department == \"ELPHD\" | Department == \"Distance ELPHD\" | \r\n           Department == \"Graduate STEM\" | Department == \"Undergraduate TELS\" | \r\n           Department == \"Undergraduate STEM\") %>%  #filter out departments to omit staff\r\n  group_by(Department) %>%\r\n  na.omit()\r\n  \r\n\r\nsoar_data2 <- soar_data2[-51, ] # delete row 51 that contains \"N/A\" for goal\r\n\r\nsoar_data2 <- tibble::rowid_to_column(soar_data2, \"index\") #add unique identifier\r\n\r\nsoar_data2 %>%\r\n  head()\r\n\r\n\r\n# A tibble: 6 x 3\r\n# Groups:   Department [2]\r\n  index Department             Goal                                   \r\n  <int> <chr>                  <chr>                                  \r\n1     1 Distance Graduate TELS Deeper understanding of Quantitative a~\r\n2     2 Distance Graduate TELS Choose a dissertation topic that makes~\r\n3     3 Distance Graduate TELS 4.0 Baby                               \r\n4     4 Distance Graduate TELS To Graduate                            \r\n5     5 Distance Graduate TELS Finish my Book                         \r\n6     6 Graduate TELS          Learn about 3 topics and become more c~\r\n\r\nI quickly visualize the data looking at all occurrences and the\r\npercentage of participation for each department with the VTREE\r\npackage.\r\nWe see that students from the Undergraduate department with the\r\nhighest participation rate is Undergraduate TELS at 47% participation\r\nrate. The highest participation rate in the Graduate department is also\r\nfrom TELS at 14% of participants. The smallest participation rates are\r\nin Graduate STEM and all DE departments. We can quickly conclude that\r\nUndergraduate students in general frequent METRC the most out of the\r\nCollege of Education from the event data.\r\n\r\n\r\nlibrary(vtree)\r\nvtree(soar_data2, \"Department\", horiz=FALSE, palette = 4, sortfill = TRUE)\r\n\r\n\r\n\r\n\r\nc. TidyText\r\nUsing Wickham\r\n2014, Tidy principleswe tokenize our data making each variable a\r\ncolumn, each observation a row and each type of observational unit is a\r\ntable with:\r\nunnest_tokens() that splits a column into tokens\r\nanti_join() returns all rows from x without a match in y and\r\nremove stop word.\r\ntokenize our data\r\n\r\n\r\nsoardata2_df <- soar_data2 %>% #create new tokenize data frame\r\n  unnest_tokens(output = word, input = Goal) %>%\r\n  anti_join(stop_words, by = \"word\") # remove all stop words\r\n\r\n\r\n\r\nI noticed I wrangled out my unique identifier. So, I created a new\r\ncolumn to count up later on with the variable name ‘number.’\r\n\r\n\r\nsoardata2_df <- soardata2_df %>%\r\n  mutate(number = row_number()) # add a new column named number to be used as the unique identifier\r\n\r\nsoardata2_df %>%\r\n  head()\r\n\r\n\r\n# A tibble: 6 x 3\r\n# Groups:   Department [1]\r\n  Department             word          number\r\n  <chr>                  <chr>          <int>\r\n1 Distance Graduate TELS deeper             1\r\n2 Distance Graduate TELS understanding      2\r\n3 Distance Graduate TELS quantitative       3\r\n4 Distance Graduate TELS qualitative        4\r\n5 Distance Graduate TELS research           5\r\n6 Distance Graduate TELS methods            6\r\n\r\n3. Explore\r\nLet’s explore our data looking for common words together, and then\r\nfilter out sentiments.\r\nCount Tokenized Words\r\nLet’s count the tokenize words. It looks as though\r\nStudents, Learn, and\r\nGoal are at the top three common words in the Soar Data\r\nand we have a lot of words that only appeared once or twice. What was\r\ninteresting as most are unique words. I may not stem the words then.\r\nWord Cloud of\r\nCommon Words in ALL Departments\r\nNoticing that “student” and “learn” are at the top of the list.\r\n“Goal” was part of the prompt so that word being in the top three is not\r\na surprise.\r\n\r\n\r\nsoardata1_df_counts <- soardata2_df %>% # create new variable for counts\r\n  ungroup ()%>%  #ungroup the tokenize data to create a wordcloud\r\n  count(word, sort = TRUE)\r\n\r\nwordcloud2(soardata1_df_counts)\r\n\r\n\r\n\r\n{\"x\":{\"word\":[\"students\",\"learn\",\"goal\",\"teacher\",\"classroom\",\"field\",\"graduate\",\"teaching\",\"future\",\"semester\",\"stay\",\"time\",\"connections\",\"finish\",\"pass\",\"placement\",\"educator\",\"grades\",\"grow\",\"positive\",\"classes\",\"learning\",\"build\",\"confident\",\"create\",\"knowledge\",\"growth\",\"lesson\",\"management\",\"people\",\"strong\",\"teach\",\"teachers\",\"care\",\"complete\",\"culturally\",\"dissertation\",\"experience\",\"experiences\",\"feel\",\"impact\",\"internship\",\"mental\",\"mindset\",\"motivated\",\"relationships\",\"responsive\",\"school\",\"skills\",\"successful\",\"4.0\",\"balance\",\"career\",\"ced\",\"class\",\"comfortable\",\"community\",\"continue\",\"design\",\"environment\",\"gain\",\"happy\",\"health\",\"healthy\",\"improve\",\"instructional\",\"job\",\"meet\",\"mentally\",\"peers\",\"plans\",\"program\",\"resources\",\"schools\",\"start\",\"strategies\",\"successfully\",\"support\",\"top\",\"week\",\"2022\",\"apply\",\"box\",\"business\",\"calculus\",\"change\",\"children\",\"classmates\",\"comfort\",\"confidence\",\"creating\",\"degree\",\"develop\",\"education\",\"emotionally\",\"encourage\",\"engage\",\"engineering\",\"enjoy\",\"excited\",\"explore\",\"family\",\"finding\",\"focus\",\"foster\",\"friends\",\"fun\",\"goals\",\"hope\",\"ideas\",\"influence\",\"life\",\"list\",\"local\",\"ncsu\",\"network\",\"obtain\",\"partners\",\"passing\",\"person\",\"physically\",\"plan\",\"process\",\"proud\",\"readings\",\"remain\",\"research\",\"safe\",\"student\",\"succeed\",\"summer\",\"survive\",\"taking\",\"topics\",\"voice\",\"write\",\"zone\",\"1\",\"12\",\"141\",\"185\",\"2021\",\"2023\",\"3\",\"3.0\",\"3.8\",\"4\",\"5\",\"8\",\"abilities\",\"ability\",\"abroad\",\"academic\",\"accomplished\",\"accountable\",\"act\",\"active\",\"actively\",\"adapt\",\"advocate\",\"anxieties\",\"assistance\",\"awesome\",\"b's\",\"baby\",\"bench\",\"beore\",\"betterment\",\"book\",\"books\",\"busyness\",\"calling\",\"catch\",\"chapters\",\"choose\",\"civil\",\"coda\",\"cohort\",\"collaborate\",\"collect\",\"college\",\"communicate\",\"comps\",\"connect\",\"conscious\",\"continueing\",\"contribute\",\"counseling\",\"courses\",\"crate\",\"createcreate\",\"creative\",\"credits\",\"critically\",\"cry\",\"culture\",\"curious\",\"daily\",\"dean's\",\"deans\",\"decisions\",\"deeper\",\"difference\",\"disabilities\",\"discover\",\"dr\",\"drive\",\"dropout\",\"ed\",\"edtpa\",\"educational\",\"educators\",\"effective\",\"effectively\",\"effort\",\"elementary\",\"engaging\",\"enter\",\"entire\",\"equitable\",\"establish\",\"europe\",\"event\",\"exam\",\"excellent\",\"exciting\",\"expand\",\"experienced\",\"feeling\",\"feels\",\"fellowship\",\"fieldwork\",\"figure\",\"fills\",\"fixed\",\"focal\",\"front\",\"fulfilled\",\"games\",\"gen\",\"gpa\",\"grade\",\"graduation\",\"hands\",\"hard\",\"highly\",\"hold\",\"honors\",\"hoping\",\"hours\",\"human\",\"identity\",\"inbox\",\"inclusion\",\"incorporate\",\"inspiration\",\"inspire\",\"interactive\",\"involved\",\"j.s\",\"join\",\"journey\",\"joyful\",\"kamoru\",\"keeping\",\"key\",\"kids\",\"knowing\",\"land\",\"learnhow\",\"lifestyle\",\"lines\",\"lives\",\"ma\",\"main\",\"maintain\",\"maintaining\",\"makes\",\"matters\",\"maximize\",\"meaning\",\"mentor\",\"mercedes\",\"methods\",\"minded\",\"nc\",\"nce\",\"nicer\",\"online\",\"organization\",\"organized\",\"orking\",\"overthink\",\"overwhelm\",\"overwhelmed\",\"passion\",\"patient\",\"perfect\",\"performance\",\"persevere\",\"personal\",\"phd\",\"physical\",\"piece\",\"planning\",\"planted\",\"play\",\"plenty\",\"poder\",\"positively\",\"potential\",\"practicing\",\"prepared\",\"preparing\",\"preservice\",\"priority\",\"productive\",\"profession\",\"professional\",\"professors\",\"progress\",\"promote\",\"prospectus\",\"provide\",\"pta\",\"public\",\"purpose\",\"push\",\"qualitative\",\"quantitative\",\"quickly\",\"read\",\"reamin\",\"reliable\",\"researcher\",\"respectful\",\"respirar\",\"responsibilities\",\"sanity\",\"schedule\",\"science\",\"selfcare\",\"sessions\",\"si\",\"sleep\",\"smile\",\"source\",\"speaking\",\"spend\",\"spiritally\",\"sports\",\"spread\",\"stable\",\"started\",\"starting\",\"stats\",\"stress\",\"stronger\",\"styudents\",\"subbing\",\"supportive\",\"survival\",\"sweat\",\"synthesize\",\"talk\",\"terms\",\"times\",\"tools\",\"topic\",\"travel\",\"truest\",\"trust\",\"understand\",\"understanding\",\"unrequired\",\"void\",\"wlak\",\"world\",\"writer\",\"writting\",\"wrong\"],\"freq\":[26,25,20,16,14,14,12,12,11,11,10,10,9,9,9,9,8,8,8,8,7,7,6,6,6,6,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"fontFamily\":\"Segoe UI\",\"fontWeight\":\"bold\",\"color\":\"random-dark\",\"minSize\":0,\"weightFactor\":6.92307692307692,\"backgroundColor\":\"white\",\"gridSize\":0,\"minRotation\":-0.785398163397448,\"maxRotation\":0.785398163397448,\"shuffle\":true,\"rotateRatio\":0.4,\"shape\":\"circle\",\"ellipticity\":0.65,\"figBase64\":null,\"hover\":null},\"evals\":[],\"jsHooks\":{\"render\":[{\"code\":\"function(el,x){\\n                        console.log(123);\\n                        if(!iii){\\n                          window.location.reload();\\n                          iii = False;\\n\\n                        }\\n  }\",\"data\":null}]}}\r\nCommon Words by Department\r\nIt is hard to visualize the data in a table form.\r\n\r\n\r\nsoardata1_df_counts <- soardata2_df %>% # create new variable for counts\r\n  count(word, sort = TRUE)\r\n\r\nsoardata1_df_counts \r\n\r\n\r\n# A tibble: 511 x 3\r\n# Groups:   Department [7]\r\n   Department         word            n\r\n   <chr>              <chr>       <int>\r\n 1 Undergraduate TELS students       20\r\n 2 Undergraduate TELS learn          19\r\n 3 Undergraduate TELS field          14\r\n 4 Undergraduate TELS teacher        13\r\n 5 Undergraduate TELS classroom      12\r\n 6 Undergraduate TELS connections     9\r\n 7 Undergraduate TELS placement       9\r\n 8 Undergraduate STEM graduate        8\r\n 9 Undergraduate TELS semester        8\r\n10 Undergraduate TELS teaching        8\r\n# ... with 501 more rows\r\n\r\nMaybe a bar graph would be a better visualization viewing each\r\ndepartments most common words.\r\n\r\n\r\nsoarviz_1 <- soardata2_df %>%\r\n  count(word, sort = TRUE) %>%\r\n  filter(n > 10) %>%\r\n  mutate(word = reorder(word, n)) %>%\r\n  ggplot(aes(n, word, fill = Department)) +\r\n  geom_col(show.legend = FALSE) \r\n\r\n\r\nsoarviz_1 %>% \r\nhead()\r\n\r\n\r\n$data\r\n# A tibble: 5 x 4\r\n# Groups:   Department [1]\r\n  Department         word          n .group\r\n  <chr>              <fct>     <int>  <int>\r\n1 Undergraduate TELS students     20      1\r\n2 Undergraduate TELS learn        19      1\r\n3 Undergraduate TELS field        14      1\r\n4 Undergraduate TELS teacher      13      1\r\n5 Undergraduate TELS classroom    12      1\r\n\r\n$layers\r\n$layers[[1]]\r\ngeom_col: width = NULL, na.rm = FALSE\r\nstat_identity: na.rm = FALSE\r\nposition_stack \r\n\r\n\r\n$scales\r\n<ggproto object: Class ScalesList, gg>\r\n    add: function\r\n    clone: function\r\n    find: function\r\n    get_scales: function\r\n    has_scale: function\r\n    input: function\r\n    n: function\r\n    non_position_scales: function\r\n    scales: list\r\n    super:  <ggproto object: Class ScalesList, gg>\r\n\r\n$mapping\r\nAesthetic mapping: \r\n* `x`    -> `n`\r\n* `y`    -> `word`\r\n* `fill` -> `Department`\r\n\r\n$theme\r\nlist()\r\n\r\n$coordinates\r\n<ggproto object: Class CoordCartesian, Coord, gg>\r\n    aspect: function\r\n    backtransform_range: function\r\n    clip: on\r\n    default: TRUE\r\n    distance: function\r\n    expand: TRUE\r\n    is_free: function\r\n    is_linear: function\r\n    labels: function\r\n    limits: list\r\n    modify_scales: function\r\n    range: function\r\n    render_axis_h: function\r\n    render_axis_v: function\r\n    render_bg: function\r\n    render_fg: function\r\n    setup_data: function\r\n    setup_layout: function\r\n    setup_panel_guides: function\r\n    setup_panel_params: function\r\n    setup_params: function\r\n    train_panel_guides: function\r\n    transform: function\r\n    super:  <ggproto object: Class CoordCartesian, Coord, gg>\r\n\r\n\r\n\r\nwords_by_Department <- soardata1_df_counts %>%\r\n  count(Department, word, sort = TRUE) %>%\r\n  ungroup()\r\n\r\n\r\n\r\n\r\n\r\ntotal_words <- words_by_Department %>% \r\n  group_by(Department) %>% \r\n  summarize(total = sum(n))\r\n\r\nwords_by_Department <- left_join(words_by_Department, total_words)\r\n\r\nwords_by_Department\r\n\r\n\r\n# A tibble: 511 x 4\r\n   Department             word         n total\r\n   <chr>                  <chr>    <int> <int>\r\n 1 Distance ELPHD         2023         1     4\r\n 2 Distance ELPHD         dr           1     4\r\n 3 Distance ELPHD         kamoru       1     4\r\n 4 Distance ELPHD         mercedes     1     4\r\n 5 Distance Graduate TELS 4.0          1    18\r\n 6 Distance Graduate TELS baby         1    18\r\n 7 Distance Graduate TELS book         1    18\r\n 8 Distance Graduate TELS choose       1    18\r\n 9 Distance Graduate TELS curious      1    18\r\n10 Distance Graduate TELS deeper       1    18\r\n# ... with 501 more rows\r\n\r\nLet’s explore the Zipfs law\r\nFrom Text Mining\r\nwith R - Zipf’s law states that the frequency that a word appears is\r\ninversely proportional to its rank.\r\n\r\n\r\nfreq_by_rank <- words_by_Department %>% \r\n  group_by(Department) %>% \r\n  mutate(rank = row_number(), \r\n         `term frequency` = n/total) %>%\r\n  ungroup()\r\n\r\n\r\n\r\n\r\n\r\ntf_idf <- words_by_Department %>%\r\n  bind_tf_idf(word, Department, n) \r\n\r\n\r\ntf_idf\r\n\r\n\r\n# A tibble: 511 x 7\r\n   Department             word         n total     tf   idf tf_idf\r\n   <chr>                  <chr>    <int> <int>  <dbl> <dbl>  <dbl>\r\n 1 Distance ELPHD         2023         1     4 0.25    1.95 0.486 \r\n 2 Distance ELPHD         dr           1     4 0.25    1.95 0.486 \r\n 3 Distance ELPHD         kamoru       1     4 0.25    1.95 0.486 \r\n 4 Distance ELPHD         mercedes     1     4 0.25    1.95 0.486 \r\n 5 Distance Graduate TELS 4.0          1    18 0.0556  1.25 0.0696\r\n 6 Distance Graduate TELS baby         1    18 0.0556  1.95 0.108 \r\n 7 Distance Graduate TELS book         1    18 0.0556  1.95 0.108 \r\n 8 Distance Graduate TELS choose       1    18 0.0556  1.95 0.108 \r\n 9 Distance Graduate TELS curious      1    18 0.0556  1.95 0.108 \r\n10 Distance Graduate TELS deeper       1    18 0.0556  1.95 0.108 \r\n# ... with 501 more rows\r\n\r\nLet’s look at high frequency words in each department\r\n\r\n\r\ntf_idf %>%\r\n  select(-total) %>%\r\n  arrange(desc(tf_idf))\r\n\r\n\r\n# A tibble: 511 x 6\r\n   Department             word         n     tf   idf tf_idf\r\n   <chr>                  <chr>    <int>  <dbl> <dbl>  <dbl>\r\n 1 Distance ELPHD         2023         1 0.25    1.95  0.486\r\n 2 Distance ELPHD         dr           1 0.25    1.95  0.486\r\n 3 Distance ELPHD         kamoru       1 0.25    1.95  0.486\r\n 4 Distance ELPHD         mercedes     1 0.25    1.95  0.486\r\n 5 Distance Graduate TELS baby         1 0.0556  1.95  0.108\r\n 6 Distance Graduate TELS book         1 0.0556  1.95  0.108\r\n 7 Distance Graduate TELS choose       1 0.0556  1.95  0.108\r\n 8 Distance Graduate TELS curious      1 0.0556  1.95  0.108\r\n 9 Distance Graduate TELS deeper       1 0.0556  1.95  0.108\r\n10 Distance Graduate TELS fills        1 0.0556  1.95  0.108\r\n# ... with 501 more rows\r\n\r\nModel\r\nHere we will model our word occurances, Bigrams, Trigrams, Sentiment\r\nand then a Topic Model.\r\nWe are looking to visusalize the 10 frequency words from our term\r\nfrequency data. The visualization did not work because the data is so\r\nsmall there are many words in the top 5 count so they are\r\noverlapping.\r\n\r\n\r\nlibrary(forcats)\r\n\r\n\r\n\r\ntf_idf %>%\r\n  group_by(Department) %>%\r\n  slice_max(tf_idf, n = 10) %>%\r\n  ungroup() %>%\r\n  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = Department)) +\r\n  geom_col(show.legend = FALSE) +\r\n  facet_wrap(~Department, ncol = 3, scales = \"free\") +\r\n  labs(x = \"tf-idf\", y = NULL)\r\n\r\n\r\n\r\n\r\nI did not have more luck with a histogram..\r\n\r\n\r\nggplot(words_by_Department, aes(n/total, fill = Department)) +\r\n  geom_histogram(show.legend = FALSE) +\r\n  facet_wrap(~Department, ncol = 3, scales = \"free_y\")\r\n\r\n\r\n\r\n\r\nBigram\r\nBy tokenizing n-grams we can check out the bigrams to see if they are\r\nof any help with noticing themes.\r\n\r\n\r\nsoardata2_bigrams <- soar_data2 %>%\r\n  unnest_tokens(output = word, input = Goal, token = \"ngrams\", n = 2) %>%\r\n  anti_join(stop_words, by = \"word\")\r\n\r\nsoardata2_bigrams_counts <- soardata2_bigrams %>%\r\n  count(word, sort = TRUE)\r\n\r\nsoardata2_bigrams_counts\r\n\r\n\r\n# A tibble: 1,618 x 3\r\n# Groups:   Department [7]\r\n   Department         word                 n\r\n   <chr>              <chr>            <int>\r\n 1 Undergraduate TELS to be               15\r\n 2 Undergraduate TELS in my               12\r\n 3 Undergraduate TELS i want              11\r\n 4 Undergraduate TELS want to             10\r\n 5 Undergraduate TELS field placement      9\r\n 6 Undergraduate TELS in the               9\r\n 7 Undergraduate TELS my field             9\r\n 8 Undergraduate TELS connections with     8\r\n 9 Undergraduate TELS how to               8\r\n10 Undergraduate TELS of my                8\r\n# ... with 1,608 more rows\r\n\r\nMy original bigram code did not provide good results I will use the\r\ntidyr’s separate(), which splits a column into multiple based on a\r\ndelimiter. This process shows much better results. Working in the CED I\r\nknow that a growth mindset was being taught to Early Elmentary students,\r\nadditionally students started field placements in the Fall and Spring.\r\nMany of the goals included ideal bigrams of what we would imagine to see\r\nin the College of Ed.\r\n\r\n\r\nsoardata2_bigrams2 <- soar_data2 %>%\r\n  unnest_tokens(bigram, Goal, token = \"ngrams\", n = 2) %>%\r\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>%\r\n  filter(!word1 %in% stop_words$word,\r\n         !word2 %in% stop_words$word) %>%\r\n  unite(bigram, word1, word2, sep = \" \") %>% \r\n  count(bigram, sort = TRUE)\r\n\r\nsoardata2_bigrams2\r\n\r\n\r\n# A tibble: 248 x 3\r\n# Groups:   Department [7]\r\n   Department         bigram                    n\r\n   <chr>              <chr>                 <int>\r\n 1 Undergraduate TELS field placement           9\r\n 2 Undergraduate TELS growth mindset            3\r\n 3 Undergraduate TELS mental health             3\r\n 4 Graduate TELS      time management           2\r\n 5 Undergraduate STEM comfort zone              2\r\n 6 Undergraduate STEM design process            2\r\n 7 Undergraduate STEM time management           2\r\n 8 Undergraduate TELS build relationships       2\r\n 9 Undergraduate TELS classroom finish          2\r\n10 Undergraduate TELS culturally responsive     2\r\n# ... with 238 more rows\r\n\r\nTrigram\r\nRunning a trigram did not produce a result that pulls out any new\r\nthemes.\r\n\r\n\r\nsoardata2_trigrams <- soar_data2 %>%\r\n  unnest_tokens(trigram, Goal, token = \"ngrams\", n = 3) %>%\r\n  separate(trigram, c(\"word1\", \"word2\", \"word3\"), sep = \" \") %>%\r\n  filter(!word1 %in% stop_words$word,\r\n         !word2 %in% stop_words$word,\r\n         !word3 %in% stop_words$word) %>%\r\n  unite(trigram, word1, word2, word3, sep = \" \") %>% \r\n  count(trigram, sort = TRUE)\r\n\r\nsoardata2_trigrams\r\n\r\n\r\n# A tibble: 84 x 3\r\n# Groups:   Department [7]\r\n   Department             trigram                             n\r\n   <chr>                  <chr>                           <int>\r\n 1 Undergraduate TELS     field placement classroom           2\r\n 2 Undergraduate TELS     field placement students            2\r\n 3 Distance ELPHD         dr mercedes kamoru                  1\r\n 4 Distance ELPHD         mercedes kamoru 2023                1\r\n 5 Distance Graduate TELS qualitative research methods        1\r\n 6 Distance Graduate TELS research methods choose             1\r\n 7 Distance Graduate TELS void 4.0 baby                       1\r\n 8 ELPHD                  culture responsive teaching         1\r\n 9 ELPHD                  incorporate culture responsive      1\r\n10 ELPHD                  spiritally emotionally mentally     1\r\n# ... with 74 more rows\r\n\r\nSENTIMENT ANALYSIS\r\nUsing the {tidytext} package we can analyze sentiments with\r\nlexicons, sometimes\r\nreferred to as dictionaries.\r\nAFINN from Finn Årup Nielsen - assigns words\r\nwith a score that runs between -5 and 5, with negative scores indicating\r\nnegative sentiment and positive scores indicating positive\r\nsentiment.\r\nbing from Bing Liu and collaborators -\r\ncategorizes words in a binary fashion into positive and negative\r\ncategories, and\r\nnrc from Saif Mohammad and Peter Turney.\r\n-categorizes words in a binary fashion (“yes”/“no”) into categories of\r\npositive, negative, anger, anticipation, disgust, fear, joy, sadness,\r\nsurprise, and trust.\r\nIt will be intersting to see if what emotions the students have in\r\ntheir written goals. Additionally comparing a lexicon for positive and\r\nnegative sentiment.\r\nLoad Sentiment Lexicons\r\n\r\n\r\nget_sentiments(\"afinn\")\r\n\r\n\r\n# A tibble: 2,477 x 2\r\n   word       value\r\n   <chr>      <dbl>\r\n 1 abandon       -2\r\n 2 abandoned     -2\r\n 3 abandons      -2\r\n 4 abducted      -2\r\n 5 abduction     -2\r\n 6 abductions    -2\r\n 7 abhor         -3\r\n 8 abhorred      -3\r\n 9 abhorrent     -3\r\n10 abhors        -3\r\n# ... with 2,467 more rows\r\n\r\n\r\n\r\nget_sentiments(\"bing\")\r\n\r\n\r\n# A tibble: 6,786 x 2\r\n   word        sentiment\r\n   <chr>       <chr>    \r\n 1 2-faces     negative \r\n 2 abnormal    negative \r\n 3 abolish     negative \r\n 4 abominable  negative \r\n 5 abominably  negative \r\n 6 abominate   negative \r\n 7 abomination negative \r\n 8 abort       negative \r\n 9 aborted     negative \r\n10 aborts      negative \r\n# ... with 6,776 more rows\r\n\r\n\r\n\r\nget_sentiments(\"nrc\")\r\n\r\n\r\n# A tibble: 13,875 x 2\r\n   word        sentiment\r\n   <chr>       <chr>    \r\n 1 abacus      trust    \r\n 2 abandon     fear     \r\n 3 abandon     negative \r\n 4 abandon     sadness  \r\n 5 abandoned   anger    \r\n 6 abandoned   fear     \r\n 7 abandoned   negative \r\n 8 abandoned   sadness  \r\n 9 abandonment anger    \r\n10 abandonment fear     \r\n# ... with 13,865 more rows\r\n\r\nUsing the “Bing Lexicon” the total “Soar Data” shows 8\r\nnegative polarity words and 102 positive polarity words. This means that\r\nthere are 94 more positive than negative words in this text.\r\n\r\n\r\nbing_tokens <- soardata2_df %>%\r\n  inner_join(get_sentiments(\"bing\")) %>% # pull out only sentiment words\r\n  count(sentiment) %>% # count the # of positive & negative words\r\n  spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow\r\n  mutate(sentiment = positive - negative) # # of positive words - # of negative owrds\r\n\r\nbing_tokens\r\n\r\n\r\n# A tibble: 5 x 4\r\n# Groups:   Department [5]\r\n  Department         negative positive sentiment\r\n  <chr>                 <dbl>    <dbl>     <dbl>\r\n1 ELPHD                     0        6         6\r\n2 Graduate STEM             0        3         3\r\n3 Graduate TELS             0        8         8\r\n4 Undergraduate STEM        6       22        16\r\n5 Undergraduate TELS        2       63        61\r\n\r\n\r\n\r\nbing_word_counts <- soardata2_df %>%\r\n  inner_join(get_sentiments(\"bing\")) %>%\r\n  count(word, sentiment, sort = TRUE) %>%\r\n  ungroup()\r\n\r\nbing_word_counts\r\n\r\n\r\n# A tibble: 83 x 4\r\n   Department         word        sentiment     n\r\n   <chr>              <chr>       <chr>     <int>\r\n 1 Undergraduate TELS positive    positive      7\r\n 2 Undergraduate TELS confident   positive      4\r\n 3 Undergraduate TELS strong      positive      4\r\n 4 Undergraduate TELS successful  positive      4\r\n 5 Undergraduate TELS comfortable positive      3\r\n 6 Undergraduate TELS gain        positive      3\r\n 7 Undergraduate TELS motivated   positive      3\r\n 8 Graduate TELS      healthy     positive      2\r\n 9 Undergraduate STEM comfort     positive      2\r\n10 Undergraduate STEM support     positive      2\r\n# ... with 73 more rows\r\n\r\nWe can look at how much each word contributed to each sentiment\r\n\r\n\r\nbing_word_counts %>%\r\n  group_by(sentiment) %>%\r\n  slice_max(n, n = 10) %>% \r\n  ungroup() %>%\r\n  mutate(word = reorder(word, n)) %>%\r\n  ggplot(aes(n, word, fill = sentiment)) +\r\n  geom_col(show.legend = FALSE) +\r\n  facet_wrap(~sentiment, scales = \"free_y\") +\r\n  labs(x = \"Contribution to sentiment\",\r\n       y = NULL)\r\n\r\n\r\n\r\n\r\nUsing the “NRC Lexicon” the total “Soar Data” shows 8\r\nnegative polarity words and 223 positive polarity words. This means that\r\nthere are 215 more positive than negative words in this text. The most\r\ncommon sentiment was with “anticipation at 89 words and”joy” at 77\r\nwords.\r\n\r\n\r\nnrc_tokens <- soardata2_df %>%\r\n  inner_join(get_sentiments(\"nrc\")) %>% # pull out only sentiment words\r\n  count(sentiment) %>% # count the # of positive & negative words\r\n  spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow\r\n  mutate(sentiment = positive - negative) # # of positive words - # of negative owrds\r\n\r\nnrc_tokens\r\n\r\n\r\n# A tibble: 6 x 12\r\n# Groups:   Department [6]\r\n  Department  anger anticipation disgust  fear   joy negative positive\r\n  <chr>       <dbl>        <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl>\r\n1 Distance G~     0            0       0     0     1        0        2\r\n2 ELPHD           0            2       0     0     2        0        5\r\n3 Graduate S~     0            3       0     1     3        0        7\r\n4 Graduate T~     0            9       0     1     7        0       31\r\n5 Undergradu~     1           23       1     5    20        6       45\r\n6 Undergradu~     0           52       0     2    44        2      133\r\n# ... with 4 more variables: sadness <dbl>, surprise <dbl>,\r\n#   trust <dbl>, sentiment <dbl>\r\n\r\nLet’s quickly look at the most common joy words in the soar data that\r\nare associated with joy in the nrc.\r\n\r\n\r\nnrc_joy <- get_sentiments(\"nrc\") %>% \r\n  filter(sentiment == \"joy\")\r\n\r\njoysoar_nrc <- soardata2_df %>%\r\n  inner_join(nrc_joy) %>%\r\n  count(word, sort = TRUE)\r\n\r\njoysoar_nrc\r\n\r\n\r\n# A tibble: 53 x 3\r\n# Groups:   Department [6]\r\n   Department         word           n\r\n   <chr>              <chr>      <int>\r\n 1 Undergraduate TELS create         5\r\n 2 Undergraduate TELS confident      4\r\n 3 Undergraduate TELS grow           4\r\n 4 Undergraduate TELS successful     4\r\n 5 Undergraduate TELS teach          4\r\n 6 Undergraduate TELS gain           3\r\n 7 Graduate TELS      grow           2\r\n 8 Undergraduate STEM comfort        2\r\n 9 Undergraduate STEM grow           2\r\n10 Undergraduate TELS excited        2\r\n# ... with 43 more rows\r\n\r\nLooking also at the negative sentiments. This looks strange and\r\n\r\n\r\nnrc_negative <- get_sentiments(\"nrc\") %>% \r\n  filter(sentiment == \"negative\")\r\n\r\nnegativesoar_nrc <- soardata2_df %>%\r\n  inner_join(nrc_negative) %>%\r\n  count(word, sort = TRUE)\r\n\r\nnegativesoar_nrc\r\n\r\n\r\n# A tibble: 8 x 3\r\n# Groups:   Department [2]\r\n  Department         word            n\r\n  <chr>              <chr>       <int>\r\n1 Undergraduate STEM cry             1\r\n2 Undergraduate STEM feeling         1\r\n3 Undergraduate STEM influence       1\r\n4 Undergraduate STEM overwhelm       1\r\n5 Undergraduate STEM overwhelmed     1\r\n6 Undergraduate STEM stress          1\r\n7 Undergraduate TELS influence       1\r\n8 Undergraduate TELS wrong           1\r\n\r\nLet’s use use the filter(),\r\nselect() and grepl() function to\r\nselect just our goals column and filter out responses that contain some\r\nof the negative words shown.\r\nHere we can see that feeling in near fulfilled maybe not so\r\nnegative\r\n\r\n\r\nsoar_negative_quotes <- soar_data2 %>%\r\n  select(Goal) %>% \r\n  filter(grepl('feeling', Goal))\r\n\r\nsoar_negative_quotes\r\n\r\n\r\n# A tibble: 1 x 2\r\n# Groups:   Department [1]\r\n  Department         Goal                              \r\n  <chr>              <chr>                             \r\n1 Undergraduate STEM end the semester feeling fulfilled\r\n\r\nI am not sure that this is necessarily a negative sentiment either\r\nsince the goals was not to do something.\r\n\r\n\r\nsoar_negative_quotes <- soar_data2 %>%\r\n  select(Goal) %>% \r\n  filter(grepl('cry', Goal))\r\n\r\nsoar_negative_quotes\r\n\r\n\r\n# A tibble: 1 x 2\r\n# Groups:   Department [1]\r\n  Department         Goal                           \r\n  <chr>              <chr>                          \r\n1 Undergraduate STEM Not cry in front of my students\r\n\r\nLet’s look at one more negative nrc sentiment and use the * operator\r\nto look for word stems.\r\n\r\n\r\nsoar_negative_quotes <- soar_data2 %>%\r\n  select(Goal) %>% \r\n  filter(grepl('overwhelm*', Goal)) #look for word stems\r\n\r\nsoar_negative_quotes\r\n\r\n\r\n# A tibble: 2 x 2\r\n# Groups:   Department [1]\r\n  Department         Goal                                             \r\n  <chr>              <chr>                                            \r\n1 Undergraduate STEM Not overthink and get overwhelmed but to trust m~\r\n2 Undergraduate STEM To get good grades and not overwhelm myself.     \r\n\r\nWe can see that overall most of the sentiments in the goals data are\r\npositive for most Departments. After looking at the phrases that\r\ncorrelated with the negative words I am not sure with hand coding those\r\nwould be considered negative. The ncr sentiment showed\r\na larger number of words vs Bing.\r\n\r\n\r\nsoar_nrc_sentiment <- soardata2_df%>%\r\n  inner_join(get_sentiments(\"nrc\")) %>%\r\n  count(Department, index = number %/% 5, sentiment) %>%\r\n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% \r\n  mutate(sentiment = positive - negative)\r\n  \r\nsoar_nrc_sentiment\r\n\r\n\r\n# A tibble: 140 x 13\r\n# Groups:   Department [6]\r\n   Department   index positive trust   joy anticipation surprise  fear\r\n   <chr>        <dbl>    <int> <int> <int>        <int>    <int> <int>\r\n 1 Distance Gr~     0        1     1     0            0        0     0\r\n 2 Distance Gr~     3        1     0     1            0        0     0\r\n 3 ELPHD            0        1     1     1            1        0     0\r\n 4 ELPHD            1        1     1     1            0        1     0\r\n 5 ELPHD            2        2     1     0            1        0     0\r\n 6 ELPHD            4        1     0     0            0        0     0\r\n 7 Graduate ST~     0        2     1     0            0        0     0\r\n 8 Graduate ST~     1        3     1     1            0        0     0\r\n 9 Graduate ST~     2        2     2     2            2        0     0\r\n10 Graduate ST~     4        0     0     0            1        0     0\r\n# ... with 130 more rows, and 5 more variables: anger <int>,\r\n#   disgust <int>, negative <int>, sadness <int>, sentiment <int>\r\n\r\nLet’s plot negative vs positive sentiment by department with NRC\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\nggplot(soar_nrc_sentiment, aes(index, sentiment, fill = Department)) + #use index as the X and sentiment as y by department\r\n  geom_col(show.legend = FALSE) + # don;t show the legend\r\n  facet_wrap(~Department, ncol = 2, scales = \"free_x\")  # put in 2 columns\r\n\r\n\r\n\r\n\r\nLet us see what the Bing visualization looks like.\r\n\r\n\r\nsoar_bing_sentiment <- soardata2_df%>%\r\n  inner_join(get_sentiments(\"bing\")) %>%\r\n  count(Department, index = number %/% 5, sentiment) %>%\r\n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% \r\n  mutate(sentiment = positive - negative)\r\n  \r\nsoar_bing_sentiment\r\n\r\n\r\n# A tibble: 85 x 5\r\n# Groups:   Department [5]\r\n   Department    index positive negative sentiment\r\n   <chr>         <dbl>    <int>    <int>     <int>\r\n 1 ELPHD             0        2        0         2\r\n 2 ELPHD             1        1        0         1\r\n 3 ELPHD             2        1        0         1\r\n 4 ELPHD             3        1        0         1\r\n 5 ELPHD             4        1        0         1\r\n 6 Graduate STEM     1        1        0         1\r\n 7 Graduate STEM     2        2        0         2\r\n 8 Graduate TELS     0        1        0         1\r\n 9 Graduate TELS     2        1        0         1\r\n10 Graduate TELS     3        1        0         1\r\n# ... with 75 more rows\r\n\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\nggplot(soar_bing_sentiment, aes(index, sentiment, fill = Department)) +\r\n  geom_col(show.legend = FALSE) +\r\n  facet_wrap(~Department, ncol = 2, scales = \"free_x\")\r\n\r\n\r\n\r\n\r\nTopic Modeling\r\nLet’s explore the data by doing a parameterized model like Latent\r\nDiricj=hlet Allocation (LDA) will pull out any terms from the Goals that\r\nMETRC can focus on to help support the students of the College of\r\nEducation.\r\nTopic Models can help to determine the proportionate composition of a\r\nfixed number of topics within a collection of data. Our data here is ver\r\nsmall in comparison to say doing exploring topics within a Literature\r\nReview.\r\nDocument Matrix\r\nFirst we need to create a document term matrix with soardata2_df. We\r\nwill remove stop words since they are uninformative.\r\n\r\n\r\nsoar_dtm <- soardata2_df %>%\r\n  count(number, word, sort = TRUE) %>%\r\n  ungroup()\r\n\r\ncast_dtm <- soar_dtm %>%\r\n  cast_dtm(number, word, n)\r\n\r\n\r\n\r\nLets look at the number of terms in the matrix\r\n\r\n\r\ndim(cast_dtm) # look at # of terms in matrix\r\n\r\n\r\n[1] 457 381\r\n\r\nNext we convert to lowercase, remove special characters and stem our\r\ncorpus.\r\n\r\n\r\n#text processing\r\ntemp <- textProcessor(soar_data2$Goal, # use file and variable that has text\r\n                      metadata = soar_data2,\r\n                      lowercase=TRUE, # change to lowercase\r\n                      removestopwords=TRUE, # remove stop words\r\n                      removenumbers=TRUE, # remove numbers\r\n                      removepunctuation=TRUE, # remove special punctuation\r\n                      wordLengths=c(3,Inf), #Change word lengths to 3\r\n                      stem=FALSE, # stem the corpus\r\n                      onlycharacter= FALSE,\r\n                      striphtml=TRUE,\r\n                      customstopwords=FALSE) # do not choose custom stop words\r\n\r\n\r\nBuilding corpus... \r\nConverting to Lower Case... \r\nRemoving punctuation... \r\nRemoving stopwords... \r\nRemove Custom Stopwords...\r\nRemoving numbers... \r\nCreating Output... \r\n\r\ntemp\r\n\r\n\r\nA text corpus with 199 documents, and an 449 word dictionary.\r\n\r\nStem did not work so we must do a different code to ‘Stem’ the\r\ncorpus.\r\n\r\n\r\n#stemming the text\r\nstemmed_soar_data <- soar_data2 %>%\r\n  unnest_tokens(output = word, input = Goal) %>%\r\n  anti_join(stop_words, by = \"word\") %>%\r\n  mutate(stem = wordStem(word)) # create a new variable named stem for the stopwords.\r\n\r\n\r\nstemmed_soar_data\r\n\r\n\r\n# A tibble: 838 x 3\r\n# Groups:   Department [7]\r\n   Department             word          stem      \r\n   <chr>                  <chr>         <chr>     \r\n 1 Distance Graduate TELS deeper        deeper    \r\n 2 Distance Graduate TELS understanding understand\r\n 3 Distance Graduate TELS quantitative  quantit   \r\n 4 Distance Graduate TELS qualitative   qualit    \r\n 5 Distance Graduate TELS research      research  \r\n 6 Distance Graduate TELS methods       method    \r\n 7 Distance Graduate TELS choose        choos     \r\n 8 Distance Graduate TELS dissertation  dissert   \r\n 9 Distance Graduate TELS topic         topic     \r\n10 Distance Graduate TELS makes         make      \r\n# ... with 828 more rows\r\n\r\nTake the Stem words document and add to cast_dtm to create one\r\ncorpus.\r\n\r\n\r\nstemmed_soar_data <- soar_data2 %>%\r\n  unnest_tokens(output = word, input = Goal) %>%\r\n  anti_join(stop_words, by = \"word\") %>%\r\n  mutate(stem = wordStem(word)) %>%\r\n  count(word, stem, sort = TRUE) %>%\r\n  cast_dtm(word, stem, n)\r\n\r\nstemmed_soar_data\r\n\r\n\r\n<<DocumentTermMatrix (documents: 381, terms: 330)>>\r\nNon-/sparse entries: 381/125349\r\nSparsity           : 100%\r\nMaximal term length: 12\r\nWeighting          : term frequency (tf)\r\n\r\n#Latent Dirichlet allocation\r\nUsing the topicmodels package we will run our LDA. Setting K to\r\n10.\r\n\r\n\r\n#running lda to find 8 topics\r\nlda_soar_data <- LDA(cast_dtm, k = 10, control = list(seed = 0713))\r\n\r\nlda_soar_data\r\n\r\n\r\nA LDA_VEM topic model with 10 topics.\r\n\r\nLooking at the Beta occurance for each term\r\n\r\n\r\nsoar_topics <- tidy(lda_soar_data, matrix = \"beta\")\r\nsoar_topics\r\n\r\n\r\n# A tibble: 3,810 x 3\r\n   topic term       beta\r\n   <int> <chr>     <dbl>\r\n 1     1 dr    3.93e-216\r\n 2     2 dr    1.74e-216\r\n 3     3 dr    1.11e-  2\r\n 4     4 dr    2.96e-217\r\n 5     5 dr    9.99e-218\r\n 6     6 dr    3.21e-218\r\n 7     7 dr    6.03e- 45\r\n 8     8 dr    6.83e- 85\r\n 9     9 dr    2.77e-217\r\n10    10 dr    2.01e-225\r\n# ... with 3,800 more rows\r\n\r\nLet’s see how many times the term might occur in each topic. We use\r\naugment() it uses a model to add information to each observation in the\r\noriginal data.\r\n\r\n\r\nsoar_assignments <- augment(lda_soar_data, data = cast_dtm)\r\nsoar_assignments\r\n\r\n\r\n# A tibble: 838 x 4\r\n   document term          count .topic\r\n   <chr>    <chr>         <dbl>  <dbl>\r\n 1 1        dr                1      3\r\n 2 2        mercedes          1      4\r\n 3 3        kamoru            1      8\r\n 4 4        2023              1      8\r\n 5 1        deeper            1      3\r\n 6 2        understanding     1      4\r\n 7 3        quantitative      1      8\r\n 8 4        qualitative       1      8\r\n 9 5        research          1      4\r\n10 28       research          1      3\r\n# ... with 828 more rows\r\n\r\nLook for the most common differences within each of the model\r\ntopics.\r\n\r\n\r\nbeta_wide <- soar_topics %>%\r\n  mutate(topic = paste0(\"topic\", topic)) %>%\r\n  pivot_wider(names_from = topic, values_from = beta) %>% \r\n  filter(topic1 > .001 | topic2 > .001) %>%\r\n  mutate(log_ratio = log2(topic2 / topic1))\r\n\r\nbeta_wide\r\n\r\n\r\n# A tibble: 78 x 12\r\n   term       topic1    topic2    topic3    topic4    topic5    topic6\r\n   <chr>       <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\r\n 1 disser~ 2.16e-180 1.22e-  2 6.22e- 83 3.75e-  2 1.00e- 72 1.25e-181\r\n 2 fills   1.84e-225 1.22e-  2 8.17e-236 4.31e-227 5.92e-229 2.31e-226\r\n 3 learnh~ 2.72e-242 1.22e-  2 1.80e-251 7.58e-146 3.40e-243 5.29e-246\r\n 4 calling 1.23e-  2 1.38e-220 2.77e-213 6.49e-219 2.26e-222 7.83e-220\r\n 5 succes~ 2.29e-163 3.66e-  2 6.43e-172 2.46e-161 6.45e- 29 5.38e-162\r\n 6 mental~ 2.14e-188 3.66e-  2 3.95e- 80 3.05e-150 4.84e-190 1.31e-189\r\n 7 excell~ 2.39e-242 1.22e-  2 1.16e-251 4.81e-145 2.56e-244 2.99e-245\r\n 8 edtpa   1.23e-  2 2.86e-221 6.75e-214 3.09e-219 1.07e-222 1.26e-220\r\n 9 finding 1.49e-176 2.44e-  2 2.54e-185 1.15e- 50 6.56e-179 2.06e-176\r\n10 balance 2.94e-157 3.66e-  2 3.46e-167 6.24e- 56 2.04e- 58 7.27e-157\r\n# ... with 68 more rows, and 5 more variables: topic7 <dbl>,\r\n#   topic8 <dbl>, topic9 <dbl>, topic10 <dbl>, log_ratio <dbl>\r\n\r\nWe can run the posterior distribution on teh LDA Results. This will show\r\nthe compromise between the prior distribution and the likelihood\r\nfunction.\r\n\r\n\r\nldaResult <- posterior(lda_soar_data)\r\n\r\nattributes(ldaResult)\r\n\r\n\r\n$names\r\n[1] \"terms\"  \"topics\"\r\n\r\nnext we look at the length of the vocabulary.\r\n\r\n\r\nncol(cast_dtm)\r\n\r\n\r\n[1] 381\r\n\r\nWe find the k distributions over ncol(cast dtm) terms. We had 10 for K\r\nand 381 for our DTM.\r\n\r\n\r\nbeta <- ldaResult$terms\r\n\r\ndim(beta) # k distributions over ncol(sdtm) terms\r\n\r\n\r\n[1]  10 381\r\n\r\nWe look at the matrix on beta sum to 1\r\n\r\n\r\nrowSums(beta) # rows in beta sum to 1\r\n\r\n\r\n 1  2  3  4  5  6  7  8  9 10 \r\n 1  1  1  1  1  1  1  1  1  1 \r\n\r\n\r\n\r\nnrow(cast_dtm) #size of collection\r\n\r\n\r\n[1] 457\r\n\r\nNext we look at the same within theta.\r\n\r\n\r\ntheta <- ldaResult$topics\r\n\r\ndim(theta) #ndocs (soardtm) distribution over K topics\r\n\r\n\r\n[1] 457  10\r\n\r\nLet’s take a look at the 10 most common terms withing the term\r\nprobability of inferred topics.\r\n\r\n\r\nterms(lda_soar_data, 10)\r\n\r\n\r\n      Topic 1       Topic 2        Topic 3      Topic 4        \r\n [1,] \"field\"       \"classes\"      \"future\"     \"teacher\"      \r\n [2,] \"educator\"    \"growth\"       \"grow\"       \"semester\"     \r\n [3,] \"knowledge\"   \"people\"       \"learning\"   \"positive\"     \r\n [4,] \"build\"       \"teach\"        \"lesson\"     \"internship\"   \r\n [5,] \"care\"        \"experience\"   \"responsive\" \"dissertation\" \r\n [6,] \"mental\"      \"successfully\" \"feel\"       \"happy\"        \r\n [7,] \"experiences\" \"mentally\"     \"start\"      \"instructional\"\r\n [8,] \"plans\"       \"balance\"      \"community\"  \"calculus\"     \r\n [9,] \"gain\"        \"week\"         \"support\"    \"engineering\"  \r\n[10,] \"family\"      \"health\"       \"career\"     \"research\"     \r\n      Topic 5      Topic 6         Topic 7     Topic 8    \r\n [1,] \"graduate\"   \"placement\"     \"goal\"      \"learn\"    \r\n [2,] \"stay\"       \"connections\"   \"classroom\" \"confident\"\r\n [3,] \"create\"     \"relationships\" \"pass\"      \"teachers\" \r\n [4,] \"management\" \"program\"       \"strong\"    \"complete\" \r\n [5,] \"motivated\"  \"job\"           \"impact\"    \"skills\"   \r\n [6,] \"successful\" \"improve\"       \"4.0\"       \"degree\"   \r\n [7,] \"schools\"    \"design\"        \"comfort\"   \"topics\"   \r\n [8,] \"class\"      \"resources\"     \"process\"   \"education\"\r\n [9,] \"foster\"     \"ced\"           \"passing\"   \"ncsu\"     \r\n[10,] \"fun\"        \"environment\"   \"succeed\"   \"friends\"  \r\n      Topic 9       Topic 10    \r\n [1,] \"students\"    \"teaching\"  \r\n [2,] \"school\"      \"time\"      \r\n [3,] \"culturally\"  \"finish\"    \r\n [4,] \"top\"         \"grades\"    \r\n [5,] \"comfortable\" \"mindset\"   \r\n [6,] \"safe\"        \"peers\"     \r\n [7,] \"influence\"   \"strategies\"\r\n [8,] \"hope\"        \"physically\"\r\n [9,] \"2021\"        \"confidence\"\r\n[10,] \"synthesize\"  \"creating\"  \r\n\r\nTopic Ranking\r\nWe can try to get more meaningful order by looking at to terms in\r\neach topic.\r\n\r\n\r\ntopicNames <- apply(terms(lda_soar_data, 5), 2, paste, collapse = \"\") # reset topic names\r\ntopicNames\r\n\r\n\r\n                                        Topic 1 \r\n              \"fieldeducatorknowledgebuildcare\" \r\n                                        Topic 2 \r\n           \"classesgrowthpeopleteachexperience\" \r\n                                        Topic 3 \r\n           \"futuregrowlearninglessonresponsive\" \r\n                                        Topic 4 \r\n\"teachersemesterpositiveinternshipdissertation\" \r\n                                        Topic 5 \r\n        \"graduatestaycreatemanagementmotivated\" \r\n                                        Topic 6 \r\n  \"placementconnectionsrelationshipsprogramjob\" \r\n                                        Topic 7 \r\n                \"goalclassroompassstrongimpact\" \r\n                                        Topic 8 \r\n         \"learnconfidentteacherscompleteskills\" \r\n                                        Topic 9 \r\n       \"studentsschoolculturallytopcomfortable\" \r\n                                       Topic 10 \r\n              \"teachingtimefinishgradesmindset\" \r\n\r\nLet’s get a rank for the top terms per topic. This didn;t produce\r\nmore then we already had above.\r\n\r\n\r\ntopicNames <- apply(lda::top.topic.words(beta, 5, by.score = T), 2, paste, collapse = \"\")\r\n\r\ntopicNames\r\n\r\n\r\n                                            1 \r\n            \"fieldeducatorknowledgebuildcare\" \r\n                                            2 \r\n         \"classesgrowthteachpeopleexperience\" \r\n                                            3 \r\n         \"futuregrowlearninglessonresponsive\" \r\n                                            4 \r\n     \"teachersemesterpositiveinternshiphappy\" \r\n                                            5 \r\n      \"graduatestaycreatemanagementmotivated\" \r\n                                            6 \r\n\"placementconnectionsrelationshipsprogramjob\" \r\n                                            7 \r\n              \"goalclassroompassstrongimpact\" \r\n                                            8 \r\n       \"learnconfidentteacherscompleteskills\" \r\n                                            9 \r\n     \"studentsschoolculturallytopcomfortable\" \r\n                                           10 \r\n            \"teachingtimefinishgradesmindset\" \r\n\r\nI am wondering if e can look at the probable topics and find their\r\noccurance. Sort topics according to the probability in the goals\r\ndata\r\n\r\n\r\ntopicProportions <- colSums(theta)/ nrow(cast_dtm)\r\n\r\ntopicProportions\r\n\r\n\r\n         1          2          3          4          5          6 \r\n0.10568281 0.09661194 0.09708784 0.09642858 0.10052924 0.10723441 \r\n         7          8          9         10 \r\n0.09697681 0.09272263 0.10476696 0.10195879 \r\n\r\nWe can see that some topics are occuring more often then others in\r\nthe corpus.\r\n\r\n\r\nnames(topicProportions) <- topicNames\r\n\r\nsort(topicProportions, decreasing = TRUE)\r\n\r\n\r\nplacementconnectionsrelationshipsprogramjob \r\n                                 0.10723441 \r\n            fieldeducatorknowledgebuildcare \r\n                                 0.10568281 \r\n     studentsschoolculturallytopcomfortable \r\n                                 0.10476696 \r\n            teachingtimefinishgradesmindset \r\n                                 0.10195879 \r\n      graduatestaycreatemanagementmotivated \r\n                                 0.10052924 \r\n         futuregrowlearninglessonresponsive \r\n                                 0.09708784 \r\n              goalclassroompassstrongimpact \r\n                                 0.09697681 \r\n         classesgrowthteachpeopleexperience \r\n                                 0.09661194 \r\n     teachersemesterpositiveinternshiphappy \r\n                                 0.09642858 \r\n       learnconfidentteacherscompleteskills \r\n                                 0.09272263 \r\n\r\nLet’s slice out the top 5 topics\r\n\r\n\r\nsoar_top_terms <- soar_topics %>%\r\n  group_by(topic) %>%\r\n  slice_max(beta, n = 5) %>% \r\n  ungroup() %>%\r\n  arrange(topic, -beta)\r\n\r\nsoar_top_terms %>%\r\n  mutate(term = reorder_within(term, beta, topic)) %>%\r\n  ggplot(aes(beta, term, fill = factor(topic))) +\r\n  geom_col(show.legend = FALSE) +\r\n  facet_wrap(~ topic, scales = \"free\") +\r\n  scale_y_reordered()\r\n\r\n\r\n\r\n\r\nCommunication\r\nI was hoping that we would have been able to tell from the LDA model\r\nAnalysis what department the terms were from and if there are any themes\r\nin which METRC would be able to support the students better. A LDA model\r\ndid not conclude anything more then a text Mining Analysis with\r\nSentiment.\r\nThe Bigrams was by far the most successfull when looking at themes\r\nthat may be of interst to METRC with supportive workshops and or PGU’s\r\nin the future.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-04-03-soar-project/soarpict1.jpg",
    "last_modified": "2022-04-03T20:28:39-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-03-a-prediction-model/",
    "title": "Do males outperform females in online STEM courses?",
    "description": "Looking at data from five online STEM courses.",
    "author": [
      {
        "name": "Jeanne McClure",
        "url": {}
      }
    ],
    "date": "2021-10-09",
    "categories": [],
    "contents": "\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\nlibrary(\"ggpubr\")\r\n\r\ndata_to_explore <- read_csv(\"data/data-to-explore.csv\")\r\n\r\ndata_to_viz <- data_to_explore %>%\r\n  select(subject, gender, proportion_earned) %>%  # reduced \r\n  mutate(subject = recode(subject, \r\n                          \"AnPhA\" = \"Anatomy\",\r\n                          \"BioA\" = \"Biology\", \r\n                          \"FrScA\" = \"Forensics\", \r\n                          \"OcnA\" =  \"Oceanography\", \r\n                          \"PhysA\" = \"Physics\")) %>%\r\n  mutate(grade = proportion_earned * 100) %>%\r\n  # filter(!is.na(gender)) %>%\r\n  na.omit() %>% # removed all NAs instead of just those for gender\r\n  group_by(subject, gender) %>% # grouped by subject and gender\r\n  summarise(grade = mean(grade), sd = sd(grade))# calculated mean and sd for grade and saved as grade again  \r\n\r\n  ggplot(data_to_viz, aes(x = subject, y = grade, \r\n                          fill = gender)) +\r\n  geom_bar(stat = \"identity\", \r\n           position = position_dodge()) +\r\n  geom_errorbar(aes(x = subject, ymin=grade-sd, ymax=grade+sd), width=0.4, \r\n                colour=\"black\", alpha=0.9, size=1.5)+\r\n  labs(title = \"Do Males out-preform Females in online STEM courses?\",\r\n       caption = \"Online STEM course performance, why is there still a gender gap?\",\r\n       y = \"Average Grade\",\r\n       x = \"Online STEM Course\")\r\n\r\n\r\n\r\n\r\nThe stereotypes about women in technical fields can linger with\r\ngender gaps in most science fields. Is it because males outpreform\r\nfemales in STEM courses? Collection data was obtained over four\r\nsemesters on five on-line STEM courses. Data was then computed into a\r\nstacked barplot looking at overal grade per course. NA’s were eliminated\r\nfrom the data. For each of five online STEM courses offered by the\r\nstatewide virtual public school from which this data was collected,\r\nfemales preformed higher in all STEM courses but Forensics.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-04-03-a-prediction-model/stem.png",
    "last_modified": "2022-04-03T21:42:38-04:00",
    "input_file": {}
  }
]
